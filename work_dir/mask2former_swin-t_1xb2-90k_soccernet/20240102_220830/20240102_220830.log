2024/01/02 22:08:30 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 681964601
    GPU 0: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda-12.2
    NVCC: Cuda compilation tools, release 12.2, V12.2.140
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.8.1
    MMEngine: 0.10.1

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 681964601
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2024/01/02 22:08:30 - mmengine - INFO - Config:
ann_dir = 'Labels'
auto_scale_lr = dict(base_batch_size=8, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    1080,
    1920,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        1080,
        1920,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = 'Dataset'
dataset_type = 'SoccerNet'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_dir = 'Images'
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            1080,
            1920,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=3,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 3
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    loss_scale='dynamic',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='AmpOptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=90000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file='splits/val.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
train_cfg = dict(max_iters=90000, type='IterBasedTrainLoop', val_interval=200)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        ann_file='splits/train.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file='splits/val.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/mask2former_swin-t_1xb2-90k_soccernet'

2024/01/02 22:08:31 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2024/01/02 22:08:31 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2024/01/02 22:08:32 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2024/01/02 22:08:32 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 768, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 192, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 96, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2024/01/02 22:08:32 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/01/02 22:08:32 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/01/02 22:08:32 - mmengine - INFO - Checkpoints will be saved to /home/vgaspar/Documents/TFE/banner-replacement/work_dirs/mask2former_swin-t_1xb2-90k_soccernet.
2024/01/02 22:09:14 - mmengine - INFO - Iter(train) [   50/90000]  base_lr: 9.9951e-05 lr: 9.9951e-06  eta: 21:10:03  time: 0.8256  data_time: 0.0072  memory: 14874  grad_norm: 239.9697  loss: 38.4783  decode.loss_cls: 1.2324  decode.loss_mask: 1.2755  decode.loss_dice: 2.8641  decode.d0.loss_cls: 2.7481  decode.d0.loss_mask: 0.6471  decode.d0.loss_dice: 2.2119  decode.d1.loss_cls: 0.6159  decode.d1.loss_mask: 0.6646  decode.d1.loss_dice: 2.1338  decode.d2.loss_cls: 0.2216  decode.d2.loss_mask: 0.6744  decode.d2.loss_dice: 2.2442  decode.d3.loss_cls: 0.2015  decode.d3.loss_mask: 0.6867  decode.d3.loss_dice: 2.2438  decode.d4.loss_cls: 0.2112  decode.d4.loss_mask: 0.6643  decode.d4.loss_dice: 2.2406  decode.d5.loss_cls: 0.2735  decode.d5.loss_mask: 0.7685  decode.d5.loss_dice: 2.1714  decode.d6.loss_cls: 0.3648  decode.d6.loss_mask: 1.0434  decode.d6.loss_dice: 2.1745  decode.d7.loss_cls: 0.5728  decode.d7.loss_mask: 0.9333  decode.d7.loss_dice: 2.3241  decode.d8.loss_cls: 0.9066  decode.d8.loss_mask: 0.7575  decode.d8.loss_dice: 2.4060
2024/01/02 22:09:56 - mmengine - INFO - Iter(train) [  100/90000]  base_lr: 9.9901e-05 lr: 9.9901e-06  eta: 20:54:23  time: 0.8285  data_time: 0.0072  memory: 14874  grad_norm: 166.6502  loss: 22.9290  decode.loss_cls: 0.0681  decode.loss_mask: 0.5393  decode.loss_dice: 1.4750  decode.d0.loss_cls: 2.4560  decode.d0.loss_mask: 0.4323  decode.d0.loss_dice: 1.5615  decode.d1.loss_cls: 0.1244  decode.d1.loss_mask: 0.4916  decode.d1.loss_dice: 1.4840  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.4910  decode.d2.loss_dice: 1.4746  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.4808  decode.d3.loss_dice: 1.4937  decode.d4.loss_cls: 0.0469  decode.d4.loss_mask: 0.5020  decode.d4.loss_dice: 1.4870  decode.d5.loss_cls: 0.0440  decode.d5.loss_mask: 0.5041  decode.d5.loss_dice: 1.4949  decode.d6.loss_cls: 0.0476  decode.d6.loss_mask: 0.5149  decode.d6.loss_dice: 1.4804  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.5237  decode.d7.loss_dice: 1.4908  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.5253  decode.d8.loss_dice: 1.4937
2024/01/02 22:10:37 - mmengine - INFO - Iter(train) [  150/90000]  base_lr: 9.9851e-05 lr: 9.9851e-06  eta: 20:50:26  time: 0.8280  data_time: 0.0072  memory: 14874  grad_norm: 195.1533  loss: 17.1428  decode.loss_cls: 0.0523  decode.loss_mask: 0.3300  decode.loss_dice: 1.1370  decode.d0.loss_cls: 2.2492  decode.d0.loss_mask: 0.3158  decode.d0.loss_dice: 1.2137  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.3182  decode.d1.loss_dice: 1.1017  decode.d2.loss_cls: 0.0373  decode.d2.loss_mask: 0.3264  decode.d2.loss_dice: 1.1108  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 1.0870  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.3266  decode.d4.loss_dice: 1.0995  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.3323  decode.d5.loss_dice: 1.1271  decode.d6.loss_cls: 0.0428  decode.d6.loss_mask: 0.3342  decode.d6.loss_dice: 1.1027  decode.d7.loss_cls: 0.0490  decode.d7.loss_mask: 0.3339  decode.d7.loss_dice: 1.1212  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.3222  decode.d8.loss_dice: 1.1118
2024/01/02 22:11:19 - mmengine - INFO - Iter(train) [  200/90000]  base_lr: 9.9801e-05 lr: 9.9801e-06  eta: 20:47:54  time: 0.8326  data_time: 0.0070  memory: 14874  grad_norm: 198.8951  loss: 13.3221  decode.loss_cls: 0.0421  decode.loss_mask: 0.3764  decode.loss_dice: 0.7151  decode.d0.loss_cls: 2.1232  decode.d0.loss_mask: 0.3193  decode.d0.loss_dice: 0.7716  decode.d1.loss_cls: 0.0498  decode.d1.loss_mask: 0.3440  decode.d1.loss_dice: 0.7081  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.3436  decode.d2.loss_dice: 0.7041  decode.d3.loss_cls: 0.0314  decode.d3.loss_mask: 0.3552  decode.d3.loss_dice: 0.7244  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.3626  decode.d4.loss_dice: 0.7325  decode.d5.loss_cls: 0.0297  decode.d5.loss_mask: 0.3673  decode.d5.loss_dice: 0.7214  decode.d6.loss_cls: 0.0303  decode.d6.loss_mask: 0.3896  decode.d6.loss_dice: 0.7355  decode.d7.loss_cls: 0.0330  decode.d7.loss_mask: 0.3820  decode.d7.loss_dice: 0.7227  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.3835  decode.d8.loss_dice: 0.7249
2024/01/02 22:12:02 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:37  time: 0.8355  data_time: 0.0076  memory: 12781  
2024/01/02 22:12:38 - mmengine - INFO - per class results:
2024/01/02 22:12:38 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 97.71 | 98.82 |
|     Billboard      | 54.62 | 72.24 |
|      Goal net      | 16.29 | 24.05 |
+--------------------+-------+-------+
2024/01/02 22:12:38 - mmengine - INFO - Iter(val) [93/93]    aAcc: 97.7200  mIoU: 56.2100  mAcc: 65.0400  data_time: 0.0099  time: 0.8545
2024/01/02 22:12:39 - mmengine - INFO - The best checkpoint with 56.2100 mIoU at 200 iter is saved to best_mIoU_iter_200.pth.
2024/01/02 22:13:20 - mmengine - INFO - Iter(train) [  250/90000]  base_lr: 9.9751e-05 lr: 9.9751e-06  eta: 20:49:56  time: 0.8314  data_time: 0.0073  memory: 14857  grad_norm: 261.4021  loss: 12.1518  decode.loss_cls: 0.0629  decode.loss_mask: 0.2904  decode.loss_dice: 0.6875  decode.d0.loss_cls: 2.0062  decode.d0.loss_mask: 0.2823  decode.d0.loss_dice: 0.6670  decode.d1.loss_cls: 0.0469  decode.d1.loss_mask: 0.2885  decode.d1.loss_dice: 0.6442  decode.d2.loss_cls: 0.0414  decode.d2.loss_mask: 0.2891  decode.d2.loss_dice: 0.6218  decode.d3.loss_cls: 0.0501  decode.d3.loss_mask: 0.2901  decode.d3.loss_dice: 0.6654  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.2956  decode.d4.loss_dice: 0.6763  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.2841  decode.d5.loss_dice: 0.6780  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.3012  decode.d6.loss_dice: 0.6852  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.2976  decode.d7.loss_dice: 0.6853  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.3017  decode.d8.loss_dice: 0.6810
2024/01/02 22:14:02 - mmengine - INFO - Iter(train) [  300/90000]  base_lr: 9.9701e-05 lr: 9.9701e-06  eta: 20:48:04  time: 0.8301  data_time: 0.0072  memory: 14842  grad_norm: 281.1327  loss: 10.3271  decode.loss_cls: 0.0059  decode.loss_mask: 0.1391  decode.loss_dice: 0.6445  decode.d0.loss_cls: 1.8399  decode.d0.loss_mask: 0.1299  decode.d0.loss_dice: 0.7411  decode.d1.loss_cls: 0.0331  decode.d1.loss_mask: 0.1377  decode.d1.loss_dice: 0.7252  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.1442  decode.d2.loss_dice: 0.7163  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.1406  decode.d3.loss_dice: 0.7028  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.1452  decode.d4.loss_dice: 0.6899  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.1448  decode.d5.loss_dice: 0.6771  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.1421  decode.d6.loss_dice: 0.6809  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.1477  decode.d7.loss_dice: 0.6763  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.1405  decode.d8.loss_dice: 0.6926
2024/01/02 22:14:44 - mmengine - INFO - Iter(train) [  350/90000]  base_lr: 9.9651e-05 lr: 9.9651e-06  eta: 20:46:43  time: 0.8338  data_time: 0.0071  memory: 14842  grad_norm: 128.6788  loss: 8.1778  decode.loss_cls: 0.0032  decode.loss_mask: 0.1911  decode.loss_dice: 0.4689  decode.d0.loss_cls: 1.6905  decode.d0.loss_mask: 0.1719  decode.d0.loss_dice: 0.4711  decode.d1.loss_cls: 0.0229  decode.d1.loss_mask: 0.1868  decode.d1.loss_dice: 0.4531  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.1940  decode.d2.loss_dice: 0.4556  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.1918  decode.d3.loss_dice: 0.4502  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.1958  decode.d4.loss_dice: 0.4379  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.1881  decode.d5.loss_dice: 0.4490  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.1841  decode.d6.loss_dice: 0.4399  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.1928  decode.d7.loss_dice: 0.4673  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.1879  decode.d8.loss_dice: 0.4447
2024/01/02 22:15:25 - mmengine - INFO - Iter(train) [  400/90000]  base_lr: 9.9601e-05 lr: 9.9601e-06  eta: 20:45:32  time: 0.8317  data_time: 0.0071  memory: 14842  grad_norm: 147.8541  loss: 8.8129  decode.loss_cls: 0.0121  decode.loss_mask: 0.2890  decode.loss_dice: 0.4315  decode.d0.loss_cls: 1.5635  decode.d0.loss_mask: 0.2646  decode.d0.loss_dice: 0.4422  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.2763  decode.d1.loss_dice: 0.4333  decode.d2.loss_cls: 0.0140  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.4232  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.2824  decode.d3.loss_dice: 0.4380  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 0.2856  decode.d4.loss_dice: 0.4306  decode.d5.loss_cls: 0.0120  decode.d5.loss_mask: 0.2749  decode.d5.loss_dice: 0.4309  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.2848  decode.d6.loss_dice: 0.4369  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.2853  decode.d7.loss_dice: 0.4307  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.2873  decode.d8.loss_dice: 0.4242
2024/01/02 22:16:07 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:36  time: 0.8275  data_time: 0.0075  memory: 9557  
2024/01/02 22:16:42 - mmengine - INFO - per class results:
2024/01/02 22:16:42 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.05 | 99.78 |
|     Billboard      | 76.98 | 80.38 |
|      Goal net      | 50.31 | 65.03 |
+--------------------+-------+-------+
2024/01/02 22:16:42 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.0500  mIoU: 75.4400  mAcc: 81.7300  data_time: 0.0092  time: 0.8328
2024/01/02 22:16:42 - mmengine - INFO - The previous best checkpoint /home/vgaspar/Documents/TFE/banner-replacement/work_dirs/mask2former_swin-t_1xb2-90k_soccernet/best_mIoU_iter_200.pth is removed
2024/01/02 22:16:43 - mmengine - INFO - The best checkpoint with 75.4400 mIoU at 400 iter is saved to best_mIoU_iter_400.pth.
2024/01/02 22:17:24 - mmengine - INFO - Iter(train) [  450/90000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 20:43:19  time: 0.8156  data_time: 0.0070  memory: 14842  grad_norm: 173.1809  loss: 7.5100  decode.loss_cls: 0.0339  decode.loss_mask: 0.1496  decode.loss_dice: 0.4410  decode.d0.loss_cls: 1.3172  decode.d0.loss_mask: 0.1327  decode.d0.loss_dice: 0.4655  decode.d1.loss_cls: 0.0206  decode.d1.loss_mask: 0.1444  decode.d1.loss_dice: 0.4361  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.1477  decode.d2.loss_dice: 0.4614  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.1497  decode.d3.loss_dice: 0.4549  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.1459  decode.d4.loss_dice: 0.4399  decode.d5.loss_cls: 0.0206  decode.d5.loss_mask: 0.1472  decode.d5.loss_dice: 0.4481  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.1470  decode.d6.loss_dice: 0.4491  decode.d7.loss_cls: 0.0237  decode.d7.loss_mask: 0.1503  decode.d7.loss_dice: 0.4641  decode.d8.loss_cls: 0.0269  decode.d8.loss_mask: 0.1453  decode.d8.loss_dice: 0.4684
2024/01/02 22:18:04 - mmengine - INFO - Iter(train) [  500/90000]  base_lr: 9.9501e-05 lr: 9.9501e-06  eta: 20:40:04  time: 0.8143  data_time: 0.0071  memory: 14842  grad_norm: 112.2092  loss: 5.8082  decode.loss_cls: 0.0029  decode.loss_mask: 0.1021  decode.loss_dice: 0.3546  decode.d0.loss_cls: 1.1029  decode.d0.loss_mask: 0.0939  decode.d0.loss_dice: 0.3680  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.1039  decode.d1.loss_dice: 0.3556  decode.d2.loss_cls: 0.0213  decode.d2.loss_mask: 0.1069  decode.d2.loss_dice: 0.3612  decode.d3.loss_cls: 0.0102  decode.d3.loss_mask: 0.1062  decode.d3.loss_dice: 0.3608  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.1027  decode.d4.loss_dice: 0.3559  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.1010  decode.d5.loss_dice: 0.3557  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.1062  decode.d6.loss_dice: 0.3539  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.1031  decode.d7.loss_dice: 0.3615  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.1021  decode.d8.loss_dice: 0.3500
2024/01/02 22:18:45 - mmengine - INFO - Iter(train) [  550/90000]  base_lr: 9.9451e-05 lr: 9.9451e-06  eta: 20:37:22  time: 0.8165  data_time: 0.0070  memory: 14842  grad_norm: 223.0118  loss: 7.0754  decode.loss_cls: 0.0066  decode.loss_mask: 0.1873  decode.loss_dice: 0.4326  decode.d0.loss_cls: 0.9619  decode.d0.loss_mask: 0.1799  decode.d0.loss_dice: 0.4305  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.1823  decode.d1.loss_dice: 0.4320  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.1851  decode.d2.loss_dice: 0.4232  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.1786  decode.d3.loss_dice: 0.4132  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.1847  decode.d4.loss_dice: 0.4156  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.1819  decode.d5.loss_dice: 0.4265  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.1830  decode.d6.loss_dice: 0.4130  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1833  decode.d7.loss_dice: 0.4256  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.1840  decode.d8.loss_dice: 0.4212
2024/01/02 22:19:26 - mmengine - INFO - Iter(train) [  600/90000]  base_lr: 9.9401e-05 lr: 9.9401e-06  eta: 20:34:21  time: 0.8099  data_time: 0.0070  memory: 14842  grad_norm: 105.0876  loss: 4.7024  decode.loss_cls: 0.0038  decode.loss_mask: 0.0852  decode.loss_dice: 0.2927  decode.d0.loss_cls: 0.7826  decode.d0.loss_mask: 0.0851  decode.d0.loss_dice: 0.3087  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.0862  decode.d1.loss_dice: 0.3052  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.0832  decode.d2.loss_dice: 0.3040  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.0867  decode.d3.loss_dice: 0.2898  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.0867  decode.d4.loss_dice: 0.3021  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.0903  decode.d5.loss_dice: 0.2998  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.0885  decode.d6.loss_dice: 0.3021  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.0854  decode.d7.loss_dice: 0.2969  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.0884  decode.d8.loss_dice: 0.3069
2024/01/02 22:20:07 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8268  data_time: 0.0074  memory: 9557  
2024/01/02 22:20:42 - mmengine - INFO - per class results:
2024/01/02 22:20:42 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards |  99.3 | 99.65 |
|     Billboard      | 85.21 | 90.27 |
|      Goal net      | 57.42 |  85.3 |
+--------------------+-------+-------+
2024/01/02 22:20:42 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.3100  mIoU: 80.6500  mAcc: 91.7400  data_time: 0.0092  time: 0.8201
2024/01/02 22:20:42 - mmengine - INFO - The previous best checkpoint /home/vgaspar/Documents/TFE/banner-replacement/work_dirs/mask2former_swin-t_1xb2-90k_soccernet/best_mIoU_iter_400.pth is removed
2024/01/02 22:20:43 - mmengine - INFO - The best checkpoint with 80.6500 mIoU at 600 iter is saved to best_mIoU_iter_600.pth.
2024/01/02 22:21:24 - mmengine - INFO - Iter(train) [  650/90000]  base_lr: 9.9351e-05 lr: 9.9351e-06  eta: 20:33:07  time: 0.8135  data_time: 0.0071  memory: 14842  grad_norm: 156.3182  loss: 6.8369  decode.loss_cls: 0.0761  decode.loss_mask: 0.1508  decode.loss_dice: 0.4185  decode.d0.loss_cls: 0.6516  decode.d0.loss_mask: 0.1475  decode.d0.loss_dice: 0.4267  decode.d1.loss_cls: 0.0719  decode.d1.loss_mask: 0.1459  decode.d1.loss_dice: 0.3843  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.1479  decode.d2.loss_dice: 0.4111  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.1487  decode.d3.loss_dice: 0.4146  decode.d4.loss_cls: 0.0379  decode.d4.loss_mask: 0.1509  decode.d4.loss_dice: 0.4147  decode.d5.loss_cls: 0.0388  decode.d5.loss_mask: 0.1478  decode.d5.loss_dice: 0.4144  decode.d6.loss_cls: 0.0392  decode.d6.loss_mask: 0.1509  decode.d6.loss_dice: 0.4171  decode.d7.loss_cls: 0.0422  decode.d7.loss_mask: 0.1446  decode.d7.loss_dice: 0.4181  decode.d8.loss_cls: 0.0748  decode.d8.loss_mask: 0.1476  decode.d8.loss_dice: 0.4274
2024/01/02 22:22:04 - mmengine - INFO - Iter(train) [  700/90000]  base_lr: 9.9301e-05 lr: 9.9301e-06  eta: 20:30:50  time: 0.8148  data_time: 0.0071  memory: 14842  grad_norm: 99.0707  loss: 4.7318  decode.loss_cls: 0.0789  decode.loss_mask: 0.1041  decode.loss_dice: 0.2897  decode.d0.loss_cls: 0.5237  decode.d0.loss_mask: 0.0998  decode.d0.loss_dice: 0.2662  decode.d1.loss_cls: 0.0499  decode.d1.loss_mask: 0.1024  decode.d1.loss_dice: 0.2646  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.0967  decode.d2.loss_dice: 0.2343  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.1032  decode.d3.loss_dice: 0.2875  decode.d4.loss_cls: 0.0474  decode.d4.loss_mask: 0.1009  decode.d4.loss_dice: 0.2818  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.1023  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.1045  decode.d6.loss_dice: 0.2724  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.0997  decode.d7.loss_dice: 0.2424  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.1027  decode.d8.loss_dice: 0.2859
2024/01/02 22:22:45 - mmengine - INFO - Iter(train) [  750/90000]  base_lr: 9.9251e-05 lr: 9.9251e-06  eta: 20:28:45  time: 0.8138  data_time: 0.0070  memory: 14842  grad_norm: 217.4283  loss: 4.2756  decode.loss_cls: 0.0013  decode.loss_mask: 0.0767  decode.loss_dice: 0.3049  decode.d0.loss_cls: 0.4228  decode.d0.loss_mask: 0.0734  decode.d0.loss_dice: 0.3145  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.0750  decode.d1.loss_dice: 0.3027  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.0766  decode.d2.loss_dice: 0.3080  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.0759  decode.d3.loss_dice: 0.3148  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.0765  decode.d4.loss_dice: 0.3116  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.0788  decode.d5.loss_dice: 0.3132  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.0800  decode.d6.loss_dice: 0.2987  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.0788  decode.d7.loss_dice: 0.3011  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.0758  decode.d8.loss_dice: 0.3012
2024/01/02 22:23:26 - mmengine - INFO - Iter(train) [  800/90000]  base_lr: 9.9201e-05 lr: 9.9201e-06  eta: 20:27:08  time: 0.8126  data_time: 0.0071  memory: 14842  grad_norm: 44.8699  loss: 2.9677  decode.loss_cls: 0.0086  decode.loss_mask: 0.0983  decode.loss_dice: 0.1622  decode.d0.loss_cls: 0.3606  decode.d0.loss_mask: 0.0905  decode.d0.loss_dice: 0.1577  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.0916  decode.d1.loss_dice: 0.1575  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.0941  decode.d2.loss_dice: 0.1545  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.0962  decode.d3.loss_dice: 0.1595  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.0956  decode.d4.loss_dice: 0.1588  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.0967  decode.d5.loss_dice: 0.1614  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.0944  decode.d6.loss_dice: 0.1597  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.0964  decode.d7.loss_dice: 0.1604  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.0953  decode.d8.loss_dice: 0.1532
2024/01/02 22:24:07 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8271  data_time: 0.0075  memory: 9557  
2024/01/02 22:24:42 - mmengine - INFO - per class results:
2024/01/02 22:24:42 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.48 | 99.83 |
|     Billboard      |  87.7 | 92.09 |
|      Goal net      | 59.65 | 65.86 |
+--------------------+-------+-------+
2024/01/02 22:24:42 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.4700  mIoU: 82.2800  mAcc: 85.9300  data_time: 0.0093  time: 0.8212
2024/01/02 22:24:42 - mmengine - INFO - The previous best checkpoint /home/vgaspar/Documents/TFE/banner-replacement/work_dirs/mask2former_swin-t_1xb2-90k_soccernet/best_mIoU_iter_600.pth is removed
2024/01/02 22:24:43 - mmengine - INFO - The best checkpoint with 82.2800 mIoU at 800 iter is saved to best_mIoU_iter_800.pth.
2024/01/02 22:25:24 - mmengine - INFO - Iter(train) [  850/90000]  base_lr: 9.9151e-05 lr: 9.9151e-06  eta: 20:26:49  time: 0.8179  data_time: 0.0073  memory: 14842  grad_norm: 38.3025  loss: 3.3646  decode.loss_cls: 0.0702  decode.loss_mask: 0.0656  decode.loss_dice: 0.2210  decode.d0.loss_cls: 0.2898  decode.d0.loss_mask: 0.0655  decode.d0.loss_dice: 0.2236  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 0.0650  decode.d1.loss_dice: 0.2229  decode.d2.loss_cls: 0.0392  decode.d2.loss_mask: 0.0630  decode.d2.loss_dice: 0.1600  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.0644  decode.d3.loss_dice: 0.1786  decode.d4.loss_cls: 0.0446  decode.d4.loss_mask: 0.0649  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.0649  decode.d5.loss_dice: 0.2092  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.0650  decode.d6.loss_dice: 0.2052  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 0.0645  decode.d7.loss_dice: 0.1698  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.0646  decode.d8.loss_dice: 0.1990
2024/01/02 22:26:05 - mmengine - INFO - Iter(train) [  900/90000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 20:25:09  time: 0.8138  data_time: 0.0071  memory: 14842  grad_norm: 44.7848  loss: 2.5284  decode.loss_cls: 0.0057  decode.loss_mask: 0.0798  decode.loss_dice: 0.1514  decode.d0.loss_cls: 0.2428  decode.d0.loss_mask: 0.0757  decode.d0.loss_dice: 0.1513  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.0759  decode.d1.loss_dice: 0.1474  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.0751  decode.d2.loss_dice: 0.1406  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.0781  decode.d3.loss_dice: 0.1498  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.0762  decode.d4.loss_dice: 0.1425  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.0792  decode.d5.loss_dice: 0.1450  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.0788  decode.d6.loss_dice: 0.1397  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.0747  decode.d7.loss_dice: 0.1458  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.0768  decode.d8.loss_dice: 0.1385
2024/01/02 22:26:45 - mmengine - INFO - Iter(train) [  950/90000]  base_lr: 9.9050e-05 lr: 9.9050e-06  eta: 20:23:34  time: 0.8131  data_time: 0.0071  memory: 14842  grad_norm: 67.1161  loss: 4.0293  decode.loss_cls: 0.0044  decode.loss_mask: 0.1524  decode.loss_dice: 0.2283  decode.d0.loss_cls: 0.1996  decode.d0.loss_mask: 0.1346  decode.d0.loss_dice: 0.2319  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.1520  decode.d1.loss_dice: 0.2292  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.1501  decode.d2.loss_dice: 0.2311  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.1513  decode.d3.loss_dice: 0.2310  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.1495  decode.d4.loss_dice: 0.2295  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.1504  decode.d5.loss_dice: 0.2234  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.1521  decode.d6.loss_dice: 0.2237  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.1484  decode.d7.loss_dice: 0.2253  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.1477  decode.d8.loss_dice: 0.2296
2024/01/02 22:27:26 - mmengine - INFO - Exp name: mask2former_swin-t_1xb2-90k_soccernet_20240102_220830
2024/01/02 22:27:26 - mmengine - INFO - Iter(train) [ 1000/90000]  base_lr: 9.9000e-05 lr: 9.9000e-06  eta: 20:22:05  time: 0.8137  data_time: 0.0072  memory: 14842  grad_norm: 57.2237  loss: 2.6755  decode.loss_cls: 0.0009  decode.loss_mask: 0.0512  decode.loss_dice: 0.2020  decode.d0.loss_cls: 0.1590  decode.d0.loss_mask: 0.0471  decode.d0.loss_dice: 0.1993  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.0474  decode.d1.loss_dice: 0.2038  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.0493  decode.d2.loss_dice: 0.1998  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.0483  decode.d3.loss_dice: 0.2062  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.0475  decode.d4.loss_dice: 0.2064  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.0495  decode.d5.loss_dice: 0.1997  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.0479  decode.d6.loss_dice: 0.1967  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0498  decode.d7.loss_dice: 0.1975  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0498  decode.d8.loss_dice: 0.2086
2024/01/02 22:28:08 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8273  data_time: 0.0075  memory: 9557  
2024/01/02 22:28:43 - mmengine - INFO - per class results:
2024/01/02 22:28:43 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.57 | 99.77 |
|     Billboard      | 90.29 | 94.59 |
|      Goal net      | 66.82 | 86.74 |
+--------------------+-------+-------+
2024/01/02 22:28:43 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.5600  mIoU: 85.5600  mAcc: 93.7000  data_time: 0.0095  time: 0.8206
2024/01/02 22:28:43 - mmengine - INFO - The previous best checkpoint /home/vgaspar/Documents/TFE/banner-replacement/work_dirs/mask2former_swin-t_1xb2-90k_soccernet/best_mIoU_iter_800.pth is removed
2024/01/02 22:28:43 - mmengine - INFO - The best checkpoint with 85.5600 mIoU at 1000 iter is saved to best_mIoU_iter_1000.pth.
2024/01/02 22:29:24 - mmengine - INFO - Iter(train) [ 1050/90000]  base_lr: 9.8950e-05 lr: 9.8950e-06  eta: 20:21:27  time: 0.8098  data_time: 0.0070  memory: 14842  grad_norm: 65.1323  loss: 2.5923  decode.loss_cls: 0.0004  decode.loss_mask: 0.0682  decode.loss_dice: 0.1710  decode.d0.loss_cls: 0.1353  decode.d0.loss_mask: 0.0689  decode.d0.loss_dice: 0.1765  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.0695  decode.d1.loss_dice: 0.1738  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.0692  decode.d2.loss_dice: 0.1726  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0707  decode.d3.loss_dice: 0.1728  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0698  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0693  decode.d5.loss_dice: 0.1737  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0705  decode.d6.loss_dice: 0.1819  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0719  decode.d7.loss_dice: 0.1863  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0680  decode.d8.loss_dice: 0.1774
2024/01/02 22:29:49 - mmengine - INFO - Exp name: mask2former_swin-t_1xb2-90k_soccernet_20240102_220830
2024/01/02 22:30:05 - mmengine - INFO - Iter(train) [ 1100/90000]  base_lr: 9.8900e-05 lr: 9.8900e-06  eta: 20:20:11  time: 0.8077  data_time: 0.0071  memory: 14842  grad_norm: 72.4681  loss: 2.1718  decode.loss_cls: 0.0010  decode.loss_mask: 0.0671  decode.loss_dice: 0.1328  decode.d0.loss_cls: 0.1252  decode.d0.loss_mask: 0.0651  decode.d0.loss_dice: 0.1375  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.0699  decode.d1.loss_dice: 0.1382  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.0682  decode.d2.loss_dice: 0.1351  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.0705  decode.d3.loss_dice: 0.1411  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.0677  decode.d4.loss_dice: 0.1289  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.0687  decode.d5.loss_dice: 0.1385  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.0702  decode.d6.loss_dice: 0.1300  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.0685  decode.d7.loss_dice: 0.1302  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.0707  decode.d8.loss_dice: 0.1332
2024/01/02 22:30:45 - mmengine - INFO - Iter(train) [ 1150/90000]  base_lr: 9.8850e-05 lr: 9.8850e-06  eta: 20:18:39  time: 0.8117  data_time: 0.0072  memory: 14842  grad_norm: 28.1383  loss: 2.1798  decode.loss_cls: 0.0002  decode.loss_mask: 0.0351  decode.loss_dice: 0.1747  decode.d0.loss_cls: 0.0970  decode.d0.loss_mask: 0.0314  decode.d0.loss_dice: 0.1679  decode.d1.loss_cls: 0.0256  decode.d1.loss_mask: 0.0335  decode.d1.loss_dice: 0.1693  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.0344  decode.d2.loss_dice: 0.1752  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.0334  decode.d3.loss_dice: 0.1685  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.0341  decode.d4.loss_dice: 0.1644  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0330  decode.d5.loss_dice: 0.1745  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0352  decode.d6.loss_dice: 0.1798  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0329  decode.d7.loss_dice: 0.1592  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0325  decode.d8.loss_dice: 0.1757
2024/01/02 22:31:26 - mmengine - INFO - Iter(train) [ 1200/90000]  base_lr: 9.8800e-05 lr: 9.8800e-06  eta: 20:17:15  time: 0.8089  data_time: 0.0071  memory: 14842  grad_norm: 23.4485  loss: 1.8679  decode.loss_cls: 0.0002  decode.loss_mask: 0.0475  decode.loss_dice: 0.1273  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.0474  decode.d0.loss_dice: 0.1389  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0484  decode.d1.loss_dice: 0.1310  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0493  decode.d2.loss_dice: 0.1267  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0507  decode.d3.loss_dice: 0.1291  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0503  decode.d4.loss_dice: 0.1302  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0482  decode.d5.loss_dice: 0.1250  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0490  decode.d6.loss_dice: 0.1281  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0474  decode.d7.loss_dice: 0.1282  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0481  decode.d8.loss_dice: 0.1285
2024/01/02 22:32:07 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8270  data_time: 0.0075  memory: 9557  
2024/01/02 22:32:43 - mmengine - INFO - per class results:
2024/01/02 22:32:43 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.65 | 99.84 |
|     Billboard      |  91.7 | 95.49 |
|      Goal net      |  73.0 | 82.29 |
+--------------------+-------+-------+
2024/01/02 22:32:43 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.6400  mIoU: 88.1200  mAcc: 92.5400  data_time: 0.0092  time: 0.8205
2024/01/02 22:32:43 - mmengine - INFO - The previous best checkpoint /home/vgaspar/Documents/TFE/banner-replacement/work_dirs/mask2former_swin-t_1xb2-90k_soccernet/best_mIoU_iter_1000.pth is removed
2024/01/02 22:32:43 - mmengine - INFO - The best checkpoint with 88.1200 mIoU at 1200 iter is saved to best_mIoU_iter_1200.pth.
2024/01/02 22:33:23 - mmengine - INFO - Iter(train) [ 1250/90000]  base_lr: 9.8750e-05 lr: 9.8750e-06  eta: 20:16:21  time: 0.8100  data_time: 0.0073  memory: 14842  grad_norm: 72.0807  loss: 2.5213  decode.loss_cls: 0.0009  decode.loss_mask: 0.0763  decode.loss_dice: 0.1751  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.0728  decode.d0.loss_dice: 0.1734  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.0718  decode.d1.loss_dice: 0.1610  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.0734  decode.d2.loss_dice: 0.1739  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.0727  decode.d3.loss_dice: 0.1684  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.0731  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.0745  decode.d5.loss_dice: 0.1715  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.0732  decode.d6.loss_dice: 0.1676  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.0711  decode.d7.loss_dice: 0.1634  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.0735  decode.d8.loss_dice: 0.1669
2024/01/02 22:34:04 - mmengine - INFO - Iter(train) [ 1300/90000]  base_lr: 9.8700e-05 lr: 9.8700e-06  eta: 20:14:54  time: 0.8116  data_time: 0.0074  memory: 14842  grad_norm: 53.9828  loss: 2.3099  decode.loss_cls: 0.0001  decode.loss_mask: 0.0665  decode.loss_dice: 0.1577  decode.d0.loss_cls: 0.0705  decode.d0.loss_mask: 0.0609  decode.d0.loss_dice: 0.1598  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0613  decode.d1.loss_dice: 0.1642  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0642  decode.d2.loss_dice: 0.1643  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0662  decode.d3.loss_dice: 0.1540  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0620  decode.d4.loss_dice: 0.1550  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0666  decode.d5.loss_dice: 0.1606  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0640  decode.d6.loss_dice: 0.1607  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0625  decode.d7.loss_dice: 0.1625  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0640  decode.d8.loss_dice: 0.1607
2024/01/02 22:34:44 - mmengine - INFO - Iter(train) [ 1350/90000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 20:13:30  time: 0.8063  data_time: 0.0073  memory: 14842  grad_norm: 45.2747  loss: 2.1207  decode.loss_cls: 0.0001  decode.loss_mask: 0.0489  decode.loss_dice: 0.1679  decode.d0.loss_cls: 0.0662  decode.d0.loss_mask: 0.0478  decode.d0.loss_dice: 0.1527  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0498  decode.d1.loss_dice: 0.1473  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0494  decode.d2.loss_dice: 0.1528  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0507  decode.d3.loss_dice: 0.1608  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0487  decode.d4.loss_dice: 0.1518  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0493  decode.d5.loss_dice: 0.1616  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0495  decode.d6.loss_dice: 0.1476  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0494  decode.d7.loss_dice: 0.1567  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0480  decode.d8.loss_dice: 0.1624
2024/01/02 22:35:25 - mmengine - INFO - Iter(train) [ 1400/90000]  base_lr: 9.8600e-05 lr: 9.8600e-06  eta: 20:12:07  time: 0.8092  data_time: 0.0073  memory: 14842  grad_norm: 87.4785  loss: 2.3043  decode.loss_cls: 0.0004  decode.loss_mask: 0.0588  decode.loss_dice: 0.1727  decode.d0.loss_cls: 0.0576  decode.d0.loss_mask: 0.0552  decode.d0.loss_dice: 0.1773  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0556  decode.d1.loss_dice: 0.1677  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0552  decode.d2.loss_dice: 0.1670  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0590  decode.d3.loss_dice: 0.1736  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0572  decode.d4.loss_dice: 0.1584  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0563  decode.d5.loss_dice: 0.1642  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0566  decode.d6.loss_dice: 0.1679  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0588  decode.d7.loss_dice: 0.1641  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.0556  decode.d8.loss_dice: 0.1633
2024/01/02 22:36:06 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8290  data_time: 0.0077  memory: 9557  
2024/01/02 22:36:42 - mmengine - INFO - per class results:
2024/01/02 22:36:42 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.54 | 99.84 |
|     Billboard      | 88.96 |  92.5 |
|      Goal net      |  71.6 | 79.89 |
+--------------------+-------+-------+
2024/01/02 22:36:42 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.5400  mIoU: 86.7000  mAcc: 90.7500  data_time: 0.0093  time: 0.8213
2024/01/02 22:37:22 - mmengine - INFO - Iter(train) [ 1450/90000]  base_lr: 9.8550e-05 lr: 9.8550e-06  eta: 20:10:55  time: 0.8092  data_time: 0.0073  memory: 14842  grad_norm: 64.7628  loss: 2.2013  decode.loss_cls: 0.0001  decode.loss_mask: 0.0794  decode.loss_dice: 0.1315  decode.d0.loss_cls: 0.0607  decode.d0.loss_mask: 0.0812  decode.d0.loss_dice: 0.1413  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0780  decode.d1.loss_dice: 0.1285  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0789  decode.d2.loss_dice: 0.1393  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0786  decode.d3.loss_dice: 0.1346  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0809  decode.d4.loss_dice: 0.1468  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0787  decode.d5.loss_dice: 0.1309  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0785  decode.d6.loss_dice: 0.1283  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0768  decode.d7.loss_dice: 0.1290  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0806  decode.d8.loss_dice: 0.1371
2024/01/02 22:38:03 - mmengine - INFO - Iter(train) [ 1500/90000]  base_lr: 9.8500e-05 lr: 9.8500e-06  eta: 20:09:45  time: 0.8132  data_time: 0.0074  memory: 14842  grad_norm: 72.2829  loss: 2.4797  decode.loss_cls: 0.0002  decode.loss_mask: 0.0592  decode.loss_dice: 0.1937  decode.d0.loss_cls: 0.0518  decode.d0.loss_mask: 0.0563  decode.d0.loss_dice: 0.1800  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.0570  decode.d1.loss_dice: 0.1862  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0562  decode.d2.loss_dice: 0.1805  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0570  decode.d3.loss_dice: 0.1810  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.0546  decode.d4.loss_dice: 0.1929  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0574  decode.d5.loss_dice: 0.1891  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.0563  decode.d6.loss_dice: 0.1796  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.0577  decode.d7.loss_dice: 0.1825  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0582  decode.d8.loss_dice: 0.1882
2024/01/02 22:38:43 - mmengine - INFO - Iter(train) [ 1550/90000]  base_lr: 9.8450e-05 lr: 9.8450e-06  eta: 20:08:38  time: 0.8076  data_time: 0.0073  memory: 14842  grad_norm: 18.3851  loss: 1.7956  decode.loss_cls: 0.0007  decode.loss_mask: 0.0730  decode.loss_dice: 0.1003  decode.d0.loss_cls: 0.0535  decode.d0.loss_mask: 0.0719  decode.d0.loss_dice: 0.1053  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.0718  decode.d1.loss_dice: 0.1023  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.0720  decode.d2.loss_dice: 0.0985  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.0743  decode.d3.loss_dice: 0.0998  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.0736  decode.d4.loss_dice: 0.1006  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.0726  decode.d5.loss_dice: 0.0966  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0721  decode.d6.loss_dice: 0.0967  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.0723  decode.d7.loss_dice: 0.1049  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.0742  decode.d8.loss_dice: 0.1030
2024/01/02 22:39:24 - mmengine - INFO - Iter(train) [ 1600/90000]  base_lr: 9.8400e-05 lr: 9.8400e-06  eta: 20:07:34  time: 0.8122  data_time: 0.0073  memory: 14842  grad_norm: 26.0938  loss: 2.1039  decode.loss_cls: 0.0097  decode.loss_mask: 0.0568  decode.loss_dice: 0.1379  decode.d0.loss_cls: 0.0499  decode.d0.loss_mask: 0.0571  decode.d0.loss_dice: 0.1363  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.0546  decode.d1.loss_dice: 0.1374  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.0586  decode.d2.loss_dice: 0.1447  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.0589  decode.d3.loss_dice: 0.1412  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.0587  decode.d4.loss_dice: 0.1489  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.0580  decode.d5.loss_dice: 0.1398  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.0569  decode.d6.loss_dice: 0.1328  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.0568  decode.d7.loss_dice: 0.1317  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.0589  decode.d8.loss_dice: 0.1447
2024/01/02 22:40:05 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8279  data_time: 0.0076  memory: 9557  
2024/01/02 22:40:40 - mmengine - INFO - per class results:
2024/01/02 22:40:40 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards |  99.6 | 99.83 |
|     Billboard      | 89.91 | 93.31 |
|      Goal net      | 72.97 | 87.43 |
+--------------------+-------+-------+
2024/01/02 22:40:40 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.5900  mIoU: 87.4900  mAcc: 93.5200  data_time: 0.0093  time: 0.8208
2024/01/02 22:41:21 - mmengine - INFO - Iter(train) [ 1650/90000]  base_lr: 9.8349e-05 lr: 9.8349e-06  eta: 20:06:31  time: 0.8106  data_time: 0.0073  memory: 14842  grad_norm: 25.3269  loss: 3.0529  decode.loss_cls: 0.0635  decode.loss_mask: 0.0950  decode.loss_dice: 0.1214  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.0962  decode.d0.loss_dice: 0.1080  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.0953  decode.d1.loss_dice: 0.1582  decode.d2.loss_cls: 0.0553  decode.d2.loss_mask: 0.0941  decode.d2.loss_dice: 0.1143  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.0973  decode.d3.loss_dice: 0.1790  decode.d4.loss_cls: 0.0544  decode.d4.loss_mask: 0.0976  decode.d4.loss_dice: 0.1562  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.0914  decode.d5.loss_dice: 0.1766  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.0966  decode.d6.loss_dice: 0.1804  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.0962  decode.d7.loss_dice: 0.1517  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.0916  decode.d8.loss_dice: 0.1871
2024/01/02 22:42:02 - mmengine - INFO - Iter(train) [ 1700/90000]  base_lr: 9.8299e-05 lr: 9.8299e-06  eta: 20:05:35  time: 0.8110  data_time: 0.0074  memory: 14842  grad_norm: 27.2199  loss: 1.8182  decode.loss_cls: 0.0028  decode.loss_mask: 0.0609  decode.loss_dice: 0.1136  decode.d0.loss_cls: 0.0457  decode.d0.loss_mask: 0.0610  decode.d0.loss_dice: 0.1165  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.0598  decode.d1.loss_dice: 0.1139  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.0603  decode.d2.loss_dice: 0.1138  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.0638  decode.d3.loss_dice: 0.1184  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.0643  decode.d4.loss_dice: 0.1205  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.0614  decode.d5.loss_dice: 0.1065  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.0596  decode.d6.loss_dice: 0.1093  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.0604  decode.d7.loss_dice: 0.1099  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.0610  decode.d8.loss_dice: 0.1120
2024/01/02 22:42:42 - mmengine - INFO - Iter(train) [ 1750/90000]  base_lr: 9.8249e-05 lr: 9.8249e-06  eta: 20:04:36  time: 0.8089  data_time: 0.0074  memory: 14842  grad_norm: 50.3513  loss: 1.9324  decode.loss_cls: 0.0003  decode.loss_mask: 0.0622  decode.loss_dice: 0.1337  decode.d0.loss_cls: 0.0460  decode.d0.loss_mask: 0.0583  decode.d0.loss_dice: 0.1303  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0578  decode.d1.loss_dice: 0.1290  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.0592  decode.d2.loss_dice: 0.1346  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0602  decode.d3.loss_dice: 0.1342  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.0593  decode.d4.loss_dice: 0.1235  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.0583  decode.d5.loss_dice: 0.1207  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0581  decode.d6.loss_dice: 0.1273  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0589  decode.d7.loss_dice: 0.1283  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.0620  decode.d8.loss_dice: 0.1267
2024/01/02 22:43:23 - mmengine - INFO - Iter(train) [ 1800/90000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 20:03:36  time: 0.8132  data_time: 0.0074  memory: 14842  grad_norm: 32.6258  loss: 1.8796  decode.loss_cls: 0.0006  decode.loss_mask: 0.0629  decode.loss_dice: 0.1256  decode.d0.loss_cls: 0.0382  decode.d0.loss_mask: 0.0592  decode.d0.loss_dice: 0.1242  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0627  decode.d1.loss_dice: 0.1226  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0620  decode.d2.loss_dice: 0.1241  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.0634  decode.d3.loss_dice: 0.1205  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0604  decode.d4.loss_dice: 0.1203  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0610  decode.d5.loss_dice: 0.1182  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.0623  decode.d6.loss_dice: 0.1253  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0616  decode.d7.loss_dice: 0.1213  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0624  decode.d8.loss_dice: 0.1184
2024/01/02 22:44:04 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8280  data_time: 0.0076  memory: 9557  
2024/01/02 22:44:40 - mmengine - INFO - per class results:
2024/01/02 22:44:40 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.66 | 99.88 |
|     Billboard      | 90.75 | 92.95 |
|      Goal net      | 74.62 | 91.09 |
+--------------------+-------+-------+
2024/01/02 22:44:40 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.6300  mIoU: 88.3400  mAcc: 94.6400  data_time: 0.0094  time: 0.8204
2024/01/02 22:44:40 - mmengine - INFO - The previous best checkpoint /home/vgaspar/Documents/TFE/banner-replacement/work_dirs/mask2former_swin-t_1xb2-90k_soccernet/best_mIoU_iter_1200.pth is removed
2024/01/02 22:44:40 - mmengine - INFO - The best checkpoint with 88.3400 mIoU at 1800 iter is saved to best_mIoU_iter_1800.pth.
2024/01/02 22:45:21 - mmengine - INFO - Iter(train) [ 1850/90000]  base_lr: 9.8149e-05 lr: 9.8149e-06  eta: 20:03:04  time: 0.8098  data_time: 0.0075  memory: 14842  grad_norm: 45.6185  loss: 2.0277  decode.loss_cls: 0.0001  decode.loss_mask: 0.0592  decode.loss_dice: 0.1429  decode.d0.loss_cls: 0.0382  decode.d0.loss_mask: 0.0567  decode.d0.loss_dice: 0.1452  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0583  decode.d1.loss_dice: 0.1440  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0568  decode.d2.loss_dice: 0.1460  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0551  decode.d3.loss_dice: 0.1355  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0565  decode.d4.loss_dice: 0.1430  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0587  decode.d5.loss_dice: 0.1441  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0546  decode.d6.loss_dice: 0.1365  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0555  decode.d7.loss_dice: 0.1428  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0556  decode.d8.loss_dice: 0.1409
2024/01/02 22:46:01 - mmengine - INFO - Iter(train) [ 1900/90000]  base_lr: 9.8099e-05 lr: 9.8099e-06  eta: 20:01:54  time: 0.8046  data_time: 0.0074  memory: 14842  grad_norm: 75.0885  loss: 2.0681  decode.loss_cls: 0.1080  decode.loss_mask: 0.0487  decode.loss_dice: 0.1243  decode.d0.loss_cls: 0.0382  decode.d0.loss_mask: 0.0491  decode.d0.loss_dice: 0.1255  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.0482  decode.d1.loss_dice: 0.1262  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.0472  decode.d2.loss_dice: 0.1174  decode.d3.loss_cls: 0.0273  decode.d3.loss_mask: 0.0493  decode.d3.loss_dice: 0.1224  decode.d4.loss_cls: 0.0302  decode.d4.loss_mask: 0.0486  decode.d4.loss_dice: 0.1205  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.0480  decode.d5.loss_dice: 0.1241  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 0.0468  decode.d6.loss_dice: 0.1261  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.0476  decode.d7.loss_dice: 0.1292  decode.d8.loss_cls: 0.0257  decode.d8.loss_mask: 0.0484  decode.d8.loss_dice: 0.1186
2024/01/02 22:46:41 - mmengine - INFO - Iter(train) [ 1950/90000]  base_lr: 9.8049e-05 lr: 9.8049e-06  eta: 20:00:46  time: 0.8078  data_time: 0.0077  memory: 14842  grad_norm: 185.6944  loss: 4.3767  decode.loss_cls: 0.0870  decode.loss_mask: 0.1239  decode.loss_dice: 0.2450  decode.d0.loss_cls: 0.0373  decode.d0.loss_mask: 0.1233  decode.d0.loss_dice: 0.2546  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.1230  decode.d1.loss_dice: 0.2332  decode.d2.loss_cls: 0.0454  decode.d2.loss_mask: 0.1261  decode.d2.loss_dice: 0.2521  decode.d3.loss_cls: 0.0983  decode.d3.loss_mask: 0.1203  decode.d3.loss_dice: 0.2386  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.1233  decode.d4.loss_dice: 0.2632  decode.d5.loss_cls: 0.0885  decode.d5.loss_mask: 0.1207  decode.d5.loss_dice: 0.2170  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.1270  decode.d6.loss_dice: 0.2777  decode.d7.loss_cls: 0.0997  decode.d7.loss_mask: 0.1254  decode.d7.loss_dice: 0.2333  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.1250  decode.d8.loss_dice: 0.2693
2024/01/02 22:47:22 - mmengine - INFO - Exp name: mask2former_swin-t_1xb2-90k_soccernet_20240102_220830
2024/01/02 22:47:22 - mmengine - INFO - Iter(train) [ 2000/90000]  base_lr: 9.7999e-05 lr: 9.7999e-06  eta: 19:59:36  time: 0.8051  data_time: 0.0075  memory: 14842  grad_norm: 30.9206  loss: 1.9533  decode.loss_cls: 0.0004  decode.loss_mask: 0.0738  decode.loss_dice: 0.1157  decode.d0.loss_cls: 0.0410  decode.d0.loss_mask: 0.0711  decode.d0.loss_dice: 0.1025  decode.d1.loss_cls: 0.0459  decode.d1.loss_mask: 0.0726  decode.d1.loss_dice: 0.1351  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.0703  decode.d2.loss_dice: 0.1110  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0719  decode.d3.loss_dice: 0.1068  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.0702  decode.d4.loss_dice: 0.1012  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.0728  decode.d5.loss_dice: 0.1059  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0704  decode.d6.loss_dice: 0.1123  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0724  decode.d7.loss_dice: 0.1169  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0740  decode.d8.loss_dice: 0.1275
2024/01/02 22:48:03 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8263  data_time: 0.0078  memory: 9557  
2024/01/02 22:48:38 - mmengine - INFO - per class results:
2024/01/02 22:48:38 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.61 | 99.84 |
|     Billboard      | 89.25 | 91.89 |
|      Goal net      |  64.9 | 89.27 |
+--------------------+-------+-------+
2024/01/02 22:48:38 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.5500  mIoU: 84.5900  mAcc: 93.6700  data_time: 0.0096  time: 0.8197
2024/01/02 22:49:19 - mmengine - INFO - Iter(train) [ 2050/90000]  base_lr: 9.7949e-05 lr: 9.7949e-06  eta: 19:58:37  time: 0.8058  data_time: 0.0075  memory: 14842  grad_norm: 76.6574  loss: 2.3096  decode.loss_cls: 0.0219  decode.loss_mask: 0.0322  decode.loss_dice: 0.1659  decode.d0.loss_cls: 0.0385  decode.d0.loss_mask: 0.0337  decode.d0.loss_dice: 0.1676  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.0321  decode.d1.loss_dice: 0.1736  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.0333  decode.d2.loss_dice: 0.2048  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.0319  decode.d3.loss_dice: 0.1719  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.0324  decode.d4.loss_dice: 0.1786  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.0315  decode.d5.loss_dice: 0.1600  decode.d6.loss_cls: 0.0108  decode.d6.loss_mask: 0.0312  decode.d6.loss_dice: 0.1601  decode.d7.loss_cls: 0.0197  decode.d7.loss_mask: 0.0324  decode.d7.loss_dice: 0.1884  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.0304  decode.d8.loss_dice: 0.1894
2024/01/02 22:49:59 - mmengine - INFO - Iter(train) [ 2100/90000]  base_lr: 9.7899e-05 lr: 9.7899e-06  eta: 19:57:33  time: 0.8051  data_time: 0.0075  memory: 14842  grad_norm: 32.2458  loss: 2.0381  decode.loss_cls: 0.0001  decode.loss_mask: 0.0723  decode.loss_dice: 0.1180  decode.d0.loss_cls: 0.0359  decode.d0.loss_mask: 0.0691  decode.d0.loss_dice: 0.1208  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.0704  decode.d1.loss_dice: 0.1142  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.0695  decode.d2.loss_dice: 0.1158  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.0684  decode.d3.loss_dice: 0.1240  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0679  decode.d4.loss_dice: 0.1241  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0727  decode.d5.loss_dice: 0.1295  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0713  decode.d6.loss_dice: 0.1246  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0747  decode.d7.loss_dice: 0.1192  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0711  decode.d8.loss_dice: 0.1137
2024/01/02 22:50:39 - mmengine - INFO - Iter(train) [ 2150/90000]  base_lr: 9.7848e-05 lr: 9.7848e-06  eta: 19:56:33  time: 0.8041  data_time: 0.0078  memory: 14842  grad_norm: 25.3928  loss: 1.9004  decode.loss_cls: 0.0128  decode.loss_mask: 0.0691  decode.loss_dice: 0.1018  decode.d0.loss_cls: 0.0421  decode.d0.loss_mask: 0.0691  decode.d0.loss_dice: 0.1140  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.0699  decode.d1.loss_dice: 0.1079  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.0687  decode.d2.loss_dice: 0.1080  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.0705  decode.d3.loss_dice: 0.1105  decode.d4.loss_cls: 0.0081  decode.d4.loss_mask: 0.0702  decode.d4.loss_dice: 0.1075  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.0696  decode.d5.loss_dice: 0.1082  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.0711  decode.d6.loss_dice: 0.1054  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.0697  decode.d7.loss_dice: 0.1066  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 0.0689  decode.d8.loss_dice: 0.1103
2024/01/02 22:51:20 - mmengine - INFO - Iter(train) [ 2200/90000]  base_lr: 9.7798e-05 lr: 9.7798e-06  eta: 19:55:28  time: 0.8030  data_time: 0.0074  memory: 14842  grad_norm: 18.4113  loss: 1.6641  decode.loss_cls: 0.0001  decode.loss_mask: 0.0543  decode.loss_dice: 0.0986  decode.d0.loss_cls: 0.0455  decode.d0.loss_mask: 0.0542  decode.d0.loss_dice: 0.1055  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.0559  decode.d1.loss_dice: 0.1027  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.0584  decode.d2.loss_dice: 0.0991  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.0549  decode.d3.loss_dice: 0.1026  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.0573  decode.d4.loss_dice: 0.1084  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.0538  decode.d5.loss_dice: 0.1049  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.0564  decode.d6.loss_dice: 0.1075  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.0552  decode.d7.loss_dice: 0.0986  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0551  decode.d8.loss_dice: 0.1014
2024/01/02 22:52:01 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8255  data_time: 0.0077  memory: 9557  
2024/01/02 22:52:36 - mmengine - INFO - per class results:
2024/01/02 22:52:36 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.58 | 99.89 |
|     Billboard      | 86.42 | 88.75 |
|      Goal net      |  57.6 | 80.15 |
+--------------------+-------+-------+
2024/01/02 22:52:36 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.4700  mIoU: 81.2000  mAcc: 89.6000  data_time: 0.0096  time: 0.8184
2024/01/02 22:53:16 - mmengine - INFO - Iter(train) [ 2250/90000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 19:54:21  time: 0.8026  data_time: 0.0075  memory: 14842  grad_norm: 35.7446  loss: 1.6907  decode.loss_cls: 0.0002  decode.loss_mask: 0.0393  decode.loss_dice: 0.1273  decode.d0.loss_cls: 0.0323  decode.d0.loss_mask: 0.0406  decode.d0.loss_dice: 0.1321  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0404  decode.d1.loss_dice: 0.1213  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0401  decode.d2.loss_dice: 0.1271  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0401  decode.d3.loss_dice: 0.1233  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0402  decode.d4.loss_dice: 0.1292  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0390  decode.d5.loss_dice: 0.1209  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0391  decode.d6.loss_dice: 0.1257  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0402  decode.d7.loss_dice: 0.1331  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.0394  decode.d8.loss_dice: 0.1170
2024/01/02 22:53:57 - mmengine - INFO - Iter(train) [ 2300/90000]  base_lr: 9.7698e-05 lr: 9.7698e-06  eta: 19:53:15  time: 0.8020  data_time: 0.0075  memory: 14842  grad_norm: 17.5298  loss: 1.5312  decode.loss_cls: 0.0092  decode.loss_mask: 0.0459  decode.loss_dice: 0.0961  decode.d0.loss_cls: 0.0341  decode.d0.loss_mask: 0.0480  decode.d0.loss_dice: 0.0969  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0468  decode.d1.loss_dice: 0.1029  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.0464  decode.d2.loss_dice: 0.0986  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.0449  decode.d3.loss_dice: 0.0954  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.0483  decode.d4.loss_dice: 0.0967  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.0483  decode.d5.loss_dice: 0.0983  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.0459  decode.d6.loss_dice: 0.0939  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.0482  decode.d7.loss_dice: 0.1029  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.0488  decode.d8.loss_dice: 0.0977
2024/01/02 22:54:37 - mmengine - INFO - Iter(train) [ 2350/90000]  base_lr: 9.7648e-05 lr: 9.7648e-06  eta: 19:52:10  time: 0.8057  data_time: 0.0076  memory: 14842  grad_norm: 350.9197  loss: inf  decode.loss_cls: 0.0002  decode.loss_mask: inf  decode.loss_dice: 0.1821  decode.d0.loss_cls: 0.1424  decode.d0.loss_mask: 0.1741  decode.d0.loss_dice: 0.1966  decode.d1.loss_cls: 0.1491  decode.d1.loss_mask: 0.3146  decode.d1.loss_dice: 0.1789  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: inf  decode.d2.loss_dice: 0.1830  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: inf  decode.d3.loss_dice: 0.1807  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: inf  decode.d4.loss_dice: 0.1902  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: inf  decode.d5.loss_dice: 0.1843  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: inf  decode.d6.loss_dice: 0.1790  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: inf  decode.d7.loss_dice: 0.1858  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: inf  decode.d8.loss_dice: 0.1819
2024/01/02 22:55:17 - mmengine - INFO - Iter(train) [ 2400/90000]  base_lr: 9.7598e-05 lr: 9.7598e-06  eta: 19:51:10  time: 0.8036  data_time: 0.0075  memory: 14842  grad_norm: 17.0031  loss: 1.5011  decode.loss_cls: 0.0003  decode.loss_mask: 0.0347  decode.loss_dice: 0.1110  decode.d0.loss_cls: 0.0295  decode.d0.loss_mask: 0.0350  decode.d0.loss_dice: 0.1077  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0369  decode.d1.loss_dice: 0.1109  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0372  decode.d2.loss_dice: 0.1168  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0364  decode.d3.loss_dice: 0.1118  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.0364  decode.d4.loss_dice: 0.1066  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0335  decode.d5.loss_dice: 0.1069  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0363  decode.d6.loss_dice: 0.1113  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0367  decode.d7.loss_dice: 0.1139  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0349  decode.d8.loss_dice: 0.1135
2024/01/02 22:55:58 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8256  data_time: 0.0077  memory: 9557  
2024/01/02 22:56:34 - mmengine - INFO - per class results:
2024/01/02 22:56:34 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.48 | 99.91 |
|     Billboard      | 88.99 | 91.25 |
|      Goal net      | 55.02 | 58.05 |
+--------------------+-------+-------+
2024/01/02 22:56:34 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.4900  mIoU: 81.1600  mAcc: 83.0700  data_time: 0.0095  time: 0.8186
2024/01/02 22:57:14 - mmengine - INFO - Iter(train) [ 2450/90000]  base_lr: 9.7548e-05 lr: 9.7548e-06  eta: 19:50:03  time: 0.8045  data_time: 0.0075  memory: 14842  grad_norm: 27.9829  loss: 1.7494  decode.loss_cls: 0.0002  decode.loss_mask: 0.0580  decode.loss_dice: 0.1120  decode.d0.loss_cls: 0.0380  decode.d0.loss_mask: 0.0566  decode.d0.loss_dice: 0.1162  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0570  decode.d1.loss_dice: 0.1131  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.0558  decode.d2.loss_dice: 0.1087  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0563  decode.d3.loss_dice: 0.1127  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0567  decode.d4.loss_dice: 0.1151  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0549  decode.d5.loss_dice: 0.1179  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0569  decode.d6.loss_dice: 0.1148  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0573  decode.d7.loss_dice: 0.1184  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0559  decode.d8.loss_dice: 0.1156
2024/01/02 22:57:54 - mmengine - INFO - Iter(train) [ 2500/90000]  base_lr: 9.7497e-05 lr: 9.7497e-06  eta: 19:48:58  time: 0.8006  data_time: 0.0074  memory: 14842  grad_norm: 26.0235  loss: 2.4083  decode.loss_cls: 0.0700  decode.loss_mask: 0.0392  decode.loss_dice: 0.1385  decode.d0.loss_cls: 0.0326  decode.d0.loss_mask: 0.0401  decode.d0.loss_dice: 0.1461  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.0383  decode.d1.loss_dice: 0.0974  decode.d2.loss_cls: 0.1222  decode.d2.loss_mask: 0.0389  decode.d2.loss_dice: 0.1343  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.0410  decode.d3.loss_dice: 0.1529  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.0389  decode.d4.loss_dice: 0.1118  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.0411  decode.d5.loss_dice: 0.1197  decode.d6.loss_cls: 0.0747  decode.d6.loss_mask: 0.0391  decode.d6.loss_dice: 0.1366  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 0.0403  decode.d7.loss_dice: 0.1071  decode.d8.loss_cls: 0.1094  decode.d8.loss_mask: 0.0394  decode.d8.loss_dice: 0.1563
2024/01/02 22:58:34 - mmengine - INFO - Iter(train) [ 2550/90000]  base_lr: 9.7447e-05 lr: 9.7447e-06  eta: 19:47:55  time: 0.8024  data_time: 0.0074  memory: 14842  grad_norm: 45.0123  loss: 1.6501  decode.loss_cls: 0.0001  decode.loss_mask: 0.0488  decode.loss_dice: 0.1160  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0498  decode.d0.loss_dice: 0.1159  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0487  decode.d1.loss_dice: 0.1005  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0525  decode.d2.loss_dice: 0.1094  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0486  decode.d3.loss_dice: 0.1141  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0478  decode.d4.loss_dice: 0.1100  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.0535  decode.d5.loss_dice: 0.1134  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0478  decode.d6.loss_dice: 0.1097  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0496  decode.d7.loss_dice: 0.1114  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0541  decode.d8.loss_dice: 0.1187
2024/01/02 22:59:14 - mmengine - INFO - Iter(train) [ 2600/90000]  base_lr: 9.7397e-05 lr: 9.7397e-06  eta: 19:46:53  time: 0.8009  data_time: 0.0075  memory: 14842  grad_norm: 11.5756  loss: 1.5307  decode.loss_cls: 0.0000  decode.loss_mask: 0.0461  decode.loss_dice: 0.1031  decode.d0.loss_cls: 0.0299  decode.d0.loss_mask: 0.0462  decode.d0.loss_dice: 0.1011  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0466  decode.d1.loss_dice: 0.1034  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0462  decode.d2.loss_dice: 0.1061  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0482  decode.d3.loss_dice: 0.1005  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0454  decode.d4.loss_dice: 0.1031  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0470  decode.d5.loss_dice: 0.1072  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0470  decode.d6.loss_dice: 0.1032  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0463  decode.d7.loss_dice: 0.0984  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0479  decode.d8.loss_dice: 0.1068
2024/01/02 22:59:55 - mmengine - INFO - Iter(val) [50/93]    eta: 0:00:35  time: 0.8257  data_time: 0.0078  memory: 9557  
2024/01/02 23:00:31 - mmengine - INFO - per class results:
2024/01/02 23:00:31 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards |  99.4 | 99.63 |
|     Billboard      | 90.62 | 92.43 |
|      Goal net      | 42.84 | 87.63 |
+--------------------+-------+-------+
2024/01/02 23:00:31 - mmengine - INFO - Iter(val) [93/93]    aAcc: 99.3600  mIoU: 77.6200  mAcc: 93.2300  data_time: 0.0095  time: 0.8192
2024/01/02 23:01:11 - mmengine - INFO - Iter(train) [ 2650/90000]  base_lr: 9.7347e-05 lr: 9.7347e-06  eta: 19:45:56  time: 0.8060  data_time: 0.0075  memory: 14842  grad_norm: 48.3433  loss: 2.1198  decode.loss_cls: 0.0000  decode.loss_mask: 0.0768  decode.loss_dice: 0.1327  decode.d0.loss_cls: 0.0330  decode.d0.loss_mask: 0.0786  decode.d0.loss_dice: 0.1388  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0761  decode.d1.loss_dice: 0.1325  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0766  decode.d2.loss_dice: 0.1280  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0756  decode.d3.loss_dice: 0.1287  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0758  decode.d4.loss_dice: 0.1348  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0783  decode.d5.loss_dice: 0.1355  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0759  decode.d6.loss_dice: 0.1279  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0752  decode.d7.loss_dice: 0.1312  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0756  decode.d8.loss_dice: 0.1314
2024/01/02 23:01:51 - mmengine - INFO - Iter(train) [ 2700/90000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 19:44:58  time: 0.8023  data_time: 0.0074  memory: 14842  grad_norm: 44.2202  loss: 1.7075  decode.loss_cls: 0.0000  decode.loss_mask: 0.0512  decode.loss_dice: 0.1180  decode.d0.loss_cls: 0.0293  decode.d0.loss_mask: 0.0500  decode.d0.loss_dice: 0.1148  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0513  decode.d1.loss_dice: 0.1183  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0518  decode.d2.loss_dice: 0.1204  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0503  decode.d3.loss_dice: 0.1165  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0496  decode.d4.loss_dice: 0.1182  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0493  decode.d5.loss_dice: 0.1147  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0505  decode.d6.loss_dice: 0.1194  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0508  decode.d7.loss_dice: 0.1155  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0489  decode.d8.loss_dice: 0.1182
