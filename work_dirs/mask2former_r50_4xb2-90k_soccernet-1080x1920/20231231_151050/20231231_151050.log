2023/12/31 15:10:51 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 442767463
    GPU 0: NVIDIA RTX A5000
    CUDA_HOME: None
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 2.1.2+cu118
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2+cu118
    OpenCV: 4.8.1
    MMEngine: 0.10.2

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 442767463
    Distributed launcher: slurm
    Distributed training: True
    GPU number: 1
------------------------------------------------------------

2023/12/31 15:10:51 - mmengine - INFO - Config:
ann_dir = 'Labels'
auto_scale_lr = dict(base_batch_size=8, enable=False)
crop_size = (
    1080,
    1920,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        1080,
        1920,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = 'Dataset'
dataset_type = 'SoccerNet'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_dir = 'Images'
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'slurm'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        deep_stem=False,
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='SyncBN'),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            1080,
            1920,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=3,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 3
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(decay_mult=1.0, lr_mult=0.1),
            level_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=90000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='splits/val.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1920,
                1080,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1920,
        1080,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=90000, type='IterBasedTrainLoop', val_interval=5000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        ann_file='splits/train.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(keep_ratio=True, scale=(
                1920,
                1080,
            ), type='Resize'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(keep_ratio=True, scale=(
        1920,
        1080,
    ), type='Resize'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='splits/val.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1920,
                1080,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/mask2former_r50_4xb2-90k_soccernet-1080x1920'

2023/12/31 15:10:55 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr_mult=0.1
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1e-05
2023/12/31 15:10:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2023/12/31 15:10:57 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2023/12/31 15:10:57 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
2023/12/31 15:10:57 - mmengine - INFO - load model from: torchvision://resnet50
2023/12/31 15:10:57 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
2023/12/31 15:10:58 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023/12/31 15:10:58 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2023/12/31 15:10:58 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2023/12/31 15:10:58 - mmengine - INFO - Checkpoints will be saved to /scratch/users/vgaspar/work_dirs/mask2former_r50_4xb2-90k_soccernet-1080x1920.
2023/12/31 15:11:53 - mmengine - INFO - Iter(train) [   50/90000]  base_lr: 9.9951e-05 lr: 9.9951e-06  eta: 1 day, 3:42:52  time: 0.9918  data_time: 0.0095  memory: 18548  grad_norm: 251.0128  loss: 34.4905  decode.loss_cls: 0.7298  decode.loss_mask: 0.9142  decode.loss_dice: 1.8735  decode.d0.loss_cls: 2.5868  decode.d0.loss_mask: 0.8540  decode.d0.loss_dice: 1.8860  decode.d1.loss_cls: 0.5366  decode.d1.loss_mask: 0.8038  decode.d1.loss_dice: 1.8441  decode.d2.loss_cls: 0.4236  decode.d2.loss_mask: 0.9257  decode.d2.loss_dice: 1.8949  decode.d3.loss_cls: 0.2547  decode.d3.loss_mask: 1.1645  decode.d3.loss_dice: 1.8375  decode.d4.loss_cls: 0.2427  decode.d4.loss_mask: 0.9381  decode.d4.loss_dice: 1.8368  decode.d5.loss_cls: 0.2838  decode.d5.loss_mask: 0.9395  decode.d5.loss_dice: 1.7806  decode.d6.loss_cls: 0.4300  decode.d6.loss_mask: 0.9192  decode.d6.loss_dice: 1.8729  decode.d7.loss_cls: 0.4903  decode.d7.loss_mask: 0.9947  decode.d7.loss_dice: 1.8044  decode.d8.loss_cls: 0.6197  decode.d8.loss_mask: 0.9466  decode.d8.loss_dice: 1.8614
2023/12/31 15:12:43 - mmengine - INFO - Iter(train) [  100/90000]  base_lr: 9.9901e-05 lr: 9.9901e-06  eta: 1 day, 2:17:56  time: 0.9998  data_time: 0.0095  memory: 18545  grad_norm: 151.1804  loss: 21.3086  decode.loss_cls: 0.0532  decode.loss_mask: 0.5937  decode.loss_dice: 1.2720  decode.d0.loss_cls: 2.4178  decode.d0.loss_mask: 0.5259  decode.d0.loss_dice: 1.3067  decode.d1.loss_cls: 0.1950  decode.d1.loss_mask: 0.5397  decode.d1.loss_dice: 1.2484  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.5710  decode.d2.loss_dice: 1.2446  decode.d3.loss_cls: 0.0417  decode.d3.loss_mask: 0.5900  decode.d3.loss_dice: 1.2236  decode.d4.loss_cls: 0.0392  decode.d4.loss_mask: 0.5887  decode.d4.loss_dice: 1.2574  decode.d5.loss_cls: 0.0408  decode.d5.loss_mask: 0.5969  decode.d5.loss_dice: 1.2464  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.5789  decode.d6.loss_dice: 1.2621  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.5906  decode.d7.loss_dice: 1.2596  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.5976  decode.d8.loss_dice: 1.2500
2023/12/31 15:13:33 - mmengine - INFO - Iter(train) [  150/90000]  base_lr: 9.9851e-05 lr: 9.9851e-06  eta: 1 day, 1:52:21  time: 1.0047  data_time: 0.0095  memory: 18547  grad_norm: 174.1157  loss: 13.8066  decode.loss_cls: 0.0427  decode.loss_mask: 0.3810  decode.loss_dice: 0.7347  decode.d0.loss_cls: 2.2499  decode.d0.loss_mask: 0.3451  decode.d0.loss_dice: 0.7559  decode.d1.loss_cls: 0.0966  decode.d1.loss_mask: 0.3703  decode.d1.loss_dice: 0.7090  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.3783  decode.d2.loss_dice: 0.7091  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.3786  decode.d3.loss_dice: 0.7316  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.3859  decode.d4.loss_dice: 0.7360  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.3885  decode.d5.loss_dice: 0.7327  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.3873  decode.d6.loss_dice: 0.7346  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.3821  decode.d7.loss_dice: 0.7352  decode.d8.loss_cls: 0.0402  decode.d8.loss_mask: 0.3857  decode.d8.loss_dice: 0.7239
2023/12/31 15:14:23 - mmengine - INFO - Iter(train) [  200/90000]  base_lr: 9.9801e-05 lr: 9.9801e-06  eta: 1 day, 1:40:04  time: 1.0064  data_time: 0.0100  memory: 18545  grad_norm: 155.1502  loss: 10.9826  decode.loss_cls: 0.0154  decode.loss_mask: 0.3058  decode.loss_dice: 0.5759  decode.d0.loss_cls: 2.0342  decode.d0.loss_mask: 0.2910  decode.d0.loss_dice: 0.5709  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.5630  decode.d2.loss_cls: 0.0229  decode.d2.loss_mask: 0.3146  decode.d2.loss_dice: 0.5648  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.3170  decode.d3.loss_dice: 0.5669  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.3107  decode.d4.loss_dice: 0.5681  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.3077  decode.d5.loss_dice: 0.5626  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.3136  decode.d6.loss_dice: 0.5787  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.3142  decode.d7.loss_dice: 0.5668  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.3083  decode.d8.loss_dice: 0.5736
2023/12/31 15:15:14 - mmengine - INFO - Iter(train) [  250/90000]  base_lr: 9.9751e-05 lr: 9.9751e-06  eta: 1 day, 1:32:47  time: 1.0082  data_time: 0.0101  memory: 18547  grad_norm: 179.4985  loss: 11.3672  decode.loss_cls: 0.0160  decode.loss_mask: 0.2960  decode.loss_dice: 0.6531  decode.d0.loss_cls: 1.8227  decode.d0.loss_mask: 0.2674  decode.d0.loss_dice: 0.6834  decode.d1.loss_cls: 0.0393  decode.d1.loss_mask: 0.2893  decode.d1.loss_dice: 0.6491  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.2916  decode.d2.loss_dice: 0.6426  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.2945  decode.d3.loss_dice: 0.6454  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.2894  decode.d4.loss_dice: 0.6404  decode.d5.loss_cls: 0.0179  decode.d5.loss_mask: 0.2841  decode.d5.loss_dice: 0.6552  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.2860  decode.d6.loss_dice: 0.6372  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.6487  decode.d8.loss_cls: 0.0158  decode.d8.loss_mask: 0.2891  decode.d8.loss_dice: 0.6300
2023/12/31 15:16:04 - mmengine - INFO - Iter(train) [  300/90000]  base_lr: 9.9701e-05 lr: 9.9701e-06  eta: 1 day, 1:27:23  time: 1.0061  data_time: 0.0104  memory: 18545  grad_norm: 105.1879  loss: 7.8548  decode.loss_cls: 0.0057  decode.loss_mask: 0.2218  decode.loss_dice: 0.3985  decode.d0.loss_cls: 1.6030  decode.d0.loss_mask: 0.2047  decode.d0.loss_dice: 0.4146  decode.d1.loss_cls: 0.0197  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.4005  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.2214  decode.d2.loss_dice: 0.4068  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.4013  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2155  decode.d4.loss_dice: 0.3954  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.2134  decode.d5.loss_dice: 0.3927  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.2174  decode.d6.loss_dice: 0.4073  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.2166  decode.d7.loss_dice: 0.3933  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2240  decode.d8.loss_dice: 0.3959
2023/12/31 15:16:54 - mmengine - INFO - Iter(train) [  350/90000]  base_lr: 9.9651e-05 lr: 9.9651e-06  eta: 1 day, 1:23:08  time: 1.0053  data_time: 0.0104  memory: 18547  grad_norm: 91.3135  loss: 7.0305  decode.loss_cls: 0.0127  decode.loss_mask: 0.1888  decode.loss_dice: 0.3596  decode.d0.loss_cls: 1.3563  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.3664  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 0.1955  decode.d1.loss_dice: 0.3622  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.1901  decode.d2.loss_dice: 0.3590  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.1967  decode.d3.loss_dice: 0.3658  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.1940  decode.d4.loss_dice: 0.3577  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.1943  decode.d5.loss_dice: 0.3605  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.1950  decode.d6.loss_dice: 0.3634  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.3625  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.1924  decode.d8.loss_dice: 0.3536
2023/12/31 15:17:45 - mmengine - INFO - Iter(train) [  400/90000]  base_lr: 9.9601e-05 lr: 9.9601e-06  eta: 1 day, 1:20:13  time: 1.0054  data_time: 0.0100  memory: 18545  grad_norm: 156.4984  loss: 9.6631  decode.loss_cls: 0.0813  decode.loss_mask: 0.3692  decode.loss_dice: 0.4461  decode.d0.loss_cls: 1.1379  decode.d0.loss_mask: 0.3573  decode.d0.loss_dice: 0.4454  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.4238  decode.d1.loss_dice: 0.4601  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.4030  decode.d2.loss_dice: 0.4461  decode.d3.loss_cls: 0.0185  decode.d3.loss_mask: 0.3814  decode.d3.loss_dice: 0.4574  decode.d4.loss_cls: 0.0230  decode.d4.loss_mask: 0.3795  decode.d4.loss_dice: 0.4523  decode.d5.loss_cls: 0.0207  decode.d5.loss_mask: 0.3722  decode.d5.loss_dice: 0.4354  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.3844  decode.d6.loss_dice: 0.4440  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.3816  decode.d7.loss_dice: 0.4450  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.3819  decode.d8.loss_dice: 0.4411
2023/12/31 15:18:35 - mmengine - INFO - Iter(train) [  450/90000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 1 day, 1:17:16  time: 1.0055  data_time: 0.0104  memory: 18545  grad_norm: 59.3097  loss: 4.9401  decode.loss_cls: 0.0039  decode.loss_mask: 0.1300  decode.loss_dice: 0.2725  decode.d0.loss_cls: 0.9133  decode.d0.loss_mask: 0.1285  decode.d0.loss_dice: 0.2856  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.1288  decode.d1.loss_dice: 0.2656  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.1264  decode.d2.loss_dice: 0.2633  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.1292  decode.d3.loss_dice: 0.2615  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.1280  decode.d4.loss_dice: 0.2738  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.1208  decode.d5.loss_dice: 0.2680  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.1222  decode.d6.loss_dice: 0.2797  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.1255  decode.d7.loss_dice: 0.2706  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.1286  decode.d8.loss_dice: 0.2701
2023/12/31 15:19:25 - mmengine - INFO - Iter(train) [  500/90000]  base_lr: 9.9501e-05 lr: 9.9501e-06  eta: 1 day, 1:14:42  time: 1.0040  data_time: 0.0107  memory: 18545  grad_norm: 67.7051  loss: 4.8495  decode.loss_cls: 0.0009  decode.loss_mask: 0.1499  decode.loss_dice: 0.2604  decode.d0.loss_cls: 0.7414  decode.d0.loss_mask: 0.1452  decode.d0.loss_dice: 0.2729  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.1450  decode.d1.loss_dice: 0.2534  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.1487  decode.d2.loss_dice: 0.2761  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.1507  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.1505  decode.d4.loss_dice: 0.2529  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.1483  decode.d5.loss_dice: 0.2643  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.1463  decode.d6.loss_dice: 0.2497  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.1512  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.1518  decode.d8.loss_dice: 0.2615
2023/12/31 15:20:16 - mmengine - INFO - Iter(train) [  550/90000]  base_lr: 9.9451e-05 lr: 9.9451e-06  eta: 1 day, 1:12:31  time: 1.0057  data_time: 0.0104  memory: 18545  grad_norm: 49.6164  loss: 4.1733  decode.loss_cls: 0.0025  decode.loss_mask: 0.1270  decode.loss_dice: 0.2313  decode.d0.loss_cls: 0.5906  decode.d0.loss_mask: 0.1235  decode.d0.loss_dice: 0.2265  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.1277  decode.d1.loss_dice: 0.2305  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.1235  decode.d2.loss_dice: 0.2314  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.1256  decode.d3.loss_dice: 0.2253  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.1268  decode.d4.loss_dice: 0.2263  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.1276  decode.d5.loss_dice: 0.2290  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.1287  decode.d6.loss_dice: 0.2295  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.1274  decode.d7.loss_dice: 0.2318  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.1257  decode.d8.loss_dice: 0.2314
2023/12/31 15:21:06 - mmengine - INFO - Iter(train) [  600/90000]  base_lr: 9.9401e-05 lr: 9.9401e-06  eta: 1 day, 1:10:41  time: 1.0065  data_time: 0.0102  memory: 18545  grad_norm: 69.3032  loss: 4.1691  decode.loss_cls: 0.0011  decode.loss_mask: 0.1268  decode.loss_dice: 0.2382  decode.d0.loss_cls: 0.4612  decode.d0.loss_mask: 0.1283  decode.d0.loss_dice: 0.2516  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.1244  decode.d1.loss_dice: 0.2350  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1249  decode.d2.loss_dice: 0.2432  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.1254  decode.d3.loss_dice: 0.2447  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1281  decode.d4.loss_dice: 0.2374  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.1274  decode.d5.loss_dice: 0.2480  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.1260  decode.d6.loss_dice: 0.2344  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.1274  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.1270  decode.d8.loss_dice: 0.2452
2023/12/31 15:21:56 - mmengine - INFO - Iter(train) [  650/90000]  base_lr: 9.9351e-05 lr: 9.9351e-06  eta: 1 day, 1:08:51  time: 1.0061  data_time: 0.0113  memory: 18547  grad_norm: 39.1693  loss: 3.2814  decode.loss_cls: 0.0047  decode.loss_mask: 0.1141  decode.loss_dice: 0.1705  decode.d0.loss_cls: 0.3685  decode.d0.loss_mask: 0.1145  decode.d0.loss_dice: 0.1769  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.1196  decode.d1.loss_dice: 0.1785  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.1162  decode.d2.loss_dice: 0.1733  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.1132  decode.d3.loss_dice: 0.1698  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.1148  decode.d4.loss_dice: 0.1684  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.1196  decode.d5.loss_dice: 0.1757  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.1152  decode.d6.loss_dice: 0.1723  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.1164  decode.d7.loss_dice: 0.1646  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.1145  decode.d8.loss_dice: 0.1649
2023/12/31 15:22:47 - mmengine - INFO - Iter(train) [  700/90000]  base_lr: 9.9301e-05 lr: 9.9301e-06  eta: 1 day, 1:07:15  time: 1.0054  data_time: 0.0109  memory: 18547  grad_norm: 77.6699  loss: 4.5233  decode.loss_cls: 0.0402  decode.loss_mask: 0.1158  decode.loss_dice: 0.2594  decode.d0.loss_cls: 0.2933  decode.d0.loss_mask: 0.1149  decode.d0.loss_dice: 0.2629  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.1131  decode.d1.loss_dice: 0.2491  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.1167  decode.d2.loss_dice: 0.2501  decode.d3.loss_cls: 0.0625  decode.d3.loss_mask: 0.1172  decode.d3.loss_dice: 0.2379  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.1156  decode.d4.loss_dice: 0.2491  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.1166  decode.d5.loss_dice: 0.2602  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.1139  decode.d6.loss_dice: 0.2437  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.1158  decode.d7.loss_dice: 0.2567  decode.d8.loss_cls: 0.1126  decode.d8.loss_mask: 0.1167  decode.d8.loss_dice: 0.2612
2023/12/31 15:23:37 - mmengine - INFO - Iter(train) [  750/90000]  base_lr: 9.9251e-05 lr: 9.9251e-06  eta: 1 day, 1:05:46  time: 1.0056  data_time: 0.0107  memory: 18545  grad_norm: 76.5449  loss: 3.5741  decode.loss_cls: 0.0028  decode.loss_mask: 0.1069  decode.loss_dice: 0.2111  decode.d0.loss_cls: 0.2332  decode.d0.loss_mask: 0.1081  decode.d0.loss_dice: 0.2276  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.1127  decode.d1.loss_dice: 0.2248  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.1137  decode.d2.loss_dice: 0.2256  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.1110  decode.d3.loss_dice: 0.2216  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.1144  decode.d4.loss_dice: 0.2200  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1116  decode.d5.loss_dice: 0.2222  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.1101  decode.d6.loss_dice: 0.2171  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.1106  decode.d7.loss_dice: 0.2191  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.1135  decode.d8.loss_dice: 0.2232
2023/12/31 15:24:27 - mmengine - INFO - Iter(train) [  800/90000]  base_lr: 9.9201e-05 lr: 9.9201e-06  eta: 1 day, 1:04:13  time: 1.0039  data_time: 0.0104  memory: 18547  grad_norm: 113.2613  loss: 4.4250  decode.loss_cls: 0.0010  decode.loss_mask: 0.2203  decode.loss_dice: 0.2071  decode.d0.loss_cls: 0.1914  decode.d0.loss_mask: 0.2220  decode.d0.loss_dice: 0.2040  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2085  decode.d1.loss_dice: 0.2050  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.2078  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2168  decode.d3.loss_dice: 0.2053  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2079  decode.d4.loss_dice: 0.2035  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.2140  decode.d5.loss_dice: 0.2111  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.2126  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2180  decode.d7.loss_dice: 0.2042  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2156  decode.d8.loss_dice: 0.2055
2023/12/31 15:25:17 - mmengine - INFO - Iter(train) [  850/90000]  base_lr: 9.9151e-05 lr: 9.9151e-06  eta: 1 day, 1:02:47  time: 1.0047  data_time: 0.0111  memory: 18545  grad_norm: 36.5326  loss: 2.9312  decode.loss_cls: 0.0024  decode.loss_mask: 0.1152  decode.loss_dice: 0.1531  decode.d0.loss_cls: 0.1686  decode.d0.loss_mask: 0.1178  decode.d0.loss_dice: 0.1535  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.1164  decode.d1.loss_dice: 0.1559  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.1180  decode.d2.loss_dice: 0.1583  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.1162  decode.d3.loss_dice: 0.1554  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.1192  decode.d4.loss_dice: 0.1544  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.1217  decode.d5.loss_dice: 0.1588  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.1197  decode.d6.loss_dice: 0.1573  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.1208  decode.d7.loss_dice: 0.1573  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.1207  decode.d8.loss_dice: 0.1608
2023/12/31 15:26:08 - mmengine - INFO - Iter(train) [  900/90000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 1 day, 1:01:30  time: 1.0058  data_time: 0.0109  memory: 18545  grad_norm: 52.0367  loss: 3.1132  decode.loss_cls: 0.0005  decode.loss_mask: 0.1003  decode.loss_dice: 0.1935  decode.d0.loss_cls: 0.1396  decode.d0.loss_mask: 0.0988  decode.d0.loss_dice: 0.1977  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.0987  decode.d1.loss_dice: 0.1926  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.1009  decode.d2.loss_dice: 0.1926  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.1022  decode.d3.loss_dice: 0.1984  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.0999  decode.d4.loss_dice: 0.1905  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.1041  decode.d5.loss_dice: 0.1980  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.0989  decode.d6.loss_dice: 0.1961  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.0996  decode.d7.loss_dice: 0.2003  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.1028  decode.d8.loss_dice: 0.2008
2023/12/31 15:26:58 - mmengine - INFO - Iter(train) [  950/90000]  base_lr: 9.9050e-05 lr: 9.9050e-06  eta: 1 day, 1:00:12  time: 1.0056  data_time: 0.0113  memory: 18545  grad_norm: 38.5796  loss: 3.0525  decode.loss_cls: 0.0005  decode.loss_mask: 0.1065  decode.loss_dice: 0.1931  decode.d0.loss_cls: 0.1195  decode.d0.loss_mask: 0.1009  decode.d0.loss_dice: 0.1754  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.1003  decode.d1.loss_dice: 0.1795  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.1017  decode.d2.loss_dice: 0.1818  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.1053  decode.d3.loss_dice: 0.1858  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.1063  decode.d4.loss_dice: 0.1888  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.1054  decode.d5.loss_dice: 0.1806  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.1050  decode.d6.loss_dice: 0.1880  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.1063  decode.d7.loss_dice: 0.1798  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.1086  decode.d8.loss_dice: 0.1848
2023/12/31 15:27:48 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 15:27:48 - mmengine - INFO - Iter(train) [ 1000/90000]  base_lr: 9.9000e-05 lr: 9.9000e-06  eta: 1 day, 0:59:01  time: 1.0059  data_time: 0.0111  memory: 18545  grad_norm: 22.6872  loss: 2.3549  decode.loss_cls: 0.0004  decode.loss_mask: 0.0782  decode.loss_dice: 0.1479  decode.d0.loss_cls: 0.1046  decode.d0.loss_mask: 0.0795  decode.d0.loss_dice: 0.1471  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0790  decode.d1.loss_dice: 0.1405  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0774  decode.d2.loss_dice: 0.1432  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0793  decode.d3.loss_dice: 0.1456  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0769  decode.d4.loss_dice: 0.1452  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0804  decode.d5.loss_dice: 0.1472  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0809  decode.d6.loss_dice: 0.1445  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0802  decode.d7.loss_dice: 0.1537  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.0770  decode.d8.loss_dice: 0.1432
2023/12/31 15:28:38 - mmengine - INFO - Iter(train) [ 1050/90000]  base_lr: 9.8950e-05 lr: 9.8950e-06  eta: 1 day, 0:57:51  time: 1.0064  data_time: 0.0115  memory: 18545  grad_norm: 42.6968  loss: 2.7364  decode.loss_cls: 0.0182  decode.loss_mask: 0.0885  decode.loss_dice: 0.1532  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.0839  decode.d0.loss_dice: 0.1574  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 0.0874  decode.d1.loss_dice: 0.1571  decode.d2.loss_cls: 0.0255  decode.d2.loss_mask: 0.0841  decode.d2.loss_dice: 0.1703  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.0844  decode.d3.loss_dice: 0.1497  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.0843  decode.d4.loss_dice: 0.1802  decode.d5.loss_cls: 0.0234  decode.d5.loss_mask: 0.0869  decode.d5.loss_dice: 0.1608  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.0864  decode.d6.loss_dice: 0.1588  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.0889  decode.d7.loss_dice: 0.1594  decode.d8.loss_cls: 0.0338  decode.d8.loss_mask: 0.0863  decode.d8.loss_dice: 0.1612
2023/12/31 15:29:09 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 15:29:29 - mmengine - INFO - Iter(train) [ 1100/90000]  base_lr: 9.8900e-05 lr: 9.8900e-06  eta: 1 day, 0:56:43  time: 1.0069  data_time: 0.0120  memory: 18547  grad_norm: 43.0027  loss: 2.9440  decode.loss_cls: 0.0007  decode.loss_mask: 0.0967  decode.loss_dice: 0.1825  decode.d0.loss_cls: 0.0815  decode.d0.loss_mask: 0.0956  decode.d0.loss_dice: 0.1894  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.0973  decode.d1.loss_dice: 0.1884  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.1003  decode.d2.loss_dice: 0.1938  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.0989  decode.d3.loss_dice: 0.1872  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0973  decode.d4.loss_dice: 0.1773  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.1007  decode.d5.loss_dice: 0.1843  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0996  decode.d6.loss_dice: 0.1926  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.0994  decode.d7.loss_dice: 0.1849  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.0977  decode.d8.loss_dice: 0.1874
2023/12/31 15:30:19 - mmengine - INFO - Iter(train) [ 1150/90000]  base_lr: 9.8850e-05 lr: 9.8850e-06  eta: 1 day, 0:55:34  time: 1.0052  data_time: 0.0109  memory: 18545  grad_norm: 28.8030  loss: 2.5438  decode.loss_cls: 0.0001  decode.loss_mask: 0.0903  decode.loss_dice: 0.1545  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.0904  decode.d0.loss_dice: 0.1577  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.0896  decode.d1.loss_dice: 0.1611  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0902  decode.d2.loss_dice: 0.1576  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0911  decode.d3.loss_dice: 0.1559  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0908  decode.d4.loss_dice: 0.1581  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0885  decode.d5.loss_dice: 0.1521  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0894  decode.d6.loss_dice: 0.1566  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0899  decode.d7.loss_dice: 0.1580  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0884  decode.d8.loss_dice: 0.1611
2023/12/31 15:31:09 - mmengine - INFO - Iter(train) [ 1200/90000]  base_lr: 9.8800e-05 lr: 9.8800e-06  eta: 1 day, 0:54:33  time: 1.0086  data_time: 0.0123  memory: 18545  grad_norm: 20.0138  loss: 2.2763  decode.loss_cls: 0.0001  decode.loss_mask: 0.0843  decode.loss_dice: 0.1395  decode.d0.loss_cls: 0.0619  decode.d0.loss_mask: 0.0826  decode.d0.loss_dice: 0.1397  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.0835  decode.d1.loss_dice: 0.1402  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0817  decode.d2.loss_dice: 0.1403  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0811  decode.d3.loss_dice: 0.1407  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0804  decode.d4.loss_dice: 0.1362  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0832  decode.d5.loss_dice: 0.1369  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0808  decode.d6.loss_dice: 0.1336  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0856  decode.d7.loss_dice: 0.1342  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0832  decode.d8.loss_dice: 0.1381
2023/12/31 15:32:00 - mmengine - INFO - Iter(train) [ 1250/90000]  base_lr: 9.8750e-05 lr: 9.8750e-06  eta: 1 day, 0:53:33  time: 1.0070  data_time: 0.0120  memory: 18545  grad_norm: 19.3088  loss: 1.9901  decode.loss_cls: 0.0001  decode.loss_mask: 0.0711  decode.loss_dice: 0.1247  decode.d0.loss_cls: 0.0611  decode.d0.loss_mask: 0.0665  decode.d0.loss_dice: 0.1222  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0672  decode.d1.loss_dice: 0.1263  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0687  decode.d2.loss_dice: 0.1231  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0683  decode.d3.loss_dice: 0.1245  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0679  decode.d4.loss_dice: 0.1204  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0693  decode.d5.loss_dice: 0.1228  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0690  decode.d6.loss_dice: 0.1275  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0704  decode.d7.loss_dice: 0.1262  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0688  decode.d8.loss_dice: 0.1229
2023/12/31 15:32:50 - mmengine - INFO - Iter(train) [ 1300/90000]  base_lr: 9.8700e-05 lr: 9.8700e-06  eta: 1 day, 0:52:31  time: 1.0067  data_time: 0.0114  memory: 18545  grad_norm: 44.7942  loss: 2.6676  decode.loss_cls: 0.0001  decode.loss_mask: 0.0781  decode.loss_dice: 0.1793  decode.d0.loss_cls: 0.0504  decode.d0.loss_mask: 0.0781  decode.d0.loss_dice: 0.1887  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0787  decode.d1.loss_dice: 0.1845  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0800  decode.d2.loss_dice: 0.1833  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0810  decode.d3.loss_dice: 0.1832  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0779  decode.d4.loss_dice: 0.1803  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0765  decode.d5.loss_dice: 0.1704  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0799  decode.d6.loss_dice: 0.1917  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0797  decode.d7.loss_dice: 0.1828  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0784  decode.d8.loss_dice: 0.1837
2023/12/31 15:33:40 - mmengine - INFO - Iter(train) [ 1350/90000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 1 day, 0:51:32  time: 1.0063  data_time: 0.0120  memory: 18545  grad_norm: 64.1202  loss: 2.8032  decode.loss_cls: 0.0001  decode.loss_mask: 0.0883  decode.loss_dice: 0.1904  decode.d0.loss_cls: 0.0542  decode.d0.loss_mask: 0.0868  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0897  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0881  decode.d2.loss_dice: 0.1894  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0875  decode.d3.loss_dice: 0.1899  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0865  decode.d4.loss_dice: 0.1837  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0855  decode.d5.loss_dice: 0.1830  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0883  decode.d6.loss_dice: 0.1898  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0879  decode.d7.loss_dice: 0.1859  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0879  decode.d8.loss_dice: 0.1814
2023/12/31 15:34:31 - mmengine - INFO - Iter(train) [ 1400/90000]  base_lr: 9.8600e-05 lr: 9.8600e-06  eta: 1 day, 0:50:33  time: 1.0074  data_time: 0.0118  memory: 18545  grad_norm: 16.8172  loss: 2.1003  decode.loss_cls: 0.0027  decode.loss_mask: 0.0661  decode.loss_dice: 0.1393  decode.d0.loss_cls: 0.0504  decode.d0.loss_mask: 0.0668  decode.d0.loss_dice: 0.1435  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0662  decode.d1.loss_dice: 0.1405  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.0651  decode.d2.loss_dice: 0.1360  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0670  decode.d3.loss_dice: 0.1296  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.0657  decode.d4.loss_dice: 0.1361  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.0687  decode.d5.loss_dice: 0.1417  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0667  decode.d6.loss_dice: 0.1380  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.0678  decode.d7.loss_dice: 0.1364  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0651  decode.d8.loss_dice: 0.1371
2023/12/31 15:35:21 - mmengine - INFO - Iter(train) [ 1450/90000]  base_lr: 9.8550e-05 lr: 9.8550e-06  eta: 1 day, 0:49:34  time: 1.0053  data_time: 0.0109  memory: 18547  grad_norm: 111.3464  loss: 4.1654  decode.loss_cls: 0.1277  decode.loss_mask: 0.1554  decode.loss_dice: 0.1961  decode.d0.loss_cls: 0.0500  decode.d0.loss_mask: 0.1663  decode.d0.loss_dice: 0.2153  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.1695  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.1637  decode.d2.loss_dice: 0.2007  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.1615  decode.d3.loss_dice: 0.2009  decode.d4.loss_cls: 0.0459  decode.d4.loss_mask: 0.1611  decode.d4.loss_dice: 0.2069  decode.d5.loss_cls: 0.0472  decode.d5.loss_mask: 0.1609  decode.d5.loss_dice: 0.2039  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.1596  decode.d6.loss_dice: 0.1969  decode.d7.loss_cls: 0.0944  decode.d7.loss_mask: 0.1569  decode.d7.loss_dice: 0.2013  decode.d8.loss_cls: 0.0589  decode.d8.loss_mask: 0.1628  decode.d8.loss_dice: 0.1980
2023/12/31 15:36:11 - mmengine - INFO - Iter(train) [ 1500/90000]  base_lr: 9.8500e-05 lr: 9.8500e-06  eta: 1 day, 0:48:37  time: 1.0069  data_time: 0.0119  memory: 18547  grad_norm: 18.1296  loss: 2.2918  decode.loss_cls: 0.0065  decode.loss_mask: 0.0816  decode.loss_dice: 0.1426  decode.d0.loss_cls: 0.0450  decode.d0.loss_mask: 0.0820  decode.d0.loss_dice: 0.1420  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0819  decode.d1.loss_dice: 0.1495  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.0836  decode.d2.loss_dice: 0.1444  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.0829  decode.d3.loss_dice: 0.1414  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0811  decode.d4.loss_dice: 0.1348  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.0823  decode.d5.loss_dice: 0.1389  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.0801  decode.d6.loss_dice: 0.1360  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.0808  decode.d7.loss_dice: 0.1402  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.0797  decode.d8.loss_dice: 0.1370
2023/12/31 15:37:02 - mmengine - INFO - Iter(train) [ 1550/90000]  base_lr: 9.8450e-05 lr: 9.8450e-06  eta: 1 day, 0:47:38  time: 1.0065  data_time: 0.0117  memory: 18545  grad_norm: 32.3704  loss: 3.7335  decode.loss_cls: 0.0836  decode.loss_mask: 0.0845  decode.loss_dice: 0.2184  decode.d0.loss_cls: 0.0395  decode.d0.loss_mask: 0.0856  decode.d0.loss_dice: 0.2216  decode.d1.loss_cls: 0.0475  decode.d1.loss_mask: 0.0847  decode.d1.loss_dice: 0.2338  decode.d2.loss_cls: 0.0663  decode.d2.loss_mask: 0.0851  decode.d2.loss_dice: 0.2198  decode.d3.loss_cls: 0.0793  decode.d3.loss_mask: 0.0818  decode.d3.loss_dice: 0.2124  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.0841  decode.d4.loss_dice: 0.1570  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.0820  decode.d5.loss_dice: 0.2224  decode.d6.loss_cls: 0.0971  decode.d6.loss_mask: 0.0831  decode.d6.loss_dice: 0.2248  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.0841  decode.d7.loss_dice: 0.2179  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 0.0863  decode.d8.loss_dice: 0.2275
2023/12/31 15:37:52 - mmengine - INFO - Iter(train) [ 1600/90000]  base_lr: 9.8400e-05 lr: 9.8400e-06  eta: 1 day, 0:46:40  time: 1.0057  data_time: 0.0113  memory: 18545  grad_norm: 30.8037  loss: 1.9707  decode.loss_cls: 0.0003  decode.loss_mask: 0.0755  decode.loss_dice: 0.1201  decode.d0.loss_cls: 0.0453  decode.d0.loss_mask: 0.0747  decode.d0.loss_dice: 0.1197  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0749  decode.d1.loss_dice: 0.1205  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0746  decode.d2.loss_dice: 0.1154  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0734  decode.d3.loss_dice: 0.1128  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0755  decode.d4.loss_dice: 0.1221  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0733  decode.d5.loss_dice: 0.1160  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0739  decode.d6.loss_dice: 0.1179  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0740  decode.d7.loss_dice: 0.1164  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0749  decode.d8.loss_dice: 0.1184
2023/12/31 15:38:42 - mmengine - INFO - Iter(train) [ 1650/90000]  base_lr: 9.8349e-05 lr: 9.8349e-06  eta: 1 day, 0:45:43  time: 1.0068  data_time: 0.0117  memory: 18545  grad_norm: 15.0302  loss: 2.0083  decode.loss_cls: 0.0001  decode.loss_mask: 0.0831  decode.loss_dice: 0.1139  decode.d0.loss_cls: 0.0410  decode.d0.loss_mask: 0.0835  decode.d0.loss_dice: 0.1186  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0811  decode.d1.loss_dice: 0.1138  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0811  decode.d2.loss_dice: 0.1097  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0851  decode.d3.loss_dice: 0.1168  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0814  decode.d4.loss_dice: 0.1158  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0821  decode.d5.loss_dice: 0.1086  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0813  decode.d6.loss_dice: 0.1128  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0831  decode.d7.loss_dice: 0.1157  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0822  decode.d8.loss_dice: 0.1167
2023/12/31 15:39:33 - mmengine - INFO - Iter(train) [ 1700/90000]  base_lr: 9.8299e-05 lr: 9.8299e-06  eta: 1 day, 0:44:53  time: 1.0070  data_time: 0.0116  memory: 18547  grad_norm: 42.2724  loss: 3.3034  decode.loss_cls: 0.0614  decode.loss_mask: 0.0797  decode.loss_dice: 0.1618  decode.d0.loss_cls: 0.0400  decode.d0.loss_mask: 0.0760  decode.d0.loss_dice: 0.2067  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.0757  decode.d1.loss_dice: 0.1796  decode.d2.loss_cls: 0.0755  decode.d2.loss_mask: 0.0761  decode.d2.loss_dice: 0.1749  decode.d3.loss_cls: 0.0648  decode.d3.loss_mask: 0.0761  decode.d3.loss_dice: 0.1658  decode.d4.loss_cls: 0.1250  decode.d4.loss_mask: 0.0769  decode.d4.loss_dice: 0.1877  decode.d5.loss_cls: 0.0867  decode.d5.loss_mask: 0.0786  decode.d5.loss_dice: 0.1814  decode.d6.loss_cls: 0.0791  decode.d6.loss_mask: 0.0782  decode.d6.loss_dice: 0.2049  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.0807  decode.d7.loss_dice: 0.1371  decode.d8.loss_cls: 0.0852  decode.d8.loss_mask: 0.0756  decode.d8.loss_dice: 0.1923
2023/12/31 15:40:23 - mmengine - INFO - Iter(train) [ 1750/90000]  base_lr: 9.8249e-05 lr: 9.8249e-06  eta: 1 day, 0:43:59  time: 1.0058  data_time: 0.0115  memory: 18547  grad_norm: 30.7780  loss: 1.8244  decode.loss_cls: 0.0003  decode.loss_mask: 0.0733  decode.loss_dice: 0.1025  decode.d0.loss_cls: 0.0494  decode.d0.loss_mask: 0.0711  decode.d0.loss_dice: 0.1062  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.0719  decode.d1.loss_dice: 0.1005  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.0721  decode.d2.loss_dice: 0.1012  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0736  decode.d3.loss_dice: 0.1007  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0732  decode.d4.loss_dice: 0.1086  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0748  decode.d5.loss_dice: 0.1082  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0749  decode.d6.loss_dice: 0.1069  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0725  decode.d7.loss_dice: 0.1053  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0725  decode.d8.loss_dice: 0.0990
2023/12/31 15:41:14 - mmengine - INFO - Iter(train) [ 1800/90000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 1 day, 0:43:04  time: 1.0059  data_time: 0.0117  memory: 18547  grad_norm: 18.2579  loss: 2.0178  decode.loss_cls: 0.0010  decode.loss_mask: 0.0671  decode.loss_dice: 0.1240  decode.d0.loss_cls: 0.0411  decode.d0.loss_mask: 0.0682  decode.d0.loss_dice: 0.1224  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.0700  decode.d1.loss_dice: 0.1361  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.0696  decode.d2.loss_dice: 0.1271  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.0679  decode.d3.loss_dice: 0.1265  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.0695  decode.d4.loss_dice: 0.1285  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.0678  decode.d5.loss_dice: 0.1190  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.0682  decode.d6.loss_dice: 0.1304  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.0694  decode.d7.loss_dice: 0.1330  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0686  decode.d8.loss_dice: 0.1255
2023/12/31 15:42:04 - mmengine - INFO - Iter(train) [ 1850/90000]  base_lr: 9.8149e-05 lr: 9.8149e-06  eta: 1 day, 0:42:07  time: 1.0056  data_time: 0.0116  memory: 18545  grad_norm: 19.2747  loss: 1.8960  decode.loss_cls: 0.0002  decode.loss_mask: 0.0777  decode.loss_dice: 0.1128  decode.d0.loss_cls: 0.0343  decode.d0.loss_mask: 0.0759  decode.d0.loss_dice: 0.1079  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.0754  decode.d1.loss_dice: 0.1088  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0760  decode.d2.loss_dice: 0.1142  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0759  decode.d3.loss_dice: 0.1120  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0761  decode.d4.loss_dice: 0.1117  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0748  decode.d5.loss_dice: 0.1057  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0768  decode.d6.loss_dice: 0.1093  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.0747  decode.d7.loss_dice: 0.1115  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0758  decode.d8.loss_dice: 0.1049
2023/12/31 15:42:54 - mmengine - INFO - Iter(train) [ 1900/90000]  base_lr: 9.8099e-05 lr: 9.8099e-06  eta: 1 day, 0:41:13  time: 1.0056  data_time: 0.0119  memory: 18547  grad_norm: 13.0245  loss: 1.6954  decode.loss_cls: 0.0004  decode.loss_mask: 0.0603  decode.loss_dice: 0.1053  decode.d0.loss_cls: 0.0335  decode.d0.loss_mask: 0.0615  decode.d0.loss_dice: 0.1056  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.0613  decode.d1.loss_dice: 0.1083  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.0607  decode.d2.loss_dice: 0.1002  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.0598  decode.d3.loss_dice: 0.1024  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.0605  decode.d4.loss_dice: 0.1034  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0608  decode.d5.loss_dice: 0.1019  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.0596  decode.d6.loss_dice: 0.0982  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.0611  decode.d7.loss_dice: 0.1081  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.0618  decode.d8.loss_dice: 0.1087
2023/12/31 15:43:45 - mmengine - INFO - Iter(train) [ 1950/90000]  base_lr: 9.8049e-05 lr: 9.8049e-06  eta: 1 day, 0:40:18  time: 1.0085  data_time: 0.0126  memory: 18547  grad_norm: 92.9505  loss: 1.9206  decode.loss_cls: 0.0001  decode.loss_mask: 0.0751  decode.loss_dice: 0.1120  decode.d0.loss_cls: 0.0377  decode.d0.loss_mask: 0.0765  decode.d0.loss_dice: 0.1112  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0746  decode.d1.loss_dice: 0.1061  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0765  decode.d2.loss_dice: 0.1088  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0768  decode.d3.loss_dice: 0.1130  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0767  decode.d4.loss_dice: 0.1153  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0759  decode.d5.loss_dice: 0.1154  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0756  decode.d6.loss_dice: 0.1166  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0767  decode.d7.loss_dice: 0.1081  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0760  decode.d8.loss_dice: 0.1152
2023/12/31 15:44:35 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 15:44:35 - mmengine - INFO - Iter(train) [ 2000/90000]  base_lr: 9.7999e-05 lr: 9.7999e-06  eta: 1 day, 0:39:25  time: 1.0059  data_time: 0.0118  memory: 18545  grad_norm: 33.2760  loss: 2.3831  decode.loss_cls: 0.0202  decode.loss_mask: 0.0744  decode.loss_dice: 0.1233  decode.d0.loss_cls: 0.0407  decode.d0.loss_mask: 0.0728  decode.d0.loss_dice: 0.1270  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.0749  decode.d1.loss_dice: 0.1386  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.0731  decode.d2.loss_dice: 0.1181  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.0724  decode.d3.loss_dice: 0.1243  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.0716  decode.d4.loss_dice: 0.1187  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.0748  decode.d5.loss_dice: 0.1541  decode.d6.loss_cls: 0.0284  decode.d6.loss_mask: 0.0734  decode.d6.loss_dice: 0.1109  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.0751  decode.d7.loss_dice: 0.1288  decode.d8.loss_cls: 0.1174  decode.d8.loss_mask: 0.0759  decode.d8.loss_dice: 0.1382
2023/12/31 15:45:25 - mmengine - INFO - Iter(train) [ 2050/90000]  base_lr: 9.7949e-05 lr: 9.7949e-06  eta: 1 day, 0:38:32  time: 1.0061  data_time: 0.0123  memory: 18545  grad_norm: 13.0407  loss: 1.8362  decode.loss_cls: 0.0000  decode.loss_mask: 0.0760  decode.loss_dice: 0.1031  decode.d0.loss_cls: 0.0384  decode.d0.loss_mask: 0.0763  decode.d0.loss_dice: 0.1010  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0772  decode.d1.loss_dice: 0.1030  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0757  decode.d2.loss_dice: 0.1019  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0774  decode.d3.loss_dice: 0.1064  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0752  decode.d4.loss_dice: 0.0994  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0784  decode.d5.loss_dice: 0.1050  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0773  decode.d6.loss_dice: 0.1065  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0793  decode.d7.loss_dice: 0.1033  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0753  decode.d8.loss_dice: 0.0993
2023/12/31 15:46:16 - mmengine - INFO - Iter(train) [ 2100/90000]  base_lr: 9.7899e-05 lr: 9.7899e-06  eta: 1 day, 0:37:38  time: 1.0074  data_time: 0.0131  memory: 18545  grad_norm: 18.5970  loss: 1.9617  decode.loss_cls: 0.0003  decode.loss_mask: 0.0708  decode.loss_dice: 0.1277  decode.d0.loss_cls: 0.0337  decode.d0.loss_mask: 0.0695  decode.d0.loss_dice: 0.1175  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0665  decode.d1.loss_dice: 0.1262  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.0690  decode.d2.loss_dice: 0.1269  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0678  decode.d3.loss_dice: 0.1194  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0690  decode.d4.loss_dice: 0.1238  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0705  decode.d5.loss_dice: 0.1258  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0704  decode.d6.loss_dice: 0.1234  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0691  decode.d7.loss_dice: 0.1230  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.0674  decode.d8.loss_dice: 0.1212
2023/12/31 15:47:06 - mmengine - INFO - Iter(train) [ 2150/90000]  base_lr: 9.7848e-05 lr: 9.7848e-06  eta: 1 day, 0:36:44  time: 1.0071  data_time: 0.0124  memory: 18545  grad_norm: 11.1267  loss: 1.7359  decode.loss_cls: 0.0001  decode.loss_mask: 0.0601  decode.loss_dice: 0.1025  decode.d0.loss_cls: 0.0324  decode.d0.loss_mask: 0.0612  decode.d0.loss_dice: 0.1094  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0619  decode.d1.loss_dice: 0.1105  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0626  decode.d2.loss_dice: 0.1096  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0626  decode.d3.loss_dice: 0.1066  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0621  decode.d4.loss_dice: 0.1134  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0617  decode.d5.loss_dice: 0.1107  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0607  decode.d6.loss_dice: 0.1068  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0619  decode.d7.loss_dice: 0.1131  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0602  decode.d8.loss_dice: 0.1053
2023/12/31 15:47:56 - mmengine - INFO - Iter(train) [ 2200/90000]  base_lr: 9.7798e-05 lr: 9.7798e-06  eta: 1 day, 0:35:53  time: 1.0090  data_time: 0.0130  memory: 18547  grad_norm: 15.2283  loss: 2.0068  decode.loss_cls: 0.0002  decode.loss_mask: 0.0623  decode.loss_dice: 0.1326  decode.d0.loss_cls: 0.0271  decode.d0.loss_mask: 0.0621  decode.d0.loss_dice: 0.1296  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.0640  decode.d1.loss_dice: 0.1346  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0621  decode.d2.loss_dice: 0.1323  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0641  decode.d3.loss_dice: 0.1382  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0623  decode.d4.loss_dice: 0.1380  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0613  decode.d5.loss_dice: 0.1336  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0642  decode.d6.loss_dice: 0.1326  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0632  decode.d7.loss_dice: 0.1395  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0639  decode.d8.loss_dice: 0.1369
2023/12/31 15:48:47 - mmengine - INFO - Iter(train) [ 2250/90000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 1 day, 0:34:59  time: 1.0074  data_time: 0.0125  memory: 18545  grad_norm: 54.4428  loss: 2.3620  decode.loss_cls: 0.0000  decode.loss_mask: 0.1021  decode.loss_dice: 0.1282  decode.d0.loss_cls: 0.0367  decode.d0.loss_mask: 0.1039  decode.d0.loss_dice: 0.1290  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0995  decode.d1.loss_dice: 0.1307  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.1018  decode.d2.loss_dice: 0.1294  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.1012  decode.d3.loss_dice: 0.1311  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.1050  decode.d4.loss_dice: 0.1321  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.1032  decode.d5.loss_dice: 0.1284  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0997  decode.d6.loss_dice: 0.1304  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.1009  decode.d7.loss_dice: 0.1316  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.1032  decode.d8.loss_dice: 0.1324
2023/12/31 15:49:37 - mmengine - INFO - Iter(train) [ 2300/90000]  base_lr: 9.7698e-05 lr: 9.7698e-06  eta: 1 day, 0:34:07  time: 1.0067  data_time: 0.0123  memory: 18547  grad_norm: 14.0949  loss: 1.9995  decode.loss_cls: 0.0020  decode.loss_mask: 0.0800  decode.loss_dice: 0.1095  decode.d0.loss_cls: 0.0334  decode.d0.loss_mask: 0.0814  decode.d0.loss_dice: 0.1129  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0837  decode.d1.loss_dice: 0.1135  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.0818  decode.d2.loss_dice: 0.1107  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.0809  decode.d3.loss_dice: 0.1108  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.0826  decode.d4.loss_dice: 0.1155  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.0796  decode.d5.loss_dice: 0.1135  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.0811  decode.d6.loss_dice: 0.1140  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.0847  decode.d7.loss_dice: 0.1144  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.0790  decode.d8.loss_dice: 0.1146
2023/12/31 15:50:28 - mmengine - INFO - Iter(train) [ 2350/90000]  base_lr: 9.7648e-05 lr: 9.7648e-06  eta: 1 day, 0:33:13  time: 1.0067  data_time: 0.0129  memory: 18547  grad_norm: 14.5296  loss: 1.8301  decode.loss_cls: 0.0000  decode.loss_mask: 0.0694  decode.loss_dice: 0.1092  decode.d0.loss_cls: 0.0411  decode.d0.loss_mask: 0.0681  decode.d0.loss_dice: 0.1108  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.0693  decode.d1.loss_dice: 0.1008  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0713  decode.d2.loss_dice: 0.1036  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0709  decode.d3.loss_dice: 0.1077  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0706  decode.d4.loss_dice: 0.1100  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0699  decode.d5.loss_dice: 0.1053  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0731  decode.d6.loss_dice: 0.1116  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0715  decode.d7.loss_dice: 0.1051  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0740  decode.d8.loss_dice: 0.1092
2023/12/31 15:51:18 - mmengine - INFO - Iter(train) [ 2400/90000]  base_lr: 9.7598e-05 lr: 9.7598e-06  eta: 1 day, 0:32:21  time: 1.0078  data_time: 0.0128  memory: 18545  grad_norm: 16.5344  loss: 2.2102  decode.loss_cls: 0.0409  decode.loss_mask: 0.0652  decode.loss_dice: 0.1179  decode.d0.loss_cls: 0.0318  decode.d0.loss_mask: 0.0648  decode.d0.loss_dice: 0.1193  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.0642  decode.d1.loss_dice: 0.1250  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.0629  decode.d2.loss_dice: 0.1009  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.0644  decode.d3.loss_dice: 0.1189  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.0621  decode.d4.loss_dice: 0.1183  decode.d5.loss_cls: 0.0357  decode.d5.loss_mask: 0.0632  decode.d5.loss_dice: 0.1430  decode.d6.loss_cls: 0.0850  decode.d6.loss_mask: 0.0625  decode.d6.loss_dice: 0.1312  decode.d7.loss_cls: 0.0306  decode.d7.loss_mask: 0.0643  decode.d7.loss_dice: 0.1130  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.0630  decode.d8.loss_dice: 0.1175
2023/12/31 15:52:08 - mmengine - INFO - Iter(train) [ 2450/90000]  base_lr: 9.7548e-05 lr: 9.7548e-06  eta: 1 day, 0:31:28  time: 1.0051  data_time: 0.0118  memory: 18547  grad_norm: 18.8082  loss: 1.9932  decode.loss_cls: 0.0001  decode.loss_mask: 0.0864  decode.loss_dice: 0.1076  decode.d0.loss_cls: 0.0370  decode.d0.loss_mask: 0.0875  decode.d0.loss_dice: 0.1040  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.0888  decode.d1.loss_dice: 0.1073  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0853  decode.d2.loss_dice: 0.1095  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0869  decode.d3.loss_dice: 0.1128  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0889  decode.d4.loss_dice: 0.1138  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0860  decode.d5.loss_dice: 0.1061  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0880  decode.d6.loss_dice: 0.1031  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0902  decode.d7.loss_dice: 0.1057  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0868  decode.d8.loss_dice: 0.1096
2023/12/31 15:52:59 - mmengine - INFO - Iter(train) [ 2500/90000]  base_lr: 9.7497e-05 lr: 9.7497e-06  eta: 1 day, 0:30:38  time: 1.0085  data_time: 0.0130  memory: 18545  grad_norm: 14.6912  loss: 1.8433  decode.loss_cls: 0.0003  decode.loss_mask: 0.0622  decode.loss_dice: 0.1233  decode.d0.loss_cls: 0.0338  decode.d0.loss_mask: 0.0603  decode.d0.loss_dice: 0.1225  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0601  decode.d1.loss_dice: 0.1206  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0595  decode.d2.loss_dice: 0.1177  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0591  decode.d3.loss_dice: 0.1150  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0601  decode.d4.loss_dice: 0.1221  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0602  decode.d5.loss_dice: 0.1144  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0605  decode.d6.loss_dice: 0.1274  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0605  decode.d7.loss_dice: 0.1182  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0606  decode.d8.loss_dice: 0.1240
2023/12/31 15:53:49 - mmengine - INFO - Iter(train) [ 2550/90000]  base_lr: 9.7447e-05 lr: 9.7447e-06  eta: 1 day, 0:29:45  time: 1.0076  data_time: 0.0130  memory: 18545  grad_norm: 11.2132  loss: 1.7252  decode.loss_cls: 0.0000  decode.loss_mask: 0.0640  decode.loss_dice: 0.1023  decode.d0.loss_cls: 0.0333  decode.d0.loss_mask: 0.0642  decode.d0.loss_dice: 0.1025  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0662  decode.d1.loss_dice: 0.1058  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0657  decode.d2.loss_dice: 0.1100  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0650  decode.d3.loss_dice: 0.1066  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0654  decode.d4.loss_dice: 0.1055  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0649  decode.d5.loss_dice: 0.1015  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0649  decode.d6.loss_dice: 0.1079  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0642  decode.d7.loss_dice: 0.1012  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0631  decode.d8.loss_dice: 0.1001
2023/12/31 15:54:39 - mmengine - INFO - Iter(train) [ 2600/90000]  base_lr: 9.7397e-05 lr: 9.7397e-06  eta: 1 day, 0:28:53  time: 1.0069  data_time: 0.0117  memory: 18545  grad_norm: 14.3129  loss: 1.7302  decode.loss_cls: 0.0000  decode.loss_mask: 0.0614  decode.loss_dice: 0.1067  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.0598  decode.d0.loss_dice: 0.1063  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0634  decode.d1.loss_dice: 0.1113  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0620  decode.d2.loss_dice: 0.1086  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0609  decode.d3.loss_dice: 0.1035  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0629  decode.d4.loss_dice: 0.1085  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0633  decode.d5.loss_dice: 0.1059  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0628  decode.d6.loss_dice: 0.1102  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0628  decode.d7.loss_dice: 0.1071  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0630  decode.d8.loss_dice: 0.1115
2023/12/31 15:55:30 - mmengine - INFO - Iter(train) [ 2650/90000]  base_lr: 9.7347e-05 lr: 9.7347e-06  eta: 1 day, 0:28:02  time: 1.0084  data_time: 0.0133  memory: 18547  grad_norm: 10.3848  loss: 1.5818  decode.loss_cls: 0.0000  decode.loss_mask: 0.0556  decode.loss_dice: 0.0909  decode.d0.loss_cls: 0.0307  decode.d0.loss_mask: 0.0566  decode.d0.loss_dice: 0.0968  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 0.0584  decode.d1.loss_dice: 0.1078  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0553  decode.d2.loss_dice: 0.0938  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0576  decode.d3.loss_dice: 0.0942  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0561  decode.d4.loss_dice: 0.0897  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0586  decode.d5.loss_dice: 0.1043  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0571  decode.d6.loss_dice: 0.0928  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0545  decode.d7.loss_dice: 0.0872  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0567  decode.d8.loss_dice: 0.0913
2023/12/31 15:56:20 - mmengine - INFO - Iter(train) [ 2700/90000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 1 day, 0:27:09  time: 1.0074  data_time: 0.0128  memory: 18545  grad_norm: 72.3144  loss: 2.3854  decode.loss_cls: 0.0003  decode.loss_mask: 0.1092  decode.loss_dice: 0.1176  decode.d0.loss_cls: 0.0301  decode.d0.loss_mask: 0.1248  decode.d0.loss_dice: 0.1221  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.1141  decode.d1.loss_dice: 0.1270  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.1115  decode.d2.loss_dice: 0.1283  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.1158  decode.d3.loss_dice: 0.1254  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.1129  decode.d4.loss_dice: 0.1146  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.1148  decode.d5.loss_dice: 0.1217  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.1091  decode.d6.loss_dice: 0.1207  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.1100  decode.d7.loss_dice: 0.1210  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.1066  decode.d8.loss_dice: 0.1212
2023/12/31 15:57:11 - mmengine - INFO - Iter(train) [ 2750/90000]  base_lr: 9.7247e-05 lr: 9.7247e-06  eta: 1 day, 0:26:18  time: 1.0080  data_time: 0.0118  memory: 18545  grad_norm: 11.6568  loss: 1.7252  decode.loss_cls: 0.0000  decode.loss_mask: 0.0576  decode.loss_dice: 0.1131  decode.d0.loss_cls: 0.0277  decode.d0.loss_mask: 0.0577  decode.d0.loss_dice: 0.1114  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0582  decode.d1.loss_dice: 0.1151  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0577  decode.d2.loss_dice: 0.1086  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0597  decode.d3.loss_dice: 0.1122  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0582  decode.d4.loss_dice: 0.1100  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0575  decode.d5.loss_dice: 0.1098  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0586  decode.d6.loss_dice: 0.1107  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0569  decode.d7.loss_dice: 0.1141  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0585  decode.d8.loss_dice: 0.1116
2023/12/31 15:58:01 - mmengine - INFO - Iter(train) [ 2800/90000]  base_lr: 9.7197e-05 lr: 9.7197e-06  eta: 1 day, 0:25:25  time: 1.0066  data_time: 0.0124  memory: 18545  grad_norm: 31.9696  loss: 1.8527  decode.loss_cls: 0.0000  decode.loss_mask: 0.0636  decode.loss_dice: 0.1169  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.0646  decode.d0.loss_dice: 0.1181  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0652  decode.d1.loss_dice: 0.1224  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0645  decode.d2.loss_dice: 0.1212  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0639  decode.d3.loss_dice: 0.1197  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0655  decode.d4.loss_dice: 0.1186  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0636  decode.d5.loss_dice: 0.1193  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0623  decode.d6.loss_dice: 0.1115  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0621  decode.d7.loss_dice: 0.1162  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0638  decode.d8.loss_dice: 0.1187
2023/12/31 15:58:51 - mmengine - INFO - Iter(train) [ 2850/90000]  base_lr: 9.7146e-05 lr: 9.7146e-06  eta: 1 day, 0:24:31  time: 1.0062  data_time: 0.0121  memory: 18547  grad_norm: 21.9879  loss: 1.7195  decode.loss_cls: 0.0000  decode.loss_mask: 0.0622  decode.loss_dice: 0.1067  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.0592  decode.d0.loss_dice: 0.1067  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0605  decode.d1.loss_dice: 0.1120  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0607  decode.d2.loss_dice: 0.1052  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0621  decode.d3.loss_dice: 0.1088  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0596  decode.d4.loss_dice: 0.1081  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0625  decode.d5.loss_dice: 0.1105  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0599  decode.d6.loss_dice: 0.1067  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0628  decode.d7.loss_dice: 0.1079  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0614  decode.d8.loss_dice: 0.1074
2023/12/31 15:59:42 - mmengine - INFO - Iter(train) [ 2900/90000]  base_lr: 9.7096e-05 lr: 9.7096e-06  eta: 1 day, 0:23:39  time: 1.0077  data_time: 0.0119  memory: 18545  grad_norm: 19.1903  loss: 1.9185  decode.loss_cls: 0.0000  decode.loss_mask: 0.0740  decode.loss_dice: 0.1145  decode.d0.loss_cls: 0.0259  decode.d0.loss_mask: 0.0730  decode.d0.loss_dice: 0.1198  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.0752  decode.d1.loss_dice: 0.1162  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0745  decode.d2.loss_dice: 0.1165  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0751  decode.d3.loss_dice: 0.1159  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0730  decode.d4.loss_dice: 0.1137  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0743  decode.d5.loss_dice: 0.1168  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0735  decode.d6.loss_dice: 0.1117  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0723  decode.d7.loss_dice: 0.1145  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0722  decode.d8.loss_dice: 0.1141
2023/12/31 16:00:32 - mmengine - INFO - Iter(train) [ 2950/90000]  base_lr: 9.7046e-05 lr: 9.7046e-06  eta: 1 day, 0:22:46  time: 1.0068  data_time: 0.0130  memory: 18545  grad_norm: 26.4415  loss: 2.0450  decode.loss_cls: 0.0009  decode.loss_mask: 0.0706  decode.loss_dice: 0.1318  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.0701  decode.d0.loss_dice: 0.1263  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.0716  decode.d1.loss_dice: 0.1336  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.0706  decode.d2.loss_dice: 0.1314  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.0695  decode.d3.loss_dice: 0.1240  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.0714  decode.d4.loss_dice: 0.1350  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.0702  decode.d5.loss_dice: 0.1292  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.0716  decode.d6.loss_dice: 0.1295  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.0727  decode.d7.loss_dice: 0.1271  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.0722  decode.d8.loss_dice: 0.1314
2023/12/31 16:01:22 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 16:01:22 - mmengine - INFO - Iter(train) [ 3000/90000]  base_lr: 9.6996e-05 lr: 9.6996e-06  eta: 1 day, 0:21:57  time: 1.0077  data_time: 0.0125  memory: 18547  grad_norm: 54.3461  loss: 2.4050  decode.loss_cls: 0.0015  decode.loss_mask: 0.0863  decode.loss_dice: 0.1323  decode.d0.loss_cls: 0.0349  decode.d0.loss_mask: 0.0863  decode.d0.loss_dice: 0.1396  decode.d1.loss_cls: 0.0301  decode.d1.loss_mask: 0.0849  decode.d1.loss_dice: 0.1237  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.0925  decode.d2.loss_dice: 0.1246  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.0868  decode.d3.loss_dice: 0.1311  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.0907  decode.d4.loss_dice: 0.1337  decode.d5.loss_cls: 0.0297  decode.d5.loss_mask: 0.0870  decode.d5.loss_dice: 0.1299  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.0878  decode.d6.loss_dice: 0.1274  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.0858  decode.d7.loss_dice: 0.1563  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 0.0870  decode.d8.loss_dice: 0.1321
2023/12/31 16:02:13 - mmengine - INFO - Iter(train) [ 3050/90000]  base_lr: 9.6946e-05 lr: 9.6946e-06  eta: 1 day, 0:21:05  time: 1.0056  data_time: 0.0118  memory: 18545  grad_norm: 29.3995  loss: 2.1973  decode.loss_cls: 0.0007  decode.loss_mask: 0.0873  decode.loss_dice: 0.1280  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.0893  decode.d0.loss_dice: 0.1362  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.0904  decode.d1.loss_dice: 0.1313  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0884  decode.d2.loss_dice: 0.1321  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.0894  decode.d3.loss_dice: 0.1233  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0876  decode.d4.loss_dice: 0.1239  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0857  decode.d5.loss_dice: 0.1303  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.0874  decode.d6.loss_dice: 0.1259  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0850  decode.d7.loss_dice: 0.1288  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0864  decode.d8.loss_dice: 0.1300
2023/12/31 16:03:03 - mmengine - INFO - Iter(train) [ 3100/90000]  base_lr: 9.6896e-05 lr: 9.6896e-06  eta: 1 day, 0:20:12  time: 1.0069  data_time: 0.0127  memory: 18545  grad_norm: 22.2201  loss: 2.2196  decode.loss_cls: 0.0496  decode.loss_mask: 0.0615  decode.loss_dice: 0.0975  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0621  decode.d0.loss_dice: 0.1113  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.0600  decode.d1.loss_dice: 0.1306  decode.d2.loss_cls: 0.0446  decode.d2.loss_mask: 0.0608  decode.d2.loss_dice: 0.1138  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.0612  decode.d3.loss_dice: 0.0907  decode.d4.loss_cls: 0.0495  decode.d4.loss_mask: 0.0604  decode.d4.loss_dice: 0.0992  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.0608  decode.d5.loss_dice: 0.1119  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.0605  decode.d6.loss_dice: 0.1166  decode.d7.loss_cls: 0.1143  decode.d7.loss_mask: 0.0603  decode.d7.loss_dice: 0.0933  decode.d8.loss_cls: 0.0454  decode.d8.loss_mask: 0.0594  decode.d8.loss_dice: 0.1130
2023/12/31 16:03:53 - mmengine - INFO - Iter(train) [ 3150/90000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 1 day, 0:19:19  time: 1.0058  data_time: 0.0119  memory: 18545  grad_norm: 15.6292  loss: 1.8905  decode.loss_cls: 0.0001  decode.loss_mask: 0.0696  decode.loss_dice: 0.1140  decode.d0.loss_cls: 0.0277  decode.d0.loss_mask: 0.0713  decode.d0.loss_dice: 0.1167  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0712  decode.d1.loss_dice: 0.1157  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0705  decode.d2.loss_dice: 0.1156  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0708  decode.d3.loss_dice: 0.1154  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0715  decode.d4.loss_dice: 0.1145  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0718  decode.d5.loss_dice: 0.1177  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0695  decode.d6.loss_dice: 0.1135  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0720  decode.d7.loss_dice: 0.1179  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0705  decode.d8.loss_dice: 0.1119
2023/12/31 16:04:44 - mmengine - INFO - Iter(train) [ 3200/90000]  base_lr: 9.6795e-05 lr: 9.6795e-06  eta: 1 day, 0:18:27  time: 1.0062  data_time: 0.0114  memory: 18545  grad_norm: 14.1765  loss: 1.6696  decode.loss_cls: 0.0000  decode.loss_mask: 0.0638  decode.loss_dice: 0.0993  decode.d0.loss_cls: 0.0275  decode.d0.loss_mask: 0.0623  decode.d0.loss_dice: 0.1050  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0618  decode.d1.loss_dice: 0.1007  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0620  decode.d2.loss_dice: 0.1004  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0631  decode.d3.loss_dice: 0.1037  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0622  decode.d4.loss_dice: 0.1002  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0636  decode.d5.loss_dice: 0.1062  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0625  decode.d6.loss_dice: 0.0988  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0616  decode.d7.loss_dice: 0.0960  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0636  decode.d8.loss_dice: 0.1049
2023/12/31 16:05:34 - mmengine - INFO - Iter(train) [ 3250/90000]  base_lr: 9.6745e-05 lr: 9.6745e-06  eta: 1 day, 0:17:34  time: 1.0067  data_time: 0.0126  memory: 18545  grad_norm: 8.6432  loss: 1.4703  decode.loss_cls: 0.0000  decode.loss_mask: 0.0593  decode.loss_dice: 0.0796  decode.d0.loss_cls: 0.0290  decode.d0.loss_mask: 0.0606  decode.d0.loss_dice: 0.0858  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.0573  decode.d1.loss_dice: 0.0871  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0598  decode.d2.loss_dice: 0.0862  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0588  decode.d3.loss_dice: 0.0830  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0592  decode.d4.loss_dice: 0.0822  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0600  decode.d5.loss_dice: 0.0917  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0589  decode.d6.loss_dice: 0.0823  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0603  decode.d7.loss_dice: 0.0856  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0594  decode.d8.loss_dice: 0.0832
2023/12/31 16:06:24 - mmengine - INFO - Iter(train) [ 3300/90000]  base_lr: 9.6695e-05 lr: 9.6695e-06  eta: 1 day, 0:16:43  time: 1.0082  data_time: 0.0118  memory: 18547  grad_norm: 21.3332  loss: 2.1303  decode.loss_cls: 0.0000  decode.loss_mask: 0.0894  decode.loss_dice: 0.1169  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.1055  decode.d0.loss_dice: 0.1130  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0922  decode.d1.loss_dice: 0.1115  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0939  decode.d2.loss_dice: 0.1142  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.1001  decode.d3.loss_dice: 0.1129  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0993  decode.d4.loss_dice: 0.1158  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0991  decode.d5.loss_dice: 0.1155  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0943  decode.d6.loss_dice: 0.1122  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0996  decode.d7.loss_dice: 0.1146  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0930  decode.d8.loss_dice: 0.1134
2023/12/31 16:07:15 - mmengine - INFO - Iter(train) [ 3350/90000]  base_lr: 9.6645e-05 lr: 9.6645e-06  eta: 1 day, 0:15:51  time: 1.0057  data_time: 0.0116  memory: 18547  grad_norm: 9.1093  loss: 1.5157  decode.loss_cls: 0.0000  decode.loss_mask: 0.0529  decode.loss_dice: 0.0951  decode.d0.loss_cls: 0.0284  decode.d0.loss_mask: 0.0531  decode.d0.loss_dice: 0.0988  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0544  decode.d1.loss_dice: 0.0944  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0542  decode.d2.loss_dice: 0.0911  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0551  decode.d3.loss_dice: 0.0946  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0552  decode.d4.loss_dice: 0.0939  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0556  decode.d5.loss_dice: 0.0943  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0555  decode.d6.loss_dice: 0.0941  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0543  decode.d7.loss_dice: 0.0931  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0537  decode.d8.loss_dice: 0.0936
2023/12/31 16:08:05 - mmengine - INFO - Iter(train) [ 3400/90000]  base_lr: 9.6594e-05 lr: 9.6594e-06  eta: 1 day, 0:15:00  time: 1.0084  data_time: 0.0128  memory: 18545  grad_norm: 24.5796  loss: 2.0636  decode.loss_cls: 0.0003  decode.loss_mask: 0.0943  decode.loss_dice: 0.1078  decode.d0.loss_cls: 0.0277  decode.d0.loss_mask: 0.0942  decode.d0.loss_dice: 0.1123  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.0939  decode.d1.loss_dice: 0.1109  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0937  decode.d2.loss_dice: 0.1155  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0929  decode.d3.loss_dice: 0.1084  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.0919  decode.d4.loss_dice: 0.1096  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0935  decode.d5.loss_dice: 0.1097  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.0921  decode.d6.loss_dice: 0.1092  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.0925  decode.d7.loss_dice: 0.1059  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0906  decode.d8.loss_dice: 0.1123
2023/12/31 16:08:55 - mmengine - INFO - Iter(train) [ 3450/90000]  base_lr: 9.6544e-05 lr: 9.6544e-06  eta: 1 day, 0:14:08  time: 1.0058  data_time: 0.0115  memory: 18547  grad_norm: 12.5608  loss: 1.6723  decode.loss_cls: 0.0000  decode.loss_mask: 0.0695  decode.loss_dice: 0.0964  decode.d0.loss_cls: 0.0368  decode.d0.loss_mask: 0.0701  decode.d0.loss_dice: 0.0924  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0695  decode.d1.loss_dice: 0.0945  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0658  decode.d2.loss_dice: 0.0890  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0719  decode.d3.loss_dice: 0.1027  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0663  decode.d4.loss_dice: 0.0915  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0659  decode.d5.loss_dice: 0.0938  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0692  decode.d6.loss_dice: 0.0968  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0668  decode.d7.loss_dice: 0.0956  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0689  decode.d8.loss_dice: 0.0984
2023/12/31 16:09:46 - mmengine - INFO - Iter(train) [ 3500/90000]  base_lr: 9.6494e-05 lr: 9.6494e-06  eta: 1 day, 0:13:16  time: 1.0072  data_time: 0.0119  memory: 18547  grad_norm: 13.3521  loss: 1.6237  decode.loss_cls: 0.0000  decode.loss_mask: 0.0621  decode.loss_dice: 0.0979  decode.d0.loss_cls: 0.0341  decode.d0.loss_mask: 0.0610  decode.d0.loss_dice: 0.0989  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.0624  decode.d1.loss_dice: 0.0958  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0619  decode.d2.loss_dice: 0.0971  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0632  decode.d3.loss_dice: 0.0936  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0634  decode.d4.loss_dice: 0.0941  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0609  decode.d5.loss_dice: 0.0961  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0612  decode.d6.loss_dice: 0.0984  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0635  decode.d7.loss_dice: 0.0968  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0625  decode.d8.loss_dice: 0.0955
2023/12/31 16:10:36 - mmengine - INFO - Iter(train) [ 3550/90000]  base_lr: 9.6444e-05 lr: 9.6444e-06  eta: 1 day, 0:12:24  time: 1.0063  data_time: 0.0118  memory: 18545  grad_norm: 14.2370  loss: 1.3968  decode.loss_cls: 0.0001  decode.loss_mask: 0.0550  decode.loss_dice: 0.0855  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.0552  decode.d0.loss_dice: 0.0828  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0549  decode.d1.loss_dice: 0.0766  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0527  decode.d2.loss_dice: 0.0779  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0560  decode.d3.loss_dice: 0.0869  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0563  decode.d4.loss_dice: 0.0817  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0555  decode.d5.loss_dice: 0.0836  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0551  decode.d6.loss_dice: 0.0821  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0540  decode.d7.loss_dice: 0.0790  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0554  decode.d8.loss_dice: 0.0816
2023/12/31 16:11:26 - mmengine - INFO - Iter(train) [ 3600/90000]  base_lr: 9.6394e-05 lr: 9.6394e-06  eta: 1 day, 0:11:32  time: 1.0062  data_time: 0.0113  memory: 18547  grad_norm: 13.5928  loss: 1.4928  decode.loss_cls: 0.0000  decode.loss_mask: 0.0571  decode.loss_dice: 0.0824  decode.d0.loss_cls: 0.0308  decode.d0.loss_mask: 0.0580  decode.d0.loss_dice: 0.0866  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0587  decode.d1.loss_dice: 0.0889  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0581  decode.d2.loss_dice: 0.0875  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0583  decode.d3.loss_dice: 0.0947  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0588  decode.d4.loss_dice: 0.0900  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0591  decode.d5.loss_dice: 0.0890  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0589  decode.d6.loss_dice: 0.0904  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0584  decode.d7.loss_dice: 0.0860  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0573  decode.d8.loss_dice: 0.0836
2023/12/31 16:12:17 - mmengine - INFO - Iter(train) [ 3650/90000]  base_lr: 9.6343e-05 lr: 9.6343e-06  eta: 1 day, 0:10:41  time: 1.0071  data_time: 0.0119  memory: 18545  grad_norm: 21.7605  loss: 1.6057  decode.loss_cls: 0.0001  decode.loss_mask: 0.0547  decode.loss_dice: 0.0972  decode.d0.loss_cls: 0.0272  decode.d0.loss_mask: 0.0577  decode.d0.loss_dice: 0.1044  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0564  decode.d1.loss_dice: 0.1007  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0568  decode.d2.loss_dice: 0.1011  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0547  decode.d3.loss_dice: 0.0989  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0579  decode.d4.loss_dice: 0.1031  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0565  decode.d5.loss_dice: 0.1032  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0562  decode.d6.loss_dice: 0.0992  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0565  decode.d7.loss_dice: 0.1071  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0547  decode.d8.loss_dice: 0.1006
2023/12/31 16:13:07 - mmengine - INFO - Iter(train) [ 3700/90000]  base_lr: 9.6293e-05 lr: 9.6293e-06  eta: 1 day, 0:09:48  time: 1.0065  data_time: 0.0118  memory: 18545  grad_norm: 15.1040  loss: 1.6806  decode.loss_cls: 0.0000  decode.loss_mask: 0.0560  decode.loss_dice: 0.1093  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.0575  decode.d0.loss_dice: 0.1116  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0573  decode.d1.loss_dice: 0.1073  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0561  decode.d2.loss_dice: 0.1065  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0565  decode.d3.loss_dice: 0.1066  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0585  decode.d4.loss_dice: 0.1115  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0576  decode.d5.loss_dice: 0.1095  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0562  decode.d6.loss_dice: 0.1023  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0581  decode.d7.loss_dice: 0.1069  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0570  decode.d8.loss_dice: 0.1097
2023/12/31 16:13:58 - mmengine - INFO - Iter(train) [ 3750/90000]  base_lr: 9.6243e-05 lr: 9.6243e-06  eta: 1 day, 0:08:58  time: 1.0077  data_time: 0.0116  memory: 18545  grad_norm: 25.4799  loss: 1.8389  decode.loss_cls: 0.0000  decode.loss_mask: 0.0716  decode.loss_dice: 0.1044  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.0745  decode.d0.loss_dice: 0.1075  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.0721  decode.d1.loss_dice: 0.1062  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0740  decode.d2.loss_dice: 0.1053  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0739  decode.d3.loss_dice: 0.1084  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0731  decode.d4.loss_dice: 0.1045  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0725  decode.d5.loss_dice: 0.1091  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0745  decode.d6.loss_dice: 0.1081  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0724  decode.d7.loss_dice: 0.1081  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0723  decode.d8.loss_dice: 0.1041
2023/12/31 16:14:48 - mmengine - INFO - Iter(train) [ 3800/90000]  base_lr: 9.6193e-05 lr: 9.6193e-06  eta: 1 day, 0:08:08  time: 1.0082  data_time: 0.0126  memory: 18545  grad_norm: 10.1973  loss: 1.7224  decode.loss_cls: 0.0000  decode.loss_mask: 0.0584  decode.loss_dice: 0.1076  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.0601  decode.d0.loss_dice: 0.1134  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0600  decode.d1.loss_dice: 0.1053  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0601  decode.d2.loss_dice: 0.1162  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0587  decode.d3.loss_dice: 0.1087  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0586  decode.d4.loss_dice: 0.1072  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0607  decode.d5.loss_dice: 0.1116  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0607  decode.d6.loss_dice: 0.1099  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0582  decode.d7.loss_dice: 0.1104  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0579  decode.d8.loss_dice: 0.1096
2023/12/31 16:15:38 - mmengine - INFO - Iter(train) [ 3850/90000]  base_lr: 9.6143e-05 lr: 9.6143e-06  eta: 1 day, 0:07:17  time: 1.0084  data_time: 0.0125  memory: 18545  grad_norm: 13.1532  loss: 1.5892  decode.loss_cls: 0.0000  decode.loss_mask: 0.0598  decode.loss_dice: 0.1013  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0577  decode.d0.loss_dice: 0.0967  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0583  decode.d1.loss_dice: 0.0972  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0576  decode.d2.loss_dice: 0.0987  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0581  decode.d3.loss_dice: 0.0963  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0579  decode.d4.loss_dice: 0.0978  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0576  decode.d5.loss_dice: 0.0987  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0589  decode.d6.loss_dice: 0.0994  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0578  decode.d7.loss_dice: 0.1008  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0573  decode.d8.loss_dice: 0.0960
2023/12/31 16:16:29 - mmengine - INFO - Iter(train) [ 3900/90000]  base_lr: 9.6092e-05 lr: 9.6092e-06  eta: 1 day, 0:06:26  time: 1.0071  data_time: 0.0118  memory: 18545  grad_norm: 18.1094  loss: 1.8127  decode.loss_cls: 0.0000  decode.loss_mask: 0.0715  decode.loss_dice: 0.1068  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0708  decode.d0.loss_dice: 0.1122  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0705  decode.d1.loss_dice: 0.1016  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0702  decode.d2.loss_dice: 0.1077  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0700  decode.d3.loss_dice: 0.1131  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0704  decode.d4.loss_dice: 0.1084  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0706  decode.d5.loss_dice: 0.1104  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0723  decode.d6.loss_dice: 0.1077  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0700  decode.d7.loss_dice: 0.1086  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0690  decode.d8.loss_dice: 0.1058
2023/12/31 16:17:19 - mmengine - INFO - Iter(train) [ 3950/90000]  base_lr: 9.6042e-05 lr: 9.6042e-06  eta: 1 day, 0:05:37  time: 1.0092  data_time: 0.0127  memory: 18547  grad_norm: 11.5311  loss: 1.7165  decode.loss_cls: 0.0000  decode.loss_mask: 0.0633  decode.loss_dice: 0.1091  decode.d0.loss_cls: 0.0296  decode.d0.loss_mask: 0.0666  decode.d0.loss_dice: 0.1008  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.0656  decode.d1.loss_dice: 0.1058  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0634  decode.d2.loss_dice: 0.1030  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0638  decode.d3.loss_dice: 0.0980  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0636  decode.d4.loss_dice: 0.1018  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0633  decode.d5.loss_dice: 0.0992  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0648  decode.d6.loss_dice: 0.1018  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0631  decode.d7.loss_dice: 0.1023  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0654  decode.d8.loss_dice: 0.1044
2023/12/31 16:18:10 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 16:18:10 - mmengine - INFO - Iter(train) [ 4000/90000]  base_lr: 9.5992e-05 lr: 9.5992e-06  eta: 1 day, 0:04:47  time: 1.0095  data_time: 0.0130  memory: 18545  grad_norm: 10.9510  loss: 1.7181  decode.loss_cls: 0.0019  decode.loss_mask: 0.0581  decode.loss_dice: 0.1127  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.0577  decode.d0.loss_dice: 0.1161  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0566  decode.d1.loss_dice: 0.1117  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.0562  decode.d2.loss_dice: 0.1096  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.0568  decode.d3.loss_dice: 0.1138  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.0566  decode.d4.loss_dice: 0.1090  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.0548  decode.d5.loss_dice: 0.1101  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.0566  decode.d6.loss_dice: 0.1100  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0570  decode.d7.loss_dice: 0.1131  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.0553  decode.d8.loss_dice: 0.1068
2023/12/31 16:19:00 - mmengine - INFO - Iter(train) [ 4050/90000]  base_lr: 9.5942e-05 lr: 9.5942e-06  eta: 1 day, 0:03:55  time: 1.0054  data_time: 0.0122  memory: 18545  grad_norm: 11.7749  loss: 1.5255  decode.loss_cls: 0.0001  decode.loss_mask: 0.0526  decode.loss_dice: 0.0967  decode.d0.loss_cls: 0.0292  decode.d0.loss_mask: 0.0539  decode.d0.loss_dice: 0.1005  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0524  decode.d1.loss_dice: 0.0912  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0544  decode.d2.loss_dice: 0.0983  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0525  decode.d3.loss_dice: 0.0952  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0534  decode.d4.loss_dice: 0.0946  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0521  decode.d5.loss_dice: 0.0955  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0550  decode.d6.loss_dice: 0.1002  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0545  decode.d7.loss_dice: 0.0922  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0534  decode.d8.loss_dice: 0.0967
2023/12/31 16:19:50 - mmengine - INFO - Iter(train) [ 4100/90000]  base_lr: 9.5891e-05 lr: 9.5891e-06  eta: 1 day, 0:03:04  time: 1.0083  data_time: 0.0136  memory: 18547  grad_norm: 8.3789  loss: 1.4259  decode.loss_cls: 0.0003  decode.loss_mask: 0.0654  decode.loss_dice: 0.0725  decode.d0.loss_cls: 0.0397  decode.d0.loss_mask: 0.0647  decode.d0.loss_dice: 0.0754  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.0626  decode.d1.loss_dice: 0.0723  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0641  decode.d2.loss_dice: 0.0718  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0648  decode.d3.loss_dice: 0.0705  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0656  decode.d4.loss_dice: 0.0745  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0646  decode.d5.loss_dice: 0.0750  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0650  decode.d6.loss_dice: 0.0747  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.0630  decode.d7.loss_dice: 0.0705  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0668  decode.d8.loss_dice: 0.0779
2023/12/31 16:20:41 - mmengine - INFO - Iter(train) [ 4150/90000]  base_lr: 9.5841e-05 lr: 9.5841e-06  eta: 1 day, 0:02:14  time: 1.0077  data_time: 0.0129  memory: 18545  grad_norm: 10.8563  loss: 1.7562  decode.loss_cls: 0.0001  decode.loss_mask: 0.0642  decode.loss_dice: 0.1124  decode.d0.loss_cls: 0.0274  decode.d0.loss_mask: 0.0636  decode.d0.loss_dice: 0.1107  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0635  decode.d1.loss_dice: 0.1145  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0620  decode.d2.loss_dice: 0.1062  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0636  decode.d3.loss_dice: 0.1099  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0617  decode.d4.loss_dice: 0.1109  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0630  decode.d5.loss_dice: 0.1075  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0626  decode.d6.loss_dice: 0.1050  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0622  decode.d7.loss_dice: 0.1128  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0632  decode.d8.loss_dice: 0.1086
2023/12/31 16:21:31 - mmengine - INFO - Iter(train) [ 4200/90000]  base_lr: 9.5791e-05 lr: 9.5791e-06  eta: 1 day, 0:01:25  time: 1.0102  data_time: 0.0128  memory: 18547  grad_norm: 8.4525  loss: 1.4648  decode.loss_cls: 0.0000  decode.loss_mask: 0.0514  decode.loss_dice: 0.0948  decode.d0.loss_cls: 0.0216  decode.d0.loss_mask: 0.0509  decode.d0.loss_dice: 0.0905  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0512  decode.d1.loss_dice: 0.0915  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0505  decode.d2.loss_dice: 0.0961  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0516  decode.d3.loss_dice: 0.0909  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0536  decode.d4.loss_dice: 0.1009  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0511  decode.d5.loss_dice: 0.0900  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0517  decode.d6.loss_dice: 0.0909  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0515  decode.d7.loss_dice: 0.0907  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0516  decode.d8.loss_dice: 0.0913
2023/12/31 16:22:22 - mmengine - INFO - Iter(train) [ 4250/90000]  base_lr: 9.5741e-05 lr: 9.5741e-06  eta: 1 day, 0:00:35  time: 1.0082  data_time: 0.0124  memory: 18545  grad_norm: 22.1042  loss: 1.4949  decode.loss_cls: 0.0003  decode.loss_mask: 0.0523  decode.loss_dice: 0.0946  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.0532  decode.d0.loss_dice: 0.0986  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.0520  decode.d1.loss_dice: 0.0977  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0513  decode.d2.loss_dice: 0.0886  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0521  decode.d3.loss_dice: 0.0950  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0512  decode.d4.loss_dice: 0.0972  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0520  decode.d5.loss_dice: 0.1009  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0519  decode.d6.loss_dice: 0.0939  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0524  decode.d7.loss_dice: 0.0902  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0503  decode.d8.loss_dice: 0.0905
2023/12/31 16:23:12 - mmengine - INFO - Iter(train) [ 4300/90000]  base_lr: 9.5691e-05 lr: 9.5691e-06  eta: 23:59:45  time: 1.0072  data_time: 0.0128  memory: 18545  grad_norm: 10.2952  loss: 1.6657  decode.loss_cls: 0.0001  decode.loss_mask: 0.0610  decode.loss_dice: 0.1029  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.0616  decode.d0.loss_dice: 0.1015  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0593  decode.d1.loss_dice: 0.1037  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0613  decode.d2.loss_dice: 0.1051  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0617  decode.d3.loss_dice: 0.1027  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0612  decode.d4.loss_dice: 0.0979  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0617  decode.d5.loss_dice: 0.1036  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0604  decode.d6.loss_dice: 0.1025  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0604  decode.d7.loss_dice: 0.1066  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0628  decode.d8.loss_dice: 0.1009
2023/12/31 16:24:02 - mmengine - INFO - Iter(train) [ 4350/90000]  base_lr: 9.5640e-05 lr: 9.5640e-06  eta: 23:58:54  time: 1.0068  data_time: 0.0118  memory: 18545  grad_norm: 13.0488  loss: 2.0810  decode.loss_cls: 0.0437  decode.loss_mask: 0.0557  decode.loss_dice: 0.0936  decode.d0.loss_cls: 0.0219  decode.d0.loss_mask: 0.0542  decode.d0.loss_dice: 0.1158  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.0544  decode.d1.loss_dice: 0.0990  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.0549  decode.d2.loss_dice: 0.1164  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.0562  decode.d3.loss_dice: 0.1130  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.0559  decode.d4.loss_dice: 0.1480  decode.d5.loss_cls: 0.0808  decode.d5.loss_mask: 0.0578  decode.d5.loss_dice: 0.1091  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.0534  decode.d6.loss_dice: 0.0960  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.0545  decode.d7.loss_dice: 0.0948  decode.d8.loss_cls: 0.0398  decode.d8.loss_mask: 0.0557  decode.d8.loss_dice: 0.0920
2023/12/31 16:24:53 - mmengine - INFO - Iter(train) [ 4400/90000]  base_lr: 9.5590e-05 lr: 9.5590e-06  eta: 23:58:03  time: 1.0059  data_time: 0.0123  memory: 18545  grad_norm: 6.8940  loss: 1.3767  decode.loss_cls: 0.0008  decode.loss_mask: 0.0525  decode.loss_dice: 0.0802  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0527  decode.d0.loss_dice: 0.0821  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0525  decode.d1.loss_dice: 0.0784  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.0521  decode.d2.loss_dice: 0.0817  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.0530  decode.d3.loss_dice: 0.0816  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.0531  decode.d4.loss_dice: 0.0828  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0531  decode.d5.loss_dice: 0.0819  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.0534  decode.d6.loss_dice: 0.0825  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.0528  decode.d7.loss_dice: 0.0809  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.0529  decode.d8.loss_dice: 0.0839
2023/12/31 16:25:43 - mmengine - INFO - Iter(train) [ 4450/90000]  base_lr: 9.5540e-05 lr: 9.5540e-06  eta: 23:57:11  time: 1.0086  data_time: 0.0124  memory: 18545  grad_norm: 5.4486  loss: 1.3282  decode.loss_cls: 0.0001  decode.loss_mask: 0.0524  decode.loss_dice: 0.0800  decode.d0.loss_cls: 0.0259  decode.d0.loss_mask: 0.0531  decode.d0.loss_dice: 0.0820  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0522  decode.d1.loss_dice: 0.0789  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0512  decode.d2.loss_dice: 0.0775  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0524  decode.d3.loss_dice: 0.0770  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0515  decode.d4.loss_dice: 0.0798  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0522  decode.d5.loss_dice: 0.0784  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0529  decode.d6.loss_dice: 0.0754  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0520  decode.d7.loss_dice: 0.0756  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0516  decode.d8.loss_dice: 0.0753
2023/12/31 16:26:33 - mmengine - INFO - Iter(train) [ 4500/90000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 23:56:21  time: 1.0059  data_time: 0.0114  memory: 18545  grad_norm: 7.9098  loss: 1.4216  decode.loss_cls: 0.0002  decode.loss_mask: 0.0560  decode.loss_dice: 0.0877  decode.d0.loss_cls: 0.0379  decode.d0.loss_mask: 0.0544  decode.d0.loss_dice: 0.0809  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.0571  decode.d1.loss_dice: 0.0883  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0560  decode.d2.loss_dice: 0.0811  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0546  decode.d3.loss_dice: 0.0800  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0549  decode.d4.loss_dice: 0.0843  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0565  decode.d5.loss_dice: 0.0829  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0539  decode.d6.loss_dice: 0.0804  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0539  decode.d7.loss_dice: 0.0805  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0561  decode.d8.loss_dice: 0.0817
2023/12/31 16:27:24 - mmengine - INFO - Iter(train) [ 4550/90000]  base_lr: 9.5439e-05 lr: 9.5439e-06  eta: 23:55:30  time: 1.0063  data_time: 0.0121  memory: 18545  grad_norm: 49.1192  loss: 1.7501  decode.loss_cls: 0.0000  decode.loss_mask: 0.0521  decode.loss_dice: 0.1177  decode.d0.loss_cls: 0.0257  decode.d0.loss_mask: 0.0520  decode.d0.loss_dice: 0.1228  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0520  decode.d1.loss_dice: 0.1270  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0504  decode.d2.loss_dice: 0.1235  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0522  decode.d3.loss_dice: 0.1267  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0508  decode.d4.loss_dice: 0.1168  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0514  decode.d5.loss_dice: 0.1260  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0501  decode.d6.loss_dice: 0.1155  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0505  decode.d7.loss_dice: 0.1172  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0497  decode.d8.loss_dice: 0.1193
2023/12/31 16:28:14 - mmengine - INFO - Iter(train) [ 4600/90000]  base_lr: 9.5389e-05 lr: 9.5389e-06  eta: 23:54:39  time: 1.0092  data_time: 0.0127  memory: 18545  grad_norm: 47.5481  loss: 2.2496  decode.loss_cls: 0.0004  decode.loss_mask: 0.0682  decode.loss_dice: 0.1544  decode.d0.loss_cls: 0.0204  decode.d0.loss_mask: 0.0670  decode.d0.loss_dice: 0.1538  decode.d1.loss_cls: 0.0231  decode.d1.loss_mask: 0.0682  decode.d1.loss_dice: 0.1531  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0684  decode.d2.loss_dice: 0.1597  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0695  decode.d3.loss_dice: 0.1440  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.0690  decode.d4.loss_dice: 0.1537  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0669  decode.d5.loss_dice: 0.1469  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0656  decode.d6.loss_dice: 0.1448  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.0707  decode.d7.loss_dice: 0.1528  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0657  decode.d8.loss_dice: 0.1600
2023/12/31 16:29:05 - mmengine - INFO - Iter(train) [ 4650/90000]  base_lr: 9.5339e-05 lr: 9.5339e-06  eta: 23:53:49  time: 1.0074  data_time: 0.0116  memory: 18545  grad_norm: 25.2554  loss: 1.8041  decode.loss_cls: 0.0023  decode.loss_mask: 0.0560  decode.loss_dice: 0.1223  decode.d0.loss_cls: 0.0203  decode.d0.loss_mask: 0.0558  decode.d0.loss_dice: 0.1119  decode.d1.loss_cls: 0.0274  decode.d1.loss_mask: 0.0550  decode.d1.loss_dice: 0.1092  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.0543  decode.d2.loss_dice: 0.1370  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0557  decode.d3.loss_dice: 0.1388  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0556  decode.d4.loss_dice: 0.0977  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.0541  decode.d5.loss_dice: 0.1317  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0538  decode.d6.loss_dice: 0.1030  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0568  decode.d7.loss_dice: 0.1004  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.0543  decode.d8.loss_dice: 0.0947
2023/12/31 16:29:55 - mmengine - INFO - Iter(train) [ 4700/90000]  base_lr: 9.5288e-05 lr: 9.5288e-06  eta: 23:52:57  time: 1.0068  data_time: 0.0128  memory: 18545  grad_norm: 6.4906  loss: 1.3771  decode.loss_cls: 0.0001  decode.loss_mask: 0.0542  decode.loss_dice: 0.0861  decode.d0.loss_cls: 0.0311  decode.d0.loss_mask: 0.0528  decode.d0.loss_dice: 0.0855  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0522  decode.d1.loss_dice: 0.0838  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0540  decode.d2.loss_dice: 0.0781  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0529  decode.d3.loss_dice: 0.0784  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0529  decode.d4.loss_dice: 0.0800  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0532  decode.d5.loss_dice: 0.0875  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0522  decode.d6.loss_dice: 0.0817  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0530  decode.d7.loss_dice: 0.0772  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0517  decode.d8.loss_dice: 0.0773
2023/12/31 16:30:45 - mmengine - INFO - Iter(train) [ 4750/90000]  base_lr: 9.5238e-05 lr: 9.5238e-06  eta: 23:52:06  time: 1.0088  data_time: 0.0130  memory: 18545  grad_norm: 9.8182  loss: 1.5598  decode.loss_cls: 0.0000  decode.loss_mask: 0.0506  decode.loss_dice: 0.1018  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.0515  decode.d0.loss_dice: 0.1041  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0510  decode.d1.loss_dice: 0.0979  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0518  decode.d2.loss_dice: 0.1040  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0519  decode.d3.loss_dice: 0.1007  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0530  decode.d4.loss_dice: 0.1044  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0521  decode.d5.loss_dice: 0.1040  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0530  decode.d6.loss_dice: 0.0952  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0516  decode.d7.loss_dice: 0.1018  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0516  decode.d8.loss_dice: 0.1028
2023/12/31 16:31:36 - mmengine - INFO - Iter(train) [ 4800/90000]  base_lr: 9.5188e-05 lr: 9.5188e-06  eta: 23:51:14  time: 1.0058  data_time: 0.0115  memory: 18547  grad_norm: 8.0645  loss: 1.4204  decode.loss_cls: 0.0000  decode.loss_mask: 0.0538  decode.loss_dice: 0.0871  decode.d0.loss_cls: 0.0273  decode.d0.loss_mask: 0.0514  decode.d0.loss_dice: 0.0834  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0535  decode.d1.loss_dice: 0.0858  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0539  decode.d2.loss_dice: 0.0886  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0519  decode.d3.loss_dice: 0.0864  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0536  decode.d4.loss_dice: 0.0840  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0528  decode.d5.loss_dice: 0.0845  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0528  decode.d6.loss_dice: 0.0891  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0520  decode.d7.loss_dice: 0.0866  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0523  decode.d8.loss_dice: 0.0890
2023/12/31 16:32:26 - mmengine - INFO - Iter(train) [ 4850/90000]  base_lr: 9.5138e-05 lr: 9.5138e-06  eta: 23:50:23  time: 1.0074  data_time: 0.0127  memory: 18547  grad_norm: 27.3104  loss: 1.3840  decode.loss_cls: 0.0003  decode.loss_mask: 0.0569  decode.loss_dice: 0.0739  decode.d0.loss_cls: 0.0417  decode.d0.loss_mask: 0.0554  decode.d0.loss_dice: 0.0720  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.0989  decode.d1.loss_dice: 0.0897  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0556  decode.d2.loss_dice: 0.0710  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0572  decode.d3.loss_dice: 0.0744  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0551  decode.d4.loss_dice: 0.0742  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0552  decode.d5.loss_dice: 0.0696  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0550  decode.d6.loss_dice: 0.0723  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0552  decode.d7.loss_dice: 0.0693  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0557  decode.d8.loss_dice: 0.0736
2023/12/31 16:33:16 - mmengine - INFO - Iter(train) [ 4900/90000]  base_lr: 9.5087e-05 lr: 9.5087e-06  eta: 23:49:32  time: 1.0070  data_time: 0.0121  memory: 18545  grad_norm: 7.1994  loss: 1.3747  decode.loss_cls: 0.0002  decode.loss_mask: 0.0497  decode.loss_dice: 0.0808  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0504  decode.d0.loss_dice: 0.0859  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0487  decode.d1.loss_dice: 0.0792  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0482  decode.d2.loss_dice: 0.0933  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0490  decode.d3.loss_dice: 0.0832  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0489  decode.d4.loss_dice: 0.0823  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0488  decode.d5.loss_dice: 0.0850  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0503  decode.d6.loss_dice: 0.0844  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0495  decode.d7.loss_dice: 0.0878  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0499  decode.d8.loss_dice: 0.0951
2023/12/31 16:34:07 - mmengine - INFO - Iter(train) [ 4950/90000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 23:48:41  time: 1.0055  data_time: 0.0116  memory: 18547  grad_norm: 8.6929  loss: 1.6216  decode.loss_cls: 0.0006  decode.loss_mask: 0.0549  decode.loss_dice: 0.1025  decode.d0.loss_cls: 0.0276  decode.d0.loss_mask: 0.0517  decode.d0.loss_dice: 0.1058  decode.d1.loss_cls: 0.0428  decode.d1.loss_mask: 0.0542  decode.d1.loss_dice: 0.1073  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.0553  decode.d2.loss_dice: 0.1066  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0551  decode.d3.loss_dice: 0.0977  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0554  decode.d4.loss_dice: 0.1008  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0551  decode.d5.loss_dice: 0.0912  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.0552  decode.d6.loss_dice: 0.0986  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.0552  decode.d7.loss_dice: 0.0971  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0543  decode.d8.loss_dice: 0.0918
2023/12/31 16:34:57 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 16:34:57 - mmengine - INFO - Iter(train) [ 5000/90000]  base_lr: 9.4987e-05 lr: 9.4987e-06  eta: 23:47:50  time: 1.0081  data_time: 0.0125  memory: 18545  grad_norm: 10.7977  loss: 1.5579  decode.loss_cls: 0.0000  decode.loss_mask: 0.0514  decode.loss_dice: 0.0924  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0509  decode.d0.loss_dice: 0.1101  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.0514  decode.d1.loss_dice: 0.1183  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0505  decode.d2.loss_dice: 0.1059  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0517  decode.d3.loss_dice: 0.0908  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0515  decode.d4.loss_dice: 0.0893  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0512  decode.d5.loss_dice: 0.0903  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0499  decode.d6.loss_dice: 0.0953  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0511  decode.d7.loss_dice: 0.1007  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0521  decode.d8.loss_dice: 0.0987
2023/12/31 16:34:57 - mmengine - INFO - Saving checkpoint at 5000 iterations
2023/12/31 16:35:09 - mmengine - INFO - Iter(val) [ 50/370]    eta: 0:01:08  time: 0.1529  data_time: 0.0033  memory: 3091  
2023/12/31 16:35:17 - mmengine - INFO - Iter(val) [100/370]    eta: 0:00:49  time: 0.1529  data_time: 0.0033  memory: 3091  
2023/12/31 16:35:24 - mmengine - INFO - Iter(val) [150/370]    eta: 0:00:38  time: 0.1530  data_time: 0.0031  memory: 3091  
2023/12/31 16:35:32 - mmengine - INFO - Iter(val) [200/370]    eta: 0:00:28  time: 0.1531  data_time: 0.0033  memory: 3091  
2023/12/31 16:35:40 - mmengine - INFO - Iter(val) [250/370]    eta: 0:00:19  time: 0.1536  data_time: 0.0036  memory: 3091  
2023/12/31 16:35:47 - mmengine - INFO - Iter(val) [300/370]    eta: 0:00:11  time: 0.1536  data_time: 0.0036  memory: 3091  
2023/12/31 16:35:55 - mmengine - INFO - Iter(val) [350/370]    eta: 0:00:03  time: 0.1537  data_time: 0.0034  memory: 3091  
2023/12/31 16:35:58 - mmengine - INFO - per class results:
2023/12/31 16:35:58 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.07 | 99.33 |
|     Billboard      | 89.96 | 93.08 |
|      Goal net      | 29.35 | 78.16 |
+--------------------+-------+-------+
2023/12/31 16:35:58 - mmengine - INFO - Iter(val) [370/370]    aAcc: 99.0600  mIoU: 72.7900  mAcc: 90.1900  data_time: 0.0094  time: 0.1615
2023/12/31 16:35:59 - mmengine - INFO - The best checkpoint with 72.7900 mIoU at 5000 iter is saved to best_mIoU_iter_5000.pth.
2023/12/31 16:36:50 - mmengine - INFO - Iter(train) [ 5050/90000]  base_lr: 9.4936e-05 lr: 9.4936e-06  eta: 23:47:34  time: 1.0059  data_time: 0.0111  memory: 18545  grad_norm: 13.6908  loss: 1.6359  decode.loss_cls: 0.0816  decode.loss_mask: 0.0626  decode.loss_dice: 0.0816  decode.d0.loss_cls: 0.0399  decode.d0.loss_mask: 0.0597  decode.d0.loss_dice: 0.0810  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.0628  decode.d1.loss_dice: 0.0863  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.0631  decode.d2.loss_dice: 0.0857  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.0611  decode.d3.loss_dice: 0.0851  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.0607  decode.d4.loss_dice: 0.0806  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.0650  decode.d5.loss_dice: 0.0840  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.0645  decode.d6.loss_dice: 0.0803  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.0634  decode.d7.loss_dice: 0.0847  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0607  decode.d8.loss_dice: 0.0786
2023/12/31 16:37:41 - mmengine - INFO - Iter(train) [ 5100/90000]  base_lr: 9.4886e-05 lr: 9.4886e-06  eta: 23:46:42  time: 1.0060  data_time: 0.0109  memory: 18544  grad_norm: 23.8190  loss: 1.6805  decode.loss_cls: 0.0008  decode.loss_mask: 0.0560  decode.loss_dice: 0.1159  decode.d0.loss_cls: 0.0297  decode.d0.loss_mask: 0.0563  decode.d0.loss_dice: 0.1022  decode.d1.loss_cls: 0.0275  decode.d1.loss_mask: 0.0550  decode.d1.loss_dice: 0.0976  decode.d2.loss_cls: 0.0459  decode.d2.loss_mask: 0.0570  decode.d2.loss_dice: 0.0886  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0555  decode.d3.loss_dice: 0.0948  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0572  decode.d4.loss_dice: 0.1054  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0558  decode.d5.loss_dice: 0.0819  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0549  decode.d6.loss_dice: 0.1108  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0570  decode.d7.loss_dice: 0.1214  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.0548  decode.d8.loss_dice: 0.0972
2023/12/31 16:38:31 - mmengine - INFO - Iter(train) [ 5150/90000]  base_lr: 9.4836e-05 lr: 9.4836e-06  eta: 23:45:49  time: 1.0068  data_time: 0.0114  memory: 18544  grad_norm: 14.2969  loss: 1.5387  decode.loss_cls: 0.0001  decode.loss_mask: 0.0504  decode.loss_dice: 0.1097  decode.d0.loss_cls: 0.0239  decode.d0.loss_mask: 0.0486  decode.d0.loss_dice: 0.1038  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0506  decode.d1.loss_dice: 0.1048  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0502  decode.d2.loss_dice: 0.1065  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0483  decode.d3.loss_dice: 0.0979  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0489  decode.d4.loss_dice: 0.0962  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.0474  decode.d5.loss_dice: 0.0999  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.0490  decode.d6.loss_dice: 0.1031  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0490  decode.d7.loss_dice: 0.0939  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0501  decode.d8.loss_dice: 0.1032
2023/12/31 16:39:21 - mmengine - INFO - Iter(train) [ 5200/90000]  base_lr: 9.4786e-05 lr: 9.4786e-06  eta: 23:44:58  time: 1.0056  data_time: 0.0111  memory: 18544  grad_norm: 92.9086  loss: 5.3823  decode.loss_cls: 0.3353  decode.loss_mask: 0.9877  decode.loss_dice: 0.2235  decode.d0.loss_cls: 0.0995  decode.d0.loss_mask: 0.1427  decode.d0.loss_dice: 0.1693  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.2052  decode.d1.loss_dice: 0.1941  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.1860  decode.d2.loss_dice: 0.1871  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.1366  decode.d3.loss_dice: 0.1870  decode.d4.loss_cls: 0.1681  decode.d4.loss_mask: 0.1410  decode.d4.loss_dice: 0.1894  decode.d5.loss_cls: 0.1660  decode.d5.loss_mask: 0.1401  decode.d5.loss_dice: 0.1654  decode.d6.loss_cls: 0.0368  decode.d6.loss_mask: 0.1348  decode.d6.loss_dice: 0.1880  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.1423  decode.d7.loss_dice: 0.1879  decode.d8.loss_cls: 0.0334  decode.d8.loss_mask: 0.3934  decode.d8.loss_dice: 0.1933
2023/12/31 16:40:12 - mmengine - INFO - Iter(train) [ 5250/90000]  base_lr: 9.4735e-05 lr: 9.4735e-06  eta: 23:44:07  time: 1.0071  data_time: 0.0116  memory: 18544  grad_norm: 45.7806  loss: 1.6561  decode.loss_cls: 0.0000  decode.loss_mask: 0.0550  decode.loss_dice: 0.1143  decode.d0.loss_cls: 0.0271  decode.d0.loss_mask: 0.0547  decode.d0.loss_dice: 0.0998  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.0538  decode.d1.loss_dice: 0.1115  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0550  decode.d2.loss_dice: 0.1030  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0529  decode.d3.loss_dice: 0.0980  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0554  decode.d4.loss_dice: 0.1252  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0559  decode.d5.loss_dice: 0.1119  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0535  decode.d6.loss_dice: 0.1074  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0538  decode.d7.loss_dice: 0.0986  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0534  decode.d8.loss_dice: 0.0915
2023/12/31 16:41:02 - mmengine - INFO - Iter(train) [ 5300/90000]  base_lr: 9.4685e-05 lr: 9.4685e-06  eta: 23:43:15  time: 1.0070  data_time: 0.0113  memory: 18544  grad_norm: 68.6301  loss: 1.8620  decode.loss_cls: 0.0000  decode.loss_mask: 0.0610  decode.loss_dice: 0.1143  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.0593  decode.d0.loss_dice: 0.1249  decode.d1.loss_cls: 0.0172  decode.d1.loss_mask: 0.0605  decode.d1.loss_dice: 0.1245  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0590  decode.d2.loss_dice: 0.1216  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0607  decode.d3.loss_dice: 0.1220  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0627  decode.d4.loss_dice: 0.1233  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0619  decode.d5.loss_dice: 0.1282  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0606  decode.d6.loss_dice: 0.1148  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0599  decode.d7.loss_dice: 0.1170  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0605  decode.d8.loss_dice: 0.1224
2023/12/31 16:41:52 - mmengine - INFO - Iter(train) [ 5350/90000]  base_lr: 9.4635e-05 lr: 9.4635e-06  eta: 23:42:24  time: 1.0057  data_time: 0.0110  memory: 18544  grad_norm: 6.7649  loss: 1.3147  decode.loss_cls: 0.0000  decode.loss_mask: 0.0537  decode.loss_dice: 0.0738  decode.d0.loss_cls: 0.0290  decode.d0.loss_mask: 0.0517  decode.d0.loss_dice: 0.0705  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0528  decode.d1.loss_dice: 0.0743  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0546  decode.d2.loss_dice: 0.0754  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0547  decode.d3.loss_dice: 0.0767  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0534  decode.d4.loss_dice: 0.0788  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0530  decode.d5.loss_dice: 0.0747  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0539  decode.d6.loss_dice: 0.0743  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0543  decode.d7.loss_dice: 0.0778  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0530  decode.d8.loss_dice: 0.0737
2023/12/31 16:42:43 - mmengine - INFO - Iter(train) [ 5400/90000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 23:41:31  time: 1.0056  data_time: 0.0112  memory: 18544  grad_norm: 9.9832  loss: 1.7309  decode.loss_cls: 0.0000  decode.loss_mask: 0.0628  decode.loss_dice: 0.1004  decode.d0.loss_cls: 0.0269  decode.d0.loss_mask: 0.0622  decode.d0.loss_dice: 0.1003  decode.d1.loss_cls: 0.0263  decode.d1.loss_mask: 0.0639  decode.d1.loss_dice: 0.1099  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0634  decode.d2.loss_dice: 0.1124  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0619  decode.d3.loss_dice: 0.1063  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0630  decode.d4.loss_dice: 0.1042  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0630  decode.d5.loss_dice: 0.1024  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0621  decode.d6.loss_dice: 0.1016  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0619  decode.d7.loss_dice: 0.1096  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0619  decode.d8.loss_dice: 0.1043
2023/12/31 16:43:33 - mmengine - INFO - Iter(train) [ 5450/90000]  base_lr: 9.4534e-05 lr: 9.4534e-06  eta: 23:40:39  time: 1.0063  data_time: 0.0118  memory: 18544  grad_norm: 20.4664  loss: 1.7424  decode.loss_cls: 0.0014  decode.loss_mask: 0.0685  decode.loss_dice: 0.1009  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0681  decode.d0.loss_dice: 0.1025  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.0675  decode.d1.loss_dice: 0.1063  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.0678  decode.d2.loss_dice: 0.1023  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.0671  decode.d3.loss_dice: 0.1010  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.0687  decode.d4.loss_dice: 0.1065  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.0689  decode.d5.loss_dice: 0.1006  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.0663  decode.d6.loss_dice: 0.0974  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.0695  decode.d7.loss_dice: 0.1026  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.0668  decode.d8.loss_dice: 0.0973
2023/12/31 16:44:23 - mmengine - INFO - Iter(train) [ 5500/90000]  base_lr: 9.4484e-05 lr: 9.4484e-06  eta: 23:39:47  time: 1.0059  data_time: 0.0113  memory: 18544  grad_norm: 5.3330  loss: 1.3094  decode.loss_cls: 0.0000  decode.loss_mask: 0.0424  decode.loss_dice: 0.0867  decode.d0.loss_cls: 0.0175  decode.d0.loss_mask: 0.0408  decode.d0.loss_dice: 0.0905  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0423  decode.d1.loss_dice: 0.0854  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0430  decode.d2.loss_dice: 0.0842  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0428  decode.d3.loss_dice: 0.0885  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0435  decode.d4.loss_dice: 0.0926  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0427  decode.d5.loss_dice: 0.0778  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0431  decode.d6.loss_dice: 0.0884  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0417  decode.d7.loss_dice: 0.0848  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0429  decode.d8.loss_dice: 0.0874
2023/12/31 16:45:14 - mmengine - INFO - Iter(train) [ 5550/90000]  base_lr: 9.4433e-05 lr: 9.4433e-06  eta: 23:38:55  time: 1.0060  data_time: 0.0116  memory: 18544  grad_norm: 36.4910  loss: 2.1106  decode.loss_cls: 0.0000  decode.loss_mask: 0.0834  decode.loss_dice: 0.1120  decode.d0.loss_cls: 0.0286  decode.d0.loss_mask: 0.0887  decode.d0.loss_dice: 0.1110  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.0864  decode.d1.loss_dice: 0.1149  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.0715  decode.d2.loss_dice: 0.1038  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0854  decode.d3.loss_dice: 0.1113  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0876  decode.d4.loss_dice: 0.1110  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0856  decode.d5.loss_dice: 0.1117  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0847  decode.d6.loss_dice: 0.1154  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0852  decode.d7.loss_dice: 0.1134  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0860  decode.d8.loss_dice: 0.1139
2023/12/31 16:46:04 - mmengine - INFO - Iter(train) [ 5600/90000]  base_lr: 9.4383e-05 lr: 9.4383e-06  eta: 23:38:03  time: 1.0049  data_time: 0.0119  memory: 18544  grad_norm: 15.0788  loss: 1.5087  decode.loss_cls: 0.0015  decode.loss_mask: 0.0517  decode.loss_dice: 0.0841  decode.d0.loss_cls: 0.0322  decode.d0.loss_mask: 0.0538  decode.d0.loss_dice: 0.0832  decode.d1.loss_cls: 0.0182  decode.d1.loss_mask: 0.0541  decode.d1.loss_dice: 0.0863  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.0519  decode.d2.loss_dice: 0.0926  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0539  decode.d3.loss_dice: 0.0835  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.0515  decode.d4.loss_dice: 0.0947  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.0516  decode.d5.loss_dice: 0.0862  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0533  decode.d6.loss_dice: 0.0862  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0512  decode.d7.loss_dice: 0.0825  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.0512  decode.d8.loss_dice: 0.0952
2023/12/31 16:46:54 - mmengine - INFO - Iter(train) [ 5650/90000]  base_lr: 9.4333e-05 lr: 9.4333e-06  eta: 23:37:11  time: 1.0060  data_time: 0.0111  memory: 18544  grad_norm: 9.4165  loss: 1.3429  decode.loss_cls: 0.0002  decode.loss_mask: 0.0516  decode.loss_dice: 0.0797  decode.d0.loss_cls: 0.0253  decode.d0.loss_mask: 0.0508  decode.d0.loss_dice: 0.0772  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0516  decode.d1.loss_dice: 0.0827  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0529  decode.d2.loss_dice: 0.0823  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0521  decode.d3.loss_dice: 0.0799  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0516  decode.d4.loss_dice: 0.0815  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0509  decode.d5.loss_dice: 0.0799  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0519  decode.d6.loss_dice: 0.0746  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0517  decode.d7.loss_dice: 0.0793  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0519  decode.d8.loss_dice: 0.0817
2023/12/31 16:47:45 - mmengine - INFO - Iter(train) [ 5700/90000]  base_lr: 9.4282e-05 lr: 9.4282e-06  eta: 23:36:20  time: 1.0057  data_time: 0.0112  memory: 18544  grad_norm: 9.1612  loss: 1.4698  decode.loss_cls: 0.0000  decode.loss_mask: 0.0486  decode.loss_dice: 0.0986  decode.d0.loss_cls: 0.0225  decode.d0.loss_mask: 0.0472  decode.d0.loss_dice: 0.0950  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0479  decode.d1.loss_dice: 0.1002  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0481  decode.d2.loss_dice: 0.0936  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0483  decode.d3.loss_dice: 0.0980  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0477  decode.d4.loss_dice: 0.0950  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0486  decode.d5.loss_dice: 0.0989  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0460  decode.d6.loss_dice: 0.0925  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0474  decode.d7.loss_dice: 0.0992  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0484  decode.d8.loss_dice: 0.0975
2023/12/31 16:48:35 - mmengine - INFO - Iter(train) [ 5750/90000]  base_lr: 9.4232e-05 lr: 9.4232e-06  eta: 23:35:28  time: 1.0060  data_time: 0.0120  memory: 18544  grad_norm: 6.4579  loss: 1.3225  decode.loss_cls: 0.0000  decode.loss_mask: 0.0500  decode.loss_dice: 0.0801  decode.d0.loss_cls: 0.0359  decode.d0.loss_mask: 0.0499  decode.d0.loss_dice: 0.0747  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.0509  decode.d1.loss_dice: 0.0806  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0500  decode.d2.loss_dice: 0.0756  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0503  decode.d3.loss_dice: 0.0774  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0517  decode.d4.loss_dice: 0.0790  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0505  decode.d5.loss_dice: 0.0778  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0504  decode.d6.loss_dice: 0.0757  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0513  decode.d7.loss_dice: 0.0761  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0513  decode.d8.loss_dice: 0.0803
2023/12/31 16:49:25 - mmengine - INFO - Iter(train) [ 5800/90000]  base_lr: 9.4182e-05 lr: 9.4182e-06  eta: 23:34:37  time: 1.0040  data_time: 0.0110  memory: 18544  grad_norm: 17.9448  loss: 1.4769  decode.loss_cls: 0.0064  decode.loss_mask: 0.0494  decode.loss_dice: 0.1004  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.0480  decode.d0.loss_dice: 0.0832  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.0485  decode.d1.loss_dice: 0.1009  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.0479  decode.d2.loss_dice: 0.0894  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.0495  decode.d3.loss_dice: 0.0888  decode.d4.loss_cls: 0.0109  decode.d4.loss_mask: 0.0497  decode.d4.loss_dice: 0.0949  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.0482  decode.d5.loss_dice: 0.0811  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.0470  decode.d6.loss_dice: 0.0811  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.0492  decode.d7.loss_dice: 0.0851  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.0488  decode.d8.loss_dice: 0.0865
2023/12/31 16:50:16 - mmengine - INFO - Iter(train) [ 5850/90000]  base_lr: 9.4131e-05 lr: 9.4131e-06  eta: 23:33:45  time: 1.0076  data_time: 0.0120  memory: 18544  grad_norm: 10.0570  loss: 1.4387  decode.loss_cls: 0.0000  decode.loss_mask: 0.0517  decode.loss_dice: 0.0895  decode.d0.loss_cls: 0.0285  decode.d0.loss_mask: 0.0520  decode.d0.loss_dice: 0.0848  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0511  decode.d1.loss_dice: 0.0862  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0515  decode.d2.loss_dice: 0.0873  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0518  decode.d3.loss_dice: 0.0909  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0507  decode.d4.loss_dice: 0.0857  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0522  decode.d5.loss_dice: 0.0879  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0525  decode.d6.loss_dice: 0.0950  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0518  decode.d7.loss_dice: 0.0943  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0527  decode.d8.loss_dice: 0.0902
2023/12/31 16:51:06 - mmengine - INFO - Iter(train) [ 5900/90000]  base_lr: 9.4081e-05 lr: 9.4081e-06  eta: 23:32:54  time: 1.0062  data_time: 0.0113  memory: 18544  grad_norm: 15.1306  loss: 1.5804  decode.loss_cls: 0.0000  decode.loss_mask: 0.0632  decode.loss_dice: 0.0905  decode.d0.loss_cls: 0.0340  decode.d0.loss_mask: 0.0625  decode.d0.loss_dice: 0.0897  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.0624  decode.d1.loss_dice: 0.0924  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0634  decode.d2.loss_dice: 0.0941  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0604  decode.d3.loss_dice: 0.0917  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0628  decode.d4.loss_dice: 0.0891  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0653  decode.d5.loss_dice: 0.0936  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0639  decode.d6.loss_dice: 0.0923  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0616  decode.d7.loss_dice: 0.0896  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0630  decode.d8.loss_dice: 0.0912
2023/12/31 16:51:56 - mmengine - INFO - Iter(train) [ 5950/90000]  base_lr: 9.4031e-05 lr: 9.4031e-06  eta: 23:32:02  time: 1.0067  data_time: 0.0113  memory: 18544  grad_norm: 15.3649  loss: 1.5951  decode.loss_cls: 0.0000  decode.loss_mask: 0.0587  decode.loss_dice: 0.1008  decode.d0.loss_cls: 0.0237  decode.d0.loss_mask: 0.0604  decode.d0.loss_dice: 0.0964  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0558  decode.d1.loss_dice: 0.0986  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0563  decode.d2.loss_dice: 0.1013  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0561  decode.d3.loss_dice: 0.0894  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0572  decode.d4.loss_dice: 0.0997  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0567  decode.d5.loss_dice: 0.1069  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0569  decode.d6.loss_dice: 0.1008  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0592  decode.d7.loss_dice: 0.1053  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0552  decode.d8.loss_dice: 0.0994
2023/12/31 16:52:47 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 16:52:47 - mmengine - INFO - Iter(train) [ 6000/90000]  base_lr: 9.3980e-05 lr: 9.3980e-06  eta: 23:31:11  time: 1.0073  data_time: 0.0126  memory: 18544  grad_norm: 8.8036  loss: 1.3673  decode.loss_cls: 0.0000  decode.loss_mask: 0.0607  decode.loss_dice: 0.0711  decode.d0.loss_cls: 0.0341  decode.d0.loss_mask: 0.0627  decode.d0.loss_dice: 0.0732  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.0624  decode.d1.loss_dice: 0.0734  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0616  decode.d2.loss_dice: 0.0739  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0588  decode.d3.loss_dice: 0.0696  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0597  decode.d4.loss_dice: 0.0703  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0618  decode.d5.loss_dice: 0.0754  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0591  decode.d6.loss_dice: 0.0704  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0610  decode.d7.loss_dice: 0.0729  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0609  decode.d8.loss_dice: 0.0736
2023/12/31 16:53:37 - mmengine - INFO - Iter(train) [ 6050/90000]  base_lr: 9.3930e-05 lr: 9.3930e-06  eta: 23:30:21  time: 1.0080  data_time: 0.0121  memory: 18544  grad_norm: 10.9910  loss: 1.6164  decode.loss_cls: 0.0000  decode.loss_mask: 0.0597  decode.loss_dice: 0.1014  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.0628  decode.d0.loss_dice: 0.0928  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0588  decode.d1.loss_dice: 0.0962  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0614  decode.d2.loss_dice: 0.1031  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0582  decode.d3.loss_dice: 0.0960  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0616  decode.d4.loss_dice: 0.0973  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0611  decode.d5.loss_dice: 0.1009  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0605  decode.d6.loss_dice: 0.1017  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0607  decode.d7.loss_dice: 0.1007  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0589  decode.d8.loss_dice: 0.0986
2023/12/31 16:54:27 - mmengine - INFO - Iter(train) [ 6100/90000]  base_lr: 9.3880e-05 lr: 9.3880e-06  eta: 23:29:31  time: 1.0066  data_time: 0.0116  memory: 18544  grad_norm: 9.9112  loss: 1.3624  decode.loss_cls: 0.0001  decode.loss_mask: 0.0486  decode.loss_dice: 0.0858  decode.d0.loss_cls: 0.0236  decode.d0.loss_mask: 0.0481  decode.d0.loss_dice: 0.0841  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0482  decode.d1.loss_dice: 0.0864  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0488  decode.d2.loss_dice: 0.0807  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0483  decode.d3.loss_dice: 0.0826  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0475  decode.d4.loss_dice: 0.0867  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0487  decode.d5.loss_dice: 0.0878  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0498  decode.d6.loss_dice: 0.0856  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0477  decode.d7.loss_dice: 0.0856  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0488  decode.d8.loss_dice: 0.0882
2023/12/31 16:55:18 - mmengine - INFO - Iter(train) [ 6150/90000]  base_lr: 9.3829e-05 lr: 9.3829e-06  eta: 23:28:41  time: 1.0083  data_time: 0.0128  memory: 18544  grad_norm: 7.9762  loss: 1.4164  decode.loss_cls: 0.0000  decode.loss_mask: 0.0556  decode.loss_dice: 0.0791  decode.d0.loss_cls: 0.0253  decode.d0.loss_mask: 0.0566  decode.d0.loss_dice: 0.0823  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0572  decode.d1.loss_dice: 0.0837  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0572  decode.d2.loss_dice: 0.0861  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0576  decode.d3.loss_dice: 0.0816  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0564  decode.d4.loss_dice: 0.0834  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0573  decode.d5.loss_dice: 0.0847  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0566  decode.d6.loss_dice: 0.0791  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0563  decode.d7.loss_dice: 0.0850  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0556  decode.d8.loss_dice: 0.0794
2023/12/31 16:56:08 - mmengine - INFO - Iter(train) [ 6200/90000]  base_lr: 9.3779e-05 lr: 9.3779e-06  eta: 23:27:49  time: 1.0063  data_time: 0.0116  memory: 18544  grad_norm: 15.3527  loss: 2.0363  decode.loss_cls: 0.0458  decode.loss_mask: 0.0594  decode.loss_dice: 0.1115  decode.d0.loss_cls: 0.0256  decode.d0.loss_mask: 0.0577  decode.d0.loss_dice: 0.0982  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.0567  decode.d1.loss_dice: 0.1018  decode.d2.loss_cls: 0.0398  decode.d2.loss_mask: 0.0565  decode.d2.loss_dice: 0.0940  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.0565  decode.d3.loss_dice: 0.0855  decode.d4.loss_cls: 0.0488  decode.d4.loss_mask: 0.0578  decode.d4.loss_dice: 0.0848  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.0590  decode.d5.loss_dice: 0.0852  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.0577  decode.d6.loss_dice: 0.1077  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.0582  decode.d7.loss_dice: 0.1296  decode.d8.loss_cls: 0.0844  decode.d8.loss_mask: 0.0578  decode.d8.loss_dice: 0.0861
2023/12/31 16:56:59 - mmengine - INFO - Iter(train) [ 6250/90000]  base_lr: 9.3729e-05 lr: 9.3729e-06  eta: 23:26:59  time: 1.0071  data_time: 0.0117  memory: 18544  grad_norm: 17.0123  loss: 1.2696  decode.loss_cls: 0.0001  decode.loss_mask: 0.0543  decode.loss_dice: 0.0708  decode.d0.loss_cls: 0.0311  decode.d0.loss_mask: 0.0556  decode.d0.loss_dice: 0.0685  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0534  decode.d1.loss_dice: 0.0668  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0540  decode.d2.loss_dice: 0.0690  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0557  decode.d3.loss_dice: 0.0725  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0540  decode.d4.loss_dice: 0.0694  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0540  decode.d5.loss_dice: 0.0686  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0533  decode.d6.loss_dice: 0.0671  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0566  decode.d7.loss_dice: 0.0715  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0540  decode.d8.loss_dice: 0.0688
2023/12/31 16:57:49 - mmengine - INFO - Iter(train) [ 6300/90000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 23:26:08  time: 1.0082  data_time: 0.0128  memory: 18544  grad_norm: 10.5531  loss: 1.4916  decode.loss_cls: 0.0001  decode.loss_mask: 0.0543  decode.loss_dice: 0.0855  decode.d0.loss_cls: 0.0357  decode.d0.loss_mask: 0.0553  decode.d0.loss_dice: 0.0965  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.0558  decode.d1.loss_dice: 0.0922  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0552  decode.d2.loss_dice: 0.0862  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0546  decode.d3.loss_dice: 0.0857  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0559  decode.d4.loss_dice: 0.0933  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0539  decode.d5.loss_dice: 0.0868  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0547  decode.d6.loss_dice: 0.0868  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0574  decode.d7.loss_dice: 0.0967  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0552  decode.d8.loss_dice: 0.0888
2023/12/31 16:58:39 - mmengine - INFO - Iter(train) [ 6350/90000]  base_lr: 9.3628e-05 lr: 9.3628e-06  eta: 23:25:17  time: 1.0045  data_time: 0.0114  memory: 18544  grad_norm: 8.2615  loss: 1.3033  decode.loss_cls: 0.0001  decode.loss_mask: 0.0517  decode.loss_dice: 0.0737  decode.d0.loss_cls: 0.0324  decode.d0.loss_mask: 0.0542  decode.d0.loss_dice: 0.0775  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0518  decode.d1.loss_dice: 0.0745  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0537  decode.d2.loss_dice: 0.0764  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0524  decode.d3.loss_dice: 0.0742  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0522  decode.d4.loss_dice: 0.0718  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0525  decode.d5.loss_dice: 0.0736  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0531  decode.d6.loss_dice: 0.0749  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0529  decode.d7.loss_dice: 0.0713  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0536  decode.d8.loss_dice: 0.0744
2023/12/31 16:59:30 - mmengine - INFO - Iter(train) [ 6400/90000]  base_lr: 9.3578e-05 lr: 9.3578e-06  eta: 23:24:27  time: 1.0063  data_time: 0.0118  memory: 18544  grad_norm: 6.8721  loss: 1.3301  decode.loss_cls: 0.0000  decode.loss_mask: 0.0464  decode.loss_dice: 0.0885  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.0464  decode.d0.loss_dice: 0.0824  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0473  decode.d1.loss_dice: 0.0851  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0484  decode.d2.loss_dice: 0.0867  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0466  decode.d3.loss_dice: 0.0858  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0467  decode.d4.loss_dice: 0.0819  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0459  decode.d5.loss_dice: 0.0821  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0458  decode.d6.loss_dice: 0.0802  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0466  decode.d7.loss_dice: 0.0833  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0468  decode.d8.loss_dice: 0.0836
2023/12/31 17:00:20 - mmengine - INFO - Iter(train) [ 6450/90000]  base_lr: 9.3527e-05 lr: 9.3527e-06  eta: 23:23:36  time: 1.0081  data_time: 0.0130  memory: 18544  grad_norm: 10.6028  loss: 1.4824  decode.loss_cls: 0.0000  decode.loss_mask: 0.0610  decode.loss_dice: 0.0948  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0589  decode.d0.loss_dice: 0.0901  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0593  decode.d1.loss_dice: 0.0885  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0589  decode.d2.loss_dice: 0.0848  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0597  decode.d3.loss_dice: 0.0821  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0577  decode.d4.loss_dice: 0.0863  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0592  decode.d5.loss_dice: 0.0825  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0590  decode.d6.loss_dice: 0.0852  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0589  decode.d7.loss_dice: 0.0843  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0583  decode.d8.loss_dice: 0.0860
2023/12/31 17:01:10 - mmengine - INFO - Iter(train) [ 6500/90000]  base_lr: 9.3477e-05 lr: 9.3477e-06  eta: 23:22:45  time: 1.0077  data_time: 0.0121  memory: 18544  grad_norm: 14.0752  loss: 1.5795  decode.loss_cls: 0.0000  decode.loss_mask: 0.0594  decode.loss_dice: 0.0913  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.0579  decode.d0.loss_dice: 0.0942  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0594  decode.d1.loss_dice: 0.0961  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0603  decode.d2.loss_dice: 0.0972  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0588  decode.d3.loss_dice: 0.0934  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0607  decode.d4.loss_dice: 0.1033  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0597  decode.d5.loss_dice: 0.0925  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0592  decode.d6.loss_dice: 0.0933  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0607  decode.d7.loss_dice: 0.0992  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0602  decode.d8.loss_dice: 0.0943
2023/12/31 17:02:01 - mmengine - INFO - Iter(train) [ 6550/90000]  base_lr: 9.3426e-05 lr: 9.3426e-06  eta: 23:21:55  time: 1.0065  data_time: 0.0121  memory: 18544  grad_norm: 6.5753  loss: 1.3521  decode.loss_cls: 0.0001  decode.loss_mask: 0.0471  decode.loss_dice: 0.0855  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0461  decode.d0.loss_dice: 0.0853  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0465  decode.d1.loss_dice: 0.0780  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0468  decode.d2.loss_dice: 0.0827  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0480  decode.d3.loss_dice: 0.0874  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0477  decode.d4.loss_dice: 0.0840  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0487  decode.d5.loss_dice: 0.0906  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0494  decode.d6.loss_dice: 0.0868  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0472  decode.d7.loss_dice: 0.0847  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0471  decode.d8.loss_dice: 0.0849
2023/12/31 17:02:51 - mmengine - INFO - Iter(train) [ 6600/90000]  base_lr: 9.3376e-05 lr: 9.3376e-06  eta: 23:21:04  time: 1.0085  data_time: 0.0128  memory: 18544  grad_norm: 10.2822  loss: 1.3139  decode.loss_cls: 0.0000  decode.loss_mask: 0.0471  decode.loss_dice: 0.0791  decode.d0.loss_cls: 0.0296  decode.d0.loss_mask: 0.0486  decode.d0.loss_dice: 0.0839  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0486  decode.d1.loss_dice: 0.0749  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0474  decode.d2.loss_dice: 0.0776  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0505  decode.d3.loss_dice: 0.0811  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0478  decode.d4.loss_dice: 0.0780  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0491  decode.d5.loss_dice: 0.0812  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0491  decode.d6.loss_dice: 0.0837  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0483  decode.d7.loss_dice: 0.0812  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0474  decode.d8.loss_dice: 0.0792
2023/12/31 17:03:42 - mmengine - INFO - Iter(train) [ 6650/90000]  base_lr: 9.3326e-05 lr: 9.3326e-06  eta: 23:20:13  time: 1.0067  data_time: 0.0119  memory: 18544  grad_norm: 13.0836  loss: 1.3285  decode.loss_cls: 0.0000  decode.loss_mask: 0.0519  decode.loss_dice: 0.0804  decode.d0.loss_cls: 0.0318  decode.d0.loss_mask: 0.0501  decode.d0.loss_dice: 0.0756  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0520  decode.d1.loss_dice: 0.0778  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0510  decode.d2.loss_dice: 0.0805  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0516  decode.d3.loss_dice: 0.0775  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0518  decode.d4.loss_dice: 0.0769  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0519  decode.d5.loss_dice: 0.0798  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0520  decode.d6.loss_dice: 0.0785  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0514  decode.d7.loss_dice: 0.0752  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0518  decode.d8.loss_dice: 0.0786
2023/12/31 17:04:32 - mmengine - INFO - Iter(train) [ 6700/90000]  base_lr: 9.3275e-05 lr: 9.3275e-06  eta: 23:19:24  time: 1.0086  data_time: 0.0124  memory: 18544  grad_norm: 9.4435  loss: 1.4649  decode.loss_cls: 0.0000  decode.loss_mask: 0.0499  decode.loss_dice: 0.0878  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.0505  decode.d0.loss_dice: 0.0884  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0515  decode.d1.loss_dice: 0.0934  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0507  decode.d2.loss_dice: 0.0926  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0495  decode.d3.loss_dice: 0.0922  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0503  decode.d4.loss_dice: 0.0916  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0511  decode.d5.loss_dice: 0.0974  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0514  decode.d6.loss_dice: 0.0976  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0521  decode.d7.loss_dice: 0.0959  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0496  decode.d8.loss_dice: 0.0968
2023/12/31 17:05:23 - mmengine - INFO - Iter(train) [ 6750/90000]  base_lr: 9.3225e-05 lr: 9.3225e-06  eta: 23:18:34  time: 1.0099  data_time: 0.0128  memory: 18544  grad_norm: 9.9229  loss: 1.9392  decode.loss_cls: 0.0529  decode.loss_mask: 0.0476  decode.loss_dice: 0.0890  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0472  decode.d0.loss_dice: 0.0755  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.0484  decode.d1.loss_dice: 0.0885  decode.d2.loss_cls: 0.1095  decode.d2.loss_mask: 0.0495  decode.d2.loss_dice: 0.0848  decode.d3.loss_cls: 0.0536  decode.d3.loss_mask: 0.0486  decode.d3.loss_dice: 0.0916  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.0481  decode.d4.loss_dice: 0.0930  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.0485  decode.d5.loss_dice: 0.0916  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.0485  decode.d6.loss_dice: 0.0805  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.0485  decode.d7.loss_dice: 0.0844  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.0469  decode.d8.loss_dice: 0.0900
2023/12/31 17:06:13 - mmengine - INFO - Iter(train) [ 6800/90000]  base_lr: 9.3175e-05 lr: 9.3175e-06  eta: 23:17:44  time: 1.0093  data_time: 0.0120  memory: 18544  grad_norm: 9.1074  loss: 1.7303  decode.loss_cls: 0.0001  decode.loss_mask: 0.0585  decode.loss_dice: 0.1032  decode.d0.loss_cls: 0.0215  decode.d0.loss_mask: 0.0582  decode.d0.loss_dice: 0.1083  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0591  decode.d1.loss_dice: 0.1047  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0597  decode.d2.loss_dice: 0.1117  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0583  decode.d3.loss_dice: 0.1110  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0591  decode.d4.loss_dice: 0.1048  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0583  decode.d5.loss_dice: 0.1011  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0552  decode.d6.loss_dice: 0.1171  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0576  decode.d7.loss_dice: 0.1275  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0586  decode.d8.loss_dice: 0.1362
2023/12/31 17:07:03 - mmengine - INFO - Iter(train) [ 6850/90000]  base_lr: 9.3124e-05 lr: 9.3124e-06  eta: 23:16:55  time: 1.0091  data_time: 0.0127  memory: 18544  grad_norm: 10.0166  loss: 1.3873  decode.loss_cls: 0.0000  decode.loss_mask: 0.0458  decode.loss_dice: 0.0895  decode.d0.loss_cls: 0.0272  decode.d0.loss_mask: 0.0467  decode.d0.loss_dice: 0.0852  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0470  decode.d1.loss_dice: 0.0888  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0470  decode.d2.loss_dice: 0.0926  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0464  decode.d3.loss_dice: 0.0904  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0462  decode.d4.loss_dice: 0.0900  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0463  decode.d5.loss_dice: 0.0897  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0471  decode.d6.loss_dice: 0.0859  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0481  decode.d7.loss_dice: 0.0876  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0481  decode.d8.loss_dice: 0.0914
2023/12/31 17:07:54 - mmengine - INFO - Iter(train) [ 6900/90000]  base_lr: 9.3074e-05 lr: 9.3074e-06  eta: 23:16:05  time: 1.0090  data_time: 0.0126  memory: 18544  grad_norm: 10.7513  loss: 1.2915  decode.loss_cls: 0.0000  decode.loss_mask: 0.0547  decode.loss_dice: 0.0759  decode.d0.loss_cls: 0.0286  decode.d0.loss_mask: 0.0543  decode.d0.loss_dice: 0.0735  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.0535  decode.d1.loss_dice: 0.0721  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.0538  decode.d2.loss_dice: 0.0690  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0537  decode.d3.loss_dice: 0.0710  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0530  decode.d4.loss_dice: 0.0719  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0536  decode.d5.loss_dice: 0.0701  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0542  decode.d6.loss_dice: 0.0718  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0532  decode.d7.loss_dice: 0.0708  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0551  decode.d8.loss_dice: 0.0750
2023/12/31 17:08:44 - mmengine - INFO - Iter(train) [ 6950/90000]  base_lr: 9.3023e-05 lr: 9.3023e-06  eta: 23:15:15  time: 1.0082  data_time: 0.0120  memory: 18544  grad_norm: 7.8541  loss: 1.3838  decode.loss_cls: 0.0000  decode.loss_mask: 0.0528  decode.loss_dice: 0.0872  decode.d0.loss_cls: 0.0200  decode.d0.loss_mask: 0.0527  decode.d0.loss_dice: 0.0878  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0516  decode.d1.loss_dice: 0.0826  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.0519  decode.d2.loss_dice: 0.0827  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0538  decode.d3.loss_dice: 0.0821  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0512  decode.d4.loss_dice: 0.0826  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0535  decode.d5.loss_dice: 0.0856  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0532  decode.d6.loss_dice: 0.0871  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0507  decode.d7.loss_dice: 0.0840  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0505  decode.d8.loss_dice: 0.0793
2023/12/31 17:09:35 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 17:09:35 - mmengine - INFO - Iter(train) [ 7000/90000]  base_lr: 9.2973e-05 lr: 9.2973e-06  eta: 23:14:25  time: 1.0073  data_time: 0.0122  memory: 18544  grad_norm: 7.1460  loss: 1.4209  decode.loss_cls: 0.0000  decode.loss_mask: 0.0527  decode.loss_dice: 0.0874  decode.d0.loss_cls: 0.0202  decode.d0.loss_mask: 0.0509  decode.d0.loss_dice: 0.0850  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0532  decode.d1.loss_dice: 0.0912  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0500  decode.d2.loss_dice: 0.0877  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0497  decode.d3.loss_dice: 0.0877  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0519  decode.d4.loss_dice: 0.0910  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0518  decode.d5.loss_dice: 0.0900  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0521  decode.d6.loss_dice: 0.0860  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0517  decode.d7.loss_dice: 0.0882  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0524  decode.d8.loss_dice: 0.0900
2023/12/31 17:10:25 - mmengine - INFO - Iter(train) [ 7050/90000]  base_lr: 9.2922e-05 lr: 9.2922e-06  eta: 23:13:35  time: 1.0091  data_time: 0.0128  memory: 18544  grad_norm: 6.8750  loss: 1.3022  decode.loss_cls: 0.0000  decode.loss_mask: 0.0468  decode.loss_dice: 0.0824  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.0472  decode.d0.loss_dice: 0.0828  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0475  decode.d1.loss_dice: 0.0854  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0470  decode.d2.loss_dice: 0.0816  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0469  decode.d3.loss_dice: 0.0781  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0455  decode.d4.loss_dice: 0.0792  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0472  decode.d5.loss_dice: 0.0818  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0469  decode.d6.loss_dice: 0.0820  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0478  decode.d7.loss_dice: 0.0786  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0459  decode.d8.loss_dice: 0.0781
2023/12/31 17:11:16 - mmengine - INFO - Iter(train) [ 7100/90000]  base_lr: 9.2872e-05 lr: 9.2872e-06  eta: 23:12:45  time: 1.0088  data_time: 0.0119  memory: 18544  grad_norm: 15.6222  loss: 1.5642  decode.loss_cls: 0.0000  decode.loss_mask: 0.0499  decode.loss_dice: 0.0998  decode.d0.loss_cls: 0.0205  decode.d0.loss_mask: 0.0510  decode.d0.loss_dice: 0.1182  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0502  decode.d1.loss_dice: 0.0978  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0516  decode.d2.loss_dice: 0.1008  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0489  decode.d3.loss_dice: 0.0935  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0493  decode.d4.loss_dice: 0.1058  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0486  decode.d5.loss_dice: 0.0940  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0508  decode.d6.loss_dice: 0.1212  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0520  decode.d7.loss_dice: 0.1152  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0487  decode.d8.loss_dice: 0.0962
2023/12/31 17:12:06 - mmengine - INFO - Iter(train) [ 7150/90000]  base_lr: 9.2822e-05 lr: 9.2822e-06  eta: 23:11:55  time: 1.0062  data_time: 0.0118  memory: 18544  grad_norm: 6.9488  loss: 1.2522  decode.loss_cls: 0.0000  decode.loss_mask: 0.0508  decode.loss_dice: 0.0693  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0530  decode.d0.loss_dice: 0.0743  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0499  decode.d1.loss_dice: 0.0695  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0506  decode.d2.loss_dice: 0.0696  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0505  decode.d3.loss_dice: 0.0728  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0489  decode.d4.loss_dice: 0.0727  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0510  decode.d5.loss_dice: 0.0759  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0501  decode.d6.loss_dice: 0.0719  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0522  decode.d7.loss_dice: 0.0722  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0506  decode.d8.loss_dice: 0.0695
2023/12/31 17:12:56 - mmengine - INFO - Iter(train) [ 7200/90000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 23:11:04  time: 1.0090  data_time: 0.0131  memory: 18544  grad_norm: 6.6214  loss: 1.3795  decode.loss_cls: 0.0000  decode.loss_mask: 0.0450  decode.loss_dice: 0.0881  decode.d0.loss_cls: 0.0205  decode.d0.loss_mask: 0.0463  decode.d0.loss_dice: 0.0892  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0474  decode.d1.loss_dice: 0.0918  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0447  decode.d2.loss_dice: 0.0878  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0475  decode.d3.loss_dice: 0.0898  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0457  decode.d4.loss_dice: 0.0906  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0469  decode.d5.loss_dice: 0.0908  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0461  decode.d6.loss_dice: 0.0916  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0451  decode.d7.loss_dice: 0.0911  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0451  decode.d8.loss_dice: 0.0884
2023/12/31 17:13:47 - mmengine - INFO - Iter(train) [ 7250/90000]  base_lr: 9.2721e-05 lr: 9.2721e-06  eta: 23:10:14  time: 1.0062  data_time: 0.0117  memory: 18544  grad_norm: 25.8647  loss: 2.4632  decode.loss_cls: 0.0601  decode.loss_mask: 0.0557  decode.loss_dice: 0.1195  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0564  decode.d0.loss_dice: 0.0944  decode.d1.loss_cls: 0.1214  decode.d1.loss_mask: 0.0569  decode.d1.loss_dice: 0.1170  decode.d2.loss_cls: 0.0601  decode.d2.loss_mask: 0.0568  decode.d2.loss_dice: 0.0867  decode.d3.loss_cls: 0.1164  decode.d3.loss_mask: 0.0558  decode.d3.loss_dice: 0.1057  decode.d4.loss_cls: 0.0599  decode.d4.loss_mask: 0.0564  decode.d4.loss_dice: 0.0923  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.0553  decode.d5.loss_dice: 0.0895  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.0546  decode.d6.loss_dice: 0.1469  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 0.0551  decode.d7.loss_dice: 0.1475  decode.d8.loss_cls: 0.1031  decode.d8.loss_mask: 0.0555  decode.d8.loss_dice: 0.1185
2023/12/31 17:14:37 - mmengine - INFO - Iter(train) [ 7300/90000]  base_lr: 9.2670e-05 lr: 9.2670e-06  eta: 23:09:24  time: 1.0074  data_time: 0.0123  memory: 18544  grad_norm: 10.5416  loss: 1.7746  decode.loss_cls: 0.0327  decode.loss_mask: 0.0502  decode.loss_dice: 0.1006  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.0481  decode.d0.loss_dice: 0.0895  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0503  decode.d1.loss_dice: 0.0915  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.0485  decode.d2.loss_dice: 0.0890  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.0497  decode.d3.loss_dice: 0.0878  decode.d4.loss_cls: 0.0363  decode.d4.loss_mask: 0.0506  decode.d4.loss_dice: 0.0957  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.0486  decode.d5.loss_dice: 0.1190  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.0503  decode.d6.loss_dice: 0.1169  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.0500  decode.d7.loss_dice: 0.1006  decode.d8.loss_cls: 0.0330  decode.d8.loss_mask: 0.0487  decode.d8.loss_dice: 0.1072
2023/12/31 17:15:28 - mmengine - INFO - Iter(train) [ 7350/90000]  base_lr: 9.2620e-05 lr: 9.2620e-06  eta: 23:08:33  time: 1.0094  data_time: 0.0132  memory: 18544  grad_norm: 7.4398  loss: 1.3640  decode.loss_cls: 0.0000  decode.loss_mask: 0.0476  decode.loss_dice: 0.0867  decode.d0.loss_cls: 0.0252  decode.d0.loss_mask: 0.0493  decode.d0.loss_dice: 0.0847  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0488  decode.d1.loss_dice: 0.0842  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0480  decode.d2.loss_dice: 0.0781  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0490  decode.d3.loss_dice: 0.0837  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0512  decode.d4.loss_dice: 0.0893  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0491  decode.d5.loss_dice: 0.0875  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0500  decode.d6.loss_dice: 0.0839  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0476  decode.d7.loss_dice: 0.0823  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0502  decode.d8.loss_dice: 0.0872
2023/12/31 17:16:18 - mmengine - INFO - Iter(train) [ 7400/90000]  base_lr: 9.2570e-05 lr: 9.2570e-06  eta: 23:07:44  time: 1.0086  data_time: 0.0118  memory: 18544  grad_norm: 37.2003  loss: 1.6945  decode.loss_cls: 0.0001  decode.loss_mask: 0.0589  decode.loss_dice: 0.1046  decode.d0.loss_cls: 0.0215  decode.d0.loss_mask: 0.0602  decode.d0.loss_dice: 0.1129  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0610  decode.d1.loss_dice: 0.1072  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0594  decode.d2.loss_dice: 0.1063  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0615  decode.d3.loss_dice: 0.1107  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0584  decode.d4.loss_dice: 0.1051  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0599  decode.d5.loss_dice: 0.1091  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0605  decode.d6.loss_dice: 0.1092  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0585  decode.d7.loss_dice: 0.1045  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0591  decode.d8.loss_dice: 0.1055
2023/12/31 17:17:09 - mmengine - INFO - Iter(train) [ 7450/90000]  base_lr: 9.2519e-05 lr: 9.2519e-06  eta: 23:06:54  time: 1.0079  data_time: 0.0122  memory: 18544  grad_norm: 11.0516  loss: 1.3248  decode.loss_cls: 0.0001  decode.loss_mask: 0.0522  decode.loss_dice: 0.0787  decode.d0.loss_cls: 0.0299  decode.d0.loss_mask: 0.0507  decode.d0.loss_dice: 0.0737  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0512  decode.d1.loss_dice: 0.0792  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0524  decode.d2.loss_dice: 0.0855  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0518  decode.d3.loss_dice: 0.0782  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0509  decode.d4.loss_dice: 0.0771  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0517  decode.d5.loss_dice: 0.0861  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0492  decode.d6.loss_dice: 0.0720  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0513  decode.d7.loss_dice: 0.0729  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0519  decode.d8.loss_dice: 0.0779
2023/12/31 17:17:59 - mmengine - INFO - Iter(train) [ 7500/90000]  base_lr: 9.2469e-05 lr: 9.2469e-06  eta: 23:06:04  time: 1.0091  data_time: 0.0127  memory: 18544  grad_norm: 10.1485  loss: 1.3910  decode.loss_cls: 0.0000  decode.loss_mask: 0.0502  decode.loss_dice: 0.0849  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0506  decode.d0.loss_dice: 0.0823  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0506  decode.d1.loss_dice: 0.0821  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0524  decode.d2.loss_dice: 0.0853  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0517  decode.d3.loss_dice: 0.0814  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0518  decode.d4.loss_dice: 0.0860  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0524  decode.d5.loss_dice: 0.0957  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0515  decode.d6.loss_dice: 0.0875  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0505  decode.d7.loss_dice: 0.0832  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0520  decode.d8.loss_dice: 0.0813
2023/12/31 17:18:49 - mmengine - INFO - Iter(train) [ 7550/90000]  base_lr: 9.2418e-05 lr: 9.2418e-06  eta: 23:05:13  time: 1.0059  data_time: 0.0115  memory: 18544  grad_norm: 20.9008  loss: 1.3780  decode.loss_cls: 0.0005  decode.loss_mask: 0.0501  decode.loss_dice: 0.0860  decode.d0.loss_cls: 0.0373  decode.d0.loss_mask: 0.0511  decode.d0.loss_dice: 0.0863  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0506  decode.d1.loss_dice: 0.0807  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0511  decode.d2.loss_dice: 0.0840  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0495  decode.d3.loss_dice: 0.0849  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0488  decode.d4.loss_dice: 0.0792  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0514  decode.d5.loss_dice: 0.0843  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0500  decode.d6.loss_dice: 0.0831  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0489  decode.d7.loss_dice: 0.0795  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.0499  decode.d8.loss_dice: 0.0821
2023/12/31 17:19:40 - mmengine - INFO - Iter(train) [ 7600/90000]  base_lr: 9.2368e-05 lr: 9.2368e-06  eta: 23:04:24  time: 1.0087  data_time: 0.0122  memory: 18544  grad_norm: 8.8326  loss: 1.3569  decode.loss_cls: 0.0000  decode.loss_mask: 0.0451  decode.loss_dice: 0.0813  decode.d0.loss_cls: 0.0211  decode.d0.loss_mask: 0.0457  decode.d0.loss_dice: 0.0834  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.0472  decode.d1.loss_dice: 0.0829  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0456  decode.d2.loss_dice: 0.0819  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0456  decode.d3.loss_dice: 0.0872  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0447  decode.d4.loss_dice: 0.0939  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0453  decode.d5.loss_dice: 0.0848  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0445  decode.d6.loss_dice: 0.0854  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0450  decode.d7.loss_dice: 0.0861  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0468  decode.d8.loss_dice: 0.0900
2023/12/31 17:20:30 - mmengine - INFO - Iter(train) [ 7650/90000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 23:03:33  time: 1.0082  data_time: 0.0126  memory: 18544  grad_norm: 9.4118  loss: 1.3147  decode.loss_cls: 0.0000  decode.loss_mask: 0.0512  decode.loss_dice: 0.0788  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0511  decode.d0.loss_dice: 0.0788  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0517  decode.d1.loss_dice: 0.0792  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0503  decode.d2.loss_dice: 0.0771  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0516  decode.d3.loss_dice: 0.0765  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0507  decode.d4.loss_dice: 0.0776  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0506  decode.d5.loss_dice: 0.0800  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0507  decode.d6.loss_dice: 0.0799  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0514  decode.d7.loss_dice: 0.0758  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0500  decode.d8.loss_dice: 0.0762
2023/12/31 17:21:21 - mmengine - INFO - Iter(train) [ 7700/90000]  base_lr: 9.2267e-05 lr: 9.2267e-06  eta: 23:02:41  time: 1.0060  data_time: 0.0111  memory: 18544  grad_norm: 26.5361  loss: 1.4298  decode.loss_cls: 0.0040  decode.loss_mask: 0.0496  decode.loss_dice: 0.0896  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.0500  decode.d0.loss_dice: 0.0927  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.0483  decode.d1.loss_dice: 0.0924  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0490  decode.d2.loss_dice: 0.0890  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0490  decode.d3.loss_dice: 0.0899  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0508  decode.d4.loss_dice: 0.0947  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0470  decode.d5.loss_dice: 0.0825  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0497  decode.d6.loss_dice: 0.0904  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.0481  decode.d7.loss_dice: 0.0900  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.0481  decode.d8.loss_dice: 0.0907
2023/12/31 17:22:11 - mmengine - INFO - Iter(train) [ 7750/90000]  base_lr: 9.2216e-05 lr: 9.2216e-06  eta: 23:01:50  time: 1.0070  data_time: 0.0117  memory: 18544  grad_norm: 12.9843  loss: 2.2478  decode.loss_cls: 0.1710  decode.loss_mask: 0.0488  decode.loss_dice: 0.0921  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0516  decode.d0.loss_dice: 0.0811  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.0499  decode.d1.loss_dice: 0.1279  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.0503  decode.d2.loss_dice: 0.1240  decode.d3.loss_cls: 0.0419  decode.d3.loss_mask: 0.0520  decode.d3.loss_dice: 0.1021  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.0506  decode.d4.loss_dice: 0.1087  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.0515  decode.d5.loss_dice: 0.1116  decode.d6.loss_cls: 0.0814  decode.d6.loss_mask: 0.0512  decode.d6.loss_dice: 0.0990  decode.d7.loss_cls: 0.1175  decode.d7.loss_mask: 0.0514  decode.d7.loss_dice: 0.1245  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.0530  decode.d8.loss_dice: 0.1295
2023/12/31 17:23:01 - mmengine - INFO - Iter(train) [ 7800/90000]  base_lr: 9.2166e-05 lr: 9.2166e-06  eta: 23:01:00  time: 1.0088  data_time: 0.0129  memory: 18544  grad_norm: 6.4429  loss: 1.1886  decode.loss_cls: 0.0000  decode.loss_mask: 0.0487  decode.loss_dice: 0.0627  decode.d0.loss_cls: 0.0407  decode.d0.loss_mask: 0.0483  decode.d0.loss_dice: 0.0703  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0491  decode.d1.loss_dice: 0.0680  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0475  decode.d2.loss_dice: 0.0697  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0496  decode.d3.loss_dice: 0.0645  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0480  decode.d4.loss_dice: 0.0614  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0485  decode.d5.loss_dice: 0.0701  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0488  decode.d6.loss_dice: 0.0686  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0467  decode.d7.loss_dice: 0.0608  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0497  decode.d8.loss_dice: 0.0663
2023/12/31 17:23:52 - mmengine - INFO - Iter(train) [ 7850/90000]  base_lr: 9.2116e-05 lr: 9.2116e-06  eta: 23:00:09  time: 1.0075  data_time: 0.0115  memory: 18544  grad_norm: 7.2064  loss: 1.3334  decode.loss_cls: 0.0000  decode.loss_mask: 0.0449  decode.loss_dice: 0.0763  decode.d0.loss_cls: 0.0311  decode.d0.loss_mask: 0.0465  decode.d0.loss_dice: 0.0837  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0458  decode.d1.loss_dice: 0.0849  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0457  decode.d2.loss_dice: 0.0840  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0465  decode.d3.loss_dice: 0.0873  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0468  decode.d4.loss_dice: 0.0884  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0462  decode.d5.loss_dice: 0.0832  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0462  decode.d6.loss_dice: 0.0851  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0459  decode.d7.loss_dice: 0.0843  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0454  decode.d8.loss_dice: 0.0848
2023/12/31 17:24:42 - mmengine - INFO - Iter(train) [ 7900/90000]  base_lr: 9.2065e-05 lr: 9.2065e-06  eta: 22:59:19  time: 1.0086  data_time: 0.0125  memory: 18544  grad_norm: 58.8619  loss: 2.4821  decode.loss_cls: 0.1035  decode.loss_mask: 0.0472  decode.loss_dice: 0.1399  decode.d0.loss_cls: 0.0202  decode.d0.loss_mask: 0.0459  decode.d0.loss_dice: 0.1215  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0472  decode.d1.loss_dice: 0.1148  decode.d2.loss_cls: 0.0335  decode.d2.loss_mask: 0.0483  decode.d2.loss_dice: 0.1475  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.0487  decode.d3.loss_dice: 0.1045  decode.d4.loss_cls: 0.1149  decode.d4.loss_mask: 0.0475  decode.d4.loss_dice: 0.1316  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.0469  decode.d5.loss_dice: 0.1010  decode.d6.loss_cls: 0.1095  decode.d6.loss_mask: 0.0472  decode.d6.loss_dice: 0.1099  decode.d7.loss_cls: 0.1023  decode.d7.loss_mask: 0.0479  decode.d7.loss_dice: 0.1217  decode.d8.loss_cls: 0.1031  decode.d8.loss_mask: 0.0491  decode.d8.loss_dice: 0.1627
2023/12/31 17:25:32 - mmengine - INFO - Iter(train) [ 7950/90000]  base_lr: 9.2015e-05 lr: 9.2015e-06  eta: 22:58:28  time: 1.0065  data_time: 0.0120  memory: 18544  grad_norm: 6.9932  loss: 1.2659  decode.loss_cls: 0.0000  decode.loss_mask: 0.0535  decode.loss_dice: 0.0671  decode.d0.loss_cls: 0.0333  decode.d0.loss_mask: 0.0531  decode.d0.loss_dice: 0.0677  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0546  decode.d1.loss_dice: 0.0694  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0550  decode.d2.loss_dice: 0.0734  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0546  decode.d3.loss_dice: 0.0690  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0545  decode.d4.loss_dice: 0.0700  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0539  decode.d5.loss_dice: 0.0683  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0533  decode.d6.loss_dice: 0.0677  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0544  decode.d7.loss_dice: 0.0700  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0538  decode.d8.loss_dice: 0.0693
2023/12/31 17:26:23 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 17:26:23 - mmengine - INFO - Iter(train) [ 8000/90000]  base_lr: 9.1964e-05 lr: 9.1964e-06  eta: 22:57:38  time: 1.0065  data_time: 0.0116  memory: 18544  grad_norm: 10.6845  loss: 1.3590  decode.loss_cls: 0.0000  decode.loss_mask: 0.0561  decode.loss_dice: 0.0797  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.0571  decode.d0.loss_dice: 0.0785  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0556  decode.d1.loss_dice: 0.0772  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0552  decode.d2.loss_dice: 0.0783  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0541  decode.d3.loss_dice: 0.0804  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0550  decode.d4.loss_dice: 0.0768  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0541  decode.d5.loss_dice: 0.0793  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0544  decode.d6.loss_dice: 0.0784  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0549  decode.d7.loss_dice: 0.0751  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0541  decode.d8.loss_dice: 0.0756
2023/12/31 17:27:13 - mmengine - INFO - Iter(train) [ 8050/90000]  base_lr: 9.1914e-05 lr: 9.1914e-06  eta: 22:56:48  time: 1.0074  data_time: 0.0125  memory: 18544  grad_norm: 9.0780  loss: 1.3008  decode.loss_cls: 0.0001  decode.loss_mask: 0.0516  decode.loss_dice: 0.0775  decode.d0.loss_cls: 0.0339  decode.d0.loss_mask: 0.0521  decode.d0.loss_dice: 0.0799  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.0511  decode.d1.loss_dice: 0.0732  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.0519  decode.d2.loss_dice: 0.0749  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0506  decode.d3.loss_dice: 0.0745  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0523  decode.d4.loss_dice: 0.0740  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0514  decode.d5.loss_dice: 0.0746  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.0498  decode.d6.loss_dice: 0.0719  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0513  decode.d7.loss_dice: 0.0750  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0506  decode.d8.loss_dice: 0.0757
2023/12/31 17:28:04 - mmengine - INFO - Iter(train) [ 8100/90000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 22:55:57  time: 1.0071  data_time: 0.0117  memory: 18544  grad_norm: 14.2292  loss: 1.3813  decode.loss_cls: 0.0000  decode.loss_mask: 0.0518  decode.loss_dice: 0.0814  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0510  decode.d0.loss_dice: 0.0794  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0539  decode.d1.loss_dice: 0.0832  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0521  decode.d2.loss_dice: 0.0832  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0537  decode.d3.loss_dice: 0.0817  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0538  decode.d4.loss_dice: 0.0848  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0536  decode.d5.loss_dice: 0.0829  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0528  decode.d6.loss_dice: 0.0825  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0523  decode.d7.loss_dice: 0.0844  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0530  decode.d8.loss_dice: 0.0815
2023/12/31 17:28:54 - mmengine - INFO - Iter(train) [ 8150/90000]  base_lr: 9.1813e-05 lr: 9.1813e-06  eta: 22:55:07  time: 1.0067  data_time: 0.0116  memory: 18544  grad_norm: 6.7292  loss: 1.2870  decode.loss_cls: 0.0000  decode.loss_mask: 0.0476  decode.loss_dice: 0.0808  decode.d0.loss_cls: 0.0253  decode.d0.loss_mask: 0.0467  decode.d0.loss_dice: 0.0766  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0472  decode.d1.loss_dice: 0.0767  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0474  decode.d2.loss_dice: 0.0780  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0481  decode.d3.loss_dice: 0.0819  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0475  decode.d4.loss_dice: 0.0771  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0468  decode.d5.loss_dice: 0.0789  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0466  decode.d6.loss_dice: 0.0787  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0471  decode.d7.loss_dice: 0.0815  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0469  decode.d8.loss_dice: 0.0791
2023/12/31 17:29:45 - mmengine - INFO - Iter(train) [ 8200/90000]  base_lr: 9.1762e-05 lr: 9.1762e-06  eta: 22:54:17  time: 1.0085  data_time: 0.0127  memory: 18544  grad_norm: 6.8646  loss: 1.1720  decode.loss_cls: 0.0000  decode.loss_mask: 0.0456  decode.loss_dice: 0.0773  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.0440  decode.d0.loss_dice: 0.0694  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0456  decode.d1.loss_dice: 0.0626  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0470  decode.d2.loss_dice: 0.0711  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0455  decode.d3.loss_dice: 0.0707  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0460  decode.d4.loss_dice: 0.0685  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0445  decode.d5.loss_dice: 0.0624  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0458  decode.d6.loss_dice: 0.0801  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0445  decode.d7.loss_dice: 0.0673  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0435  decode.d8.loss_dice: 0.0669
2023/12/31 17:30:35 - mmengine - INFO - Iter(train) [ 8250/90000]  base_lr: 9.1712e-05 lr: 9.1712e-06  eta: 22:53:26  time: 1.0053  data_time: 0.0113  memory: 18544  grad_norm: 7.6257  loss: 1.3992  decode.loss_cls: 0.0000  decode.loss_mask: 0.0480  decode.loss_dice: 0.0890  decode.d0.loss_cls: 0.0368  decode.d0.loss_mask: 0.0484  decode.d0.loss_dice: 0.0874  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0513  decode.d1.loss_dice: 0.0896  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0500  decode.d2.loss_dice: 0.0841  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0478  decode.d3.loss_dice: 0.0887  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0478  decode.d4.loss_dice: 0.0870  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0483  decode.d5.loss_dice: 0.0880  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0506  decode.d6.loss_dice: 0.0879  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0491  decode.d7.loss_dice: 0.0860  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0485  decode.d8.loss_dice: 0.0848
2023/12/31 17:31:25 - mmengine - INFO - Iter(train) [ 8300/90000]  base_lr: 9.1661e-05 lr: 9.1661e-06  eta: 22:52:35  time: 1.0058  data_time: 0.0115  memory: 18544  grad_norm: 10.9580  loss: 1.4651  decode.loss_cls: 0.0000  decode.loss_mask: 0.0506  decode.loss_dice: 0.0938  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0516  decode.d0.loss_dice: 0.0914  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0517  decode.d1.loss_dice: 0.0935  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0522  decode.d2.loss_dice: 0.0926  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0526  decode.d3.loss_dice: 0.0928  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0515  decode.d4.loss_dice: 0.0933  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0511  decode.d5.loss_dice: 0.0927  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0508  decode.d6.loss_dice: 0.0940  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0498  decode.d7.loss_dice: 0.0935  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0516  decode.d8.loss_dice: 0.0887
2023/12/31 17:32:16 - mmengine - INFO - Iter(train) [ 8350/90000]  base_lr: 9.1611e-05 lr: 9.1611e-06  eta: 22:51:45  time: 1.0091  data_time: 0.0126  memory: 18544  grad_norm: 22.1673  loss: 2.1829  decode.loss_cls: 0.0613  decode.loss_mask: 0.0483  decode.loss_dice: 0.1226  decode.d0.loss_cls: 0.0182  decode.d0.loss_mask: 0.0486  decode.d0.loss_dice: 0.1247  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0480  decode.d1.loss_dice: 0.1219  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.0479  decode.d2.loss_dice: 0.1238  decode.d3.loss_cls: 0.0326  decode.d3.loss_mask: 0.0484  decode.d3.loss_dice: 0.1369  decode.d4.loss_cls: 0.0480  decode.d4.loss_mask: 0.0480  decode.d4.loss_dice: 0.1185  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.0480  decode.d5.loss_dice: 0.1272  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.0488  decode.d6.loss_dice: 0.1265  decode.d7.loss_cls: 0.1077  decode.d7.loss_mask: 0.0484  decode.d7.loss_dice: 0.1056  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.0479  decode.d8.loss_dice: 0.0977
2023/12/31 17:33:06 - mmengine - INFO - Iter(train) [ 8400/90000]  base_lr: 9.1560e-05 lr: 9.1560e-06  eta: 22:50:54  time: 1.0060  data_time: 0.0116  memory: 18544  grad_norm: 12.8340  loss: 1.3133  decode.loss_cls: 0.0000  decode.loss_mask: 0.0531  decode.loss_dice: 0.0779  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.0538  decode.d0.loss_dice: 0.0764  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0521  decode.d1.loss_dice: 0.0767  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0535  decode.d2.loss_dice: 0.0808  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0530  decode.d3.loss_dice: 0.0748  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0517  decode.d4.loss_dice: 0.0735  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0524  decode.d5.loss_dice: 0.0749  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0515  decode.d6.loss_dice: 0.0766  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0527  decode.d7.loss_dice: 0.0768  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0518  decode.d8.loss_dice: 0.0721
2023/12/31 17:33:56 - mmengine - INFO - Iter(train) [ 8450/90000]  base_lr: 9.1510e-05 lr: 9.1510e-06  eta: 22:50:03  time: 1.0058  data_time: 0.0116  memory: 18544  grad_norm: 8.8636  loss: 1.3184  decode.loss_cls: 0.0011  decode.loss_mask: 0.0489  decode.loss_dice: 0.0807  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0489  decode.d0.loss_dice: 0.0831  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0488  decode.d1.loss_dice: 0.0807  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0471  decode.d2.loss_dice: 0.0748  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0493  decode.d3.loss_dice: 0.0749  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0512  decode.d4.loss_dice: 0.0785  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0506  decode.d5.loss_dice: 0.0790  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0498  decode.d6.loss_dice: 0.0769  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.0506  decode.d7.loss_dice: 0.0819  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0489  decode.d8.loss_dice: 0.0841
2023/12/31 17:34:47 - mmengine - INFO - Iter(train) [ 8500/90000]  base_lr: 9.1459e-05 lr: 9.1459e-06  eta: 22:49:12  time: 1.0066  data_time: 0.0128  memory: 18544  grad_norm: 6.7137  loss: 1.2616  decode.loss_cls: 0.0000  decode.loss_mask: 0.0509  decode.loss_dice: 0.0729  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.0523  decode.d0.loss_dice: 0.0724  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0499  decode.d1.loss_dice: 0.0683  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0513  decode.d2.loss_dice: 0.0703  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0494  decode.d3.loss_dice: 0.0662  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0502  decode.d4.loss_dice: 0.0696  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0524  decode.d5.loss_dice: 0.0747  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0512  decode.d6.loss_dice: 0.0739  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0518  decode.d7.loss_dice: 0.0768  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0522  decode.d8.loss_dice: 0.0744
2023/12/31 17:35:37 - mmengine - INFO - Iter(train) [ 8550/90000]  base_lr: 9.1409e-05 lr: 9.1409e-06  eta: 22:48:21  time: 1.0064  data_time: 0.0113  memory: 18544  grad_norm: 12.0780  loss: 1.4305  decode.loss_cls: 0.0011  decode.loss_mask: 0.0557  decode.loss_dice: 0.0817  decode.d0.loss_cls: 0.0335  decode.d0.loss_mask: 0.0562  decode.d0.loss_dice: 0.0805  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0562  decode.d1.loss_dice: 0.0833  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0572  decode.d2.loss_dice: 0.0867  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0556  decode.d3.loss_dice: 0.0811  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0555  decode.d4.loss_dice: 0.0835  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0576  decode.d5.loss_dice: 0.0844  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0565  decode.d6.loss_dice: 0.0814  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.0566  decode.d7.loss_dice: 0.0844  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0564  decode.d8.loss_dice: 0.0836
2023/12/31 17:36:28 - mmengine - INFO - Iter(train) [ 8600/90000]  base_lr: 9.1358e-05 lr: 9.1358e-06  eta: 22:47:31  time: 1.0080  data_time: 0.0124  memory: 18544  grad_norm: 27.2588  loss: 1.6519  decode.loss_cls: 0.0001  decode.loss_mask: 0.0590  decode.loss_dice: 0.0983  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0585  decode.d0.loss_dice: 0.0948  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.0578  decode.d1.loss_dice: 0.0997  decode.d2.loss_cls: 0.0131  decode.d2.loss_mask: 0.0578  decode.d2.loss_dice: 0.1032  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.0575  decode.d3.loss_dice: 0.0985  decode.d4.loss_cls: 0.0109  decode.d4.loss_mask: 0.0587  decode.d4.loss_dice: 0.0973  decode.d5.loss_cls: 0.0124  decode.d5.loss_mask: 0.0576  decode.d5.loss_dice: 0.0991  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.0574  decode.d6.loss_dice: 0.0968  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0554  decode.d7.loss_dice: 0.0987  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0564  decode.d8.loss_dice: 0.1019
2023/12/31 17:37:18 - mmengine - INFO - Iter(train) [ 8650/90000]  base_lr: 9.1308e-05 lr: 9.1308e-06  eta: 22:46:41  time: 1.0070  data_time: 0.0126  memory: 18544  grad_norm: 18.5656  loss: 1.7533  decode.loss_cls: 0.0000  decode.loss_mask: 0.0743  decode.loss_dice: 0.0980  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0760  decode.d0.loss_dice: 0.0923  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0795  decode.d1.loss_dice: 0.0972  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0783  decode.d2.loss_dice: 0.0982  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0733  decode.d3.loss_dice: 0.0935  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0782  decode.d4.loss_dice: 0.0968  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0765  decode.d5.loss_dice: 0.0974  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0747  decode.d6.loss_dice: 0.0929  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0767  decode.d7.loss_dice: 0.0972  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0751  decode.d8.loss_dice: 0.0990
2023/12/31 17:38:08 - mmengine - INFO - Iter(train) [ 8700/90000]  base_lr: 9.1257e-05 lr: 9.1257e-06  eta: 22:45:51  time: 1.0066  data_time: 0.0116  memory: 18544  grad_norm: 12.3323  loss: 1.4391  decode.loss_cls: 0.0000  decode.loss_mask: 0.0494  decode.loss_dice: 0.0891  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.0502  decode.d0.loss_dice: 0.0910  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0509  decode.d1.loss_dice: 0.0945  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0485  decode.d2.loss_dice: 0.0884  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0505  decode.d3.loss_dice: 0.0958  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0509  decode.d4.loss_dice: 0.0939  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0502  decode.d5.loss_dice: 0.0909  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0514  decode.d6.loss_dice: 0.0952  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0492  decode.d7.loss_dice: 0.0892  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0503  decode.d8.loss_dice: 0.0861
2023/12/31 17:38:59 - mmengine - INFO - Iter(train) [ 8750/90000]  base_lr: 9.1207e-05 lr: 9.1207e-06  eta: 22:45:00  time: 1.0078  data_time: 0.0119  memory: 18544  grad_norm: 14.0735  loss: 1.4270  decode.loss_cls: 0.0000  decode.loss_mask: 0.0505  decode.loss_dice: 0.0974  decode.d0.loss_cls: 0.0204  decode.d0.loss_mask: 0.0496  decode.d0.loss_dice: 0.0899  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0498  decode.d1.loss_dice: 0.0867  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0508  decode.d2.loss_dice: 0.0915  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0514  decode.d3.loss_dice: 0.0888  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0505  decode.d4.loss_dice: 0.0897  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0492  decode.d5.loss_dice: 0.0891  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0511  decode.d6.loss_dice: 0.0874  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0522  decode.d7.loss_dice: 0.0917  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0498  decode.d8.loss_dice: 0.0894
2023/12/31 17:39:49 - mmengine - INFO - Iter(train) [ 8800/90000]  base_lr: 9.1156e-05 lr: 9.1156e-06  eta: 22:44:10  time: 1.0094  data_time: 0.0132  memory: 18544  grad_norm: 7.9793  loss: 1.3874  decode.loss_cls: 0.0020  decode.loss_mask: 0.0534  decode.loss_dice: 0.0892  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.0507  decode.d0.loss_dice: 0.0858  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0519  decode.d1.loss_dice: 0.0816  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0505  decode.d2.loss_dice: 0.0806  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0527  decode.d3.loss_dice: 0.0835  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0501  decode.d4.loss_dice: 0.0839  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0510  decode.d5.loss_dice: 0.0839  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.0523  decode.d6.loss_dice: 0.0849  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.0519  decode.d7.loss_dice: 0.0815  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.0522  decode.d8.loss_dice: 0.0826
2023/12/31 17:40:40 - mmengine - INFO - Iter(train) [ 8850/90000]  base_lr: 9.1106e-05 lr: 9.1106e-06  eta: 22:43:19  time: 1.0071  data_time: 0.0117  memory: 18544  grad_norm: 7.7916  loss: 1.2641  decode.loss_cls: 0.0000  decode.loss_mask: 0.0506  decode.loss_dice: 0.0752  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.0505  decode.d0.loss_dice: 0.0726  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0504  decode.d1.loss_dice: 0.0745  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0497  decode.d2.loss_dice: 0.0786  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0480  decode.d3.loss_dice: 0.0698  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0495  decode.d4.loss_dice: 0.0726  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0494  decode.d5.loss_dice: 0.0713  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0486  decode.d6.loss_dice: 0.0725  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0511  decode.d7.loss_dice: 0.0765  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0501  decode.d8.loss_dice: 0.0743
2023/12/31 17:41:30 - mmengine - INFO - Iter(train) [ 8900/90000]  base_lr: 9.1055e-05 lr: 9.1055e-06  eta: 22:42:29  time: 1.0066  data_time: 0.0114  memory: 18544  grad_norm: 6.8318  loss: 1.2571  decode.loss_cls: 0.0000  decode.loss_mask: 0.0449  decode.loss_dice: 0.0756  decode.d0.loss_cls: 0.0286  decode.d0.loss_mask: 0.0451  decode.d0.loss_dice: 0.0744  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0451  decode.d1.loss_dice: 0.0778  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0456  decode.d2.loss_dice: 0.0757  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0463  decode.d3.loss_dice: 0.0761  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0460  decode.d4.loss_dice: 0.0773  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0454  decode.d5.loss_dice: 0.0794  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0467  decode.d6.loss_dice: 0.0760  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0463  decode.d7.loss_dice: 0.0787  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0461  decode.d8.loss_dice: 0.0798
2023/12/31 17:42:20 - mmengine - INFO - Iter(train) [ 8950/90000]  base_lr: 9.1005e-05 lr: 9.1005e-06  eta: 22:41:38  time: 1.0079  data_time: 0.0126  memory: 18544  grad_norm: 10.5192  loss: 1.4243  decode.loss_cls: 0.0000  decode.loss_mask: 0.0656  decode.loss_dice: 0.0747  decode.d0.loss_cls: 0.0338  decode.d0.loss_mask: 0.0704  decode.d0.loss_dice: 0.0735  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0654  decode.d1.loss_dice: 0.0721  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0658  decode.d2.loss_dice: 0.0715  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0670  decode.d3.loss_dice: 0.0723  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0668  decode.d4.loss_dice: 0.0709  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0685  decode.d5.loss_dice: 0.0714  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0673  decode.d6.loss_dice: 0.0717  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0658  decode.d7.loss_dice: 0.0710  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0660  decode.d8.loss_dice: 0.0727
2023/12/31 17:43:11 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 17:43:11 - mmengine - INFO - Iter(train) [ 9000/90000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 22:40:48  time: 1.0057  data_time: 0.0112  memory: 18544  grad_norm: 24.4777  loss: 1.4094  decode.loss_cls: 0.0001  decode.loss_mask: 0.0522  decode.loss_dice: 0.0863  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.0520  decode.d0.loss_dice: 0.0834  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.0519  decode.d1.loss_dice: 0.0828  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0531  decode.d2.loss_dice: 0.0863  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0522  decode.d3.loss_dice: 0.0883  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0508  decode.d4.loss_dice: 0.0836  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0527  decode.d5.loss_dice: 0.0839  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0527  decode.d6.loss_dice: 0.0880  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0525  decode.d7.loss_dice: 0.0857  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0535  decode.d8.loss_dice: 0.0858
2023/12/31 17:44:01 - mmengine - INFO - Iter(train) [ 9050/90000]  base_lr: 9.0904e-05 lr: 9.0904e-06  eta: 22:39:57  time: 1.0057  data_time: 0.0111  memory: 18544  grad_norm: 7.5561  loss: 1.1924  decode.loss_cls: 0.0000  decode.loss_mask: 0.0412  decode.loss_dice: 0.0753  decode.d0.loss_cls: 0.0220  decode.d0.loss_mask: 0.0423  decode.d0.loss_dice: 0.0775  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0407  decode.d1.loss_dice: 0.0736  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0418  decode.d2.loss_dice: 0.0758  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0415  decode.d3.loss_dice: 0.0784  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0416  decode.d4.loss_dice: 0.0772  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0424  decode.d5.loss_dice: 0.0764  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0410  decode.d6.loss_dice: 0.0721  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0410  decode.d7.loss_dice: 0.0715  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0430  decode.d8.loss_dice: 0.0760
2023/12/31 17:44:51 - mmengine - INFO - Iter(train) [ 9100/90000]  base_lr: 9.0853e-05 lr: 9.0853e-06  eta: 22:39:06  time: 1.0074  data_time: 0.0125  memory: 18544  grad_norm: 7.3025  loss: 1.2820  decode.loss_cls: 0.0000  decode.loss_mask: 0.0505  decode.loss_dice: 0.0769  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0503  decode.d0.loss_dice: 0.0773  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0489  decode.d1.loss_dice: 0.0722  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0502  decode.d2.loss_dice: 0.0737  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0510  decode.d3.loss_dice: 0.0754  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0496  decode.d4.loss_dice: 0.0755  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0501  decode.d5.loss_dice: 0.0745  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0511  decode.d6.loss_dice: 0.0763  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0502  decode.d7.loss_dice: 0.0763  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0493  decode.d8.loss_dice: 0.0760
2023/12/31 17:45:42 - mmengine - INFO - Iter(train) [ 9150/90000]  base_lr: 9.0803e-05 lr: 9.0803e-06  eta: 22:38:15  time: 1.0066  data_time: 0.0113  memory: 18544  grad_norm: 9.0554  loss: 1.3151  decode.loss_cls: 0.0000  decode.loss_mask: 0.0534  decode.loss_dice: 0.0741  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0528  decode.d0.loss_dice: 0.0733  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0536  decode.d1.loss_dice: 0.0757  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0538  decode.d2.loss_dice: 0.0742  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0534  decode.d3.loss_dice: 0.0750  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0550  decode.d4.loss_dice: 0.0790  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0543  decode.d5.loss_dice: 0.0727  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0538  decode.d6.loss_dice: 0.0738  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0547  decode.d7.loss_dice: 0.0756  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0544  decode.d8.loss_dice: 0.0744
2023/12/31 17:46:32 - mmengine - INFO - Iter(train) [ 9200/90000]  base_lr: 9.0752e-05 lr: 9.0752e-06  eta: 22:37:25  time: 1.0069  data_time: 0.0116  memory: 18544  grad_norm: 10.1385  loss: 1.4131  decode.loss_cls: 0.0000  decode.loss_mask: 0.0477  decode.loss_dice: 0.0969  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0464  decode.d0.loss_dice: 0.0910  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.0472  decode.d1.loss_dice: 0.0882  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0474  decode.d2.loss_dice: 0.0949  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0462  decode.d3.loss_dice: 0.0923  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0464  decode.d4.loss_dice: 0.0911  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0485  decode.d5.loss_dice: 0.0886  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0476  decode.d6.loss_dice: 0.0921  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0467  decode.d7.loss_dice: 0.0926  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0466  decode.d8.loss_dice: 0.0845
2023/12/31 17:47:22 - mmengine - INFO - Iter(train) [ 9250/90000]  base_lr: 9.0701e-05 lr: 9.0701e-06  eta: 22:36:34  time: 1.0082  data_time: 0.0129  memory: 18544  grad_norm: 6.9201  loss: 1.2976  decode.loss_cls: 0.0000  decode.loss_mask: 0.0522  decode.loss_dice: 0.0766  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.0519  decode.d0.loss_dice: 0.0756  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0521  decode.d1.loss_dice: 0.0723  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0523  decode.d2.loss_dice: 0.0735  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0535  decode.d3.loss_dice: 0.0756  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0516  decode.d4.loss_dice: 0.0713  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0528  decode.d5.loss_dice: 0.0750  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0520  decode.d6.loss_dice: 0.0727  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0523  decode.d7.loss_dice: 0.0738  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0532  decode.d8.loss_dice: 0.0771
2023/12/31 17:48:13 - mmengine - INFO - Iter(train) [ 9300/90000]  base_lr: 9.0651e-05 lr: 9.0651e-06  eta: 22:35:43  time: 1.0060  data_time: 0.0112  memory: 18544  grad_norm: 5.7592  loss: 1.2264  decode.loss_cls: 0.0001  decode.loss_mask: 0.0444  decode.loss_dice: 0.0700  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.0468  decode.d0.loss_dice: 0.0744  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0474  decode.d1.loss_dice: 0.0751  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0488  decode.d2.loss_dice: 0.0774  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0456  decode.d3.loss_dice: 0.0743  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0464  decode.d4.loss_dice: 0.0763  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0457  decode.d5.loss_dice: 0.0721  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0461  decode.d6.loss_dice: 0.0722  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0468  decode.d7.loss_dice: 0.0745  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0452  decode.d8.loss_dice: 0.0732
2023/12/31 17:49:03 - mmengine - INFO - Iter(train) [ 9350/90000]  base_lr: 9.0600e-05 lr: 9.0600e-06  eta: 22:34:52  time: 1.0066  data_time: 0.0113  memory: 18544  grad_norm: 9.1668  loss: 1.4410  decode.loss_cls: 0.0000  decode.loss_mask: 0.0490  decode.loss_dice: 0.0852  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.0463  decode.d0.loss_dice: 0.0960  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0482  decode.d1.loss_dice: 0.1008  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0483  decode.d2.loss_dice: 0.0816  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0485  decode.d3.loss_dice: 0.0896  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0487  decode.d4.loss_dice: 0.1100  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0459  decode.d5.loss_dice: 0.0936  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0482  decode.d6.loss_dice: 0.0847  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0474  decode.d7.loss_dice: 0.0915  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0486  decode.d8.loss_dice: 0.1053
2023/12/31 17:49:54 - mmengine - INFO - Iter(train) [ 9400/90000]  base_lr: 9.0550e-05 lr: 9.0550e-06  eta: 22:34:02  time: 1.0091  data_time: 0.0130  memory: 18544  grad_norm: 7.2864  loss: 1.2713  decode.loss_cls: 0.0000  decode.loss_mask: 0.0491  decode.loss_dice: 0.0757  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.0486  decode.d0.loss_dice: 0.0771  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0495  decode.d1.loss_dice: 0.0749  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0500  decode.d2.loss_dice: 0.0749  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0480  decode.d3.loss_dice: 0.0750  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0492  decode.d4.loss_dice: 0.0749  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0481  decode.d5.loss_dice: 0.0784  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0490  decode.d6.loss_dice: 0.0772  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0486  decode.d7.loss_dice: 0.0791  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0483  decode.d8.loss_dice: 0.0720
2023/12/31 17:50:44 - mmengine - INFO - Iter(train) [ 9450/90000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 22:33:11  time: 1.0059  data_time: 0.0113  memory: 18544  grad_norm: 6.5392  loss: 1.3152  decode.loss_cls: 0.0000  decode.loss_mask: 0.0456  decode.loss_dice: 0.0782  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.0469  decode.d0.loss_dice: 0.0816  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0481  decode.d1.loss_dice: 0.0813  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0487  decode.d2.loss_dice: 0.0811  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0487  decode.d3.loss_dice: 0.0865  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0478  decode.d4.loss_dice: 0.0821  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0475  decode.d5.loss_dice: 0.0832  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0476  decode.d6.loss_dice: 0.0827  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0466  decode.d7.loss_dice: 0.0834  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0471  decode.d8.loss_dice: 0.0770
2023/12/31 17:51:34 - mmengine - INFO - Iter(train) [ 9500/90000]  base_lr: 9.0449e-05 lr: 9.0449e-06  eta: 22:32:20  time: 1.0061  data_time: 0.0112  memory: 18544  grad_norm: 9.1102  loss: 1.2949  decode.loss_cls: 0.0001  decode.loss_mask: 0.0459  decode.loss_dice: 0.0727  decode.d0.loss_cls: 0.0290  decode.d0.loss_mask: 0.0462  decode.d0.loss_dice: 0.0730  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0464  decode.d1.loss_dice: 0.0813  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0457  decode.d2.loss_dice: 0.0917  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0465  decode.d3.loss_dice: 0.0717  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0447  decode.d4.loss_dice: 0.0742  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0452  decode.d5.loss_dice: 0.0968  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0453  decode.d6.loss_dice: 0.0839  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0450  decode.d7.loss_dice: 0.0762  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0458  decode.d8.loss_dice: 0.0875
2023/12/31 17:52:25 - mmengine - INFO - Iter(train) [ 9550/90000]  base_lr: 9.0398e-05 lr: 9.0398e-06  eta: 22:31:29  time: 1.0088  data_time: 0.0124  memory: 18544  grad_norm: 7.9059  loss: 1.3254  decode.loss_cls: 0.0000  decode.loss_mask: 0.0395  decode.loss_dice: 0.0903  decode.d0.loss_cls: 0.0175  decode.d0.loss_mask: 0.0391  decode.d0.loss_dice: 0.0954  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0401  decode.d1.loss_dice: 0.1001  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0400  decode.d2.loss_dice: 0.0862  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0402  decode.d3.loss_dice: 0.0871  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0391  decode.d4.loss_dice: 0.0877  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0413  decode.d5.loss_dice: 0.0883  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0404  decode.d6.loss_dice: 0.0913  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0388  decode.d7.loss_dice: 0.0773  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0418  decode.d8.loss_dice: 0.1039
2023/12/31 17:53:15 - mmengine - INFO - Iter(train) [ 9600/90000]  base_lr: 9.0348e-05 lr: 9.0348e-06  eta: 22:30:38  time: 1.0053  data_time: 0.0111  memory: 18544  grad_norm: 6.4353  loss: 1.2562  decode.loss_cls: 0.0004  decode.loss_mask: 0.0435  decode.loss_dice: 0.0736  decode.d0.loss_cls: 0.0221  decode.d0.loss_mask: 0.0435  decode.d0.loss_dice: 0.0835  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0443  decode.d1.loss_dice: 0.0791  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0435  decode.d2.loss_dice: 0.0770  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0429  decode.d3.loss_dice: 0.0774  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0446  decode.d4.loss_dice: 0.0784  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0438  decode.d5.loss_dice: 0.0829  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0444  decode.d6.loss_dice: 0.0772  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.0436  decode.d7.loss_dice: 0.0844  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.0435  decode.d8.loss_dice: 0.0805
2023/12/31 17:54:05 - mmengine - INFO - Iter(train) [ 9650/90000]  base_lr: 9.0297e-05 lr: 9.0297e-06  eta: 22:29:47  time: 1.0048  data_time: 0.0113  memory: 18544  grad_norm: 5.6666  loss: 1.1647  decode.loss_cls: 0.0000  decode.loss_mask: 0.0410  decode.loss_dice: 0.0716  decode.d0.loss_cls: 0.0423  decode.d0.loss_mask: 0.0406  decode.d0.loss_dice: 0.0715  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0426  decode.d1.loss_dice: 0.0748  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0411  decode.d2.loss_dice: 0.0793  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0404  decode.d3.loss_dice: 0.0671  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0422  decode.d4.loss_dice: 0.0692  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0417  decode.d5.loss_dice: 0.0699  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0400  decode.d6.loss_dice: 0.0653  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0395  decode.d7.loss_dice: 0.0750  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0400  decode.d8.loss_dice: 0.0687
2023/12/31 17:54:56 - mmengine - INFO - Iter(train) [ 9700/90000]  base_lr: 9.0246e-05 lr: 9.0246e-06  eta: 22:28:56  time: 1.0064  data_time: 0.0116  memory: 18544  grad_norm: 7.5519  loss: 1.1279  decode.loss_cls: 0.0000  decode.loss_mask: 0.0506  decode.loss_dice: 0.0595  decode.d0.loss_cls: 0.0343  decode.d0.loss_mask: 0.0517  decode.d0.loss_dice: 0.0588  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0497  decode.d1.loss_dice: 0.0594  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0505  decode.d2.loss_dice: 0.0592  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0492  decode.d3.loss_dice: 0.0561  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0501  decode.d4.loss_dice: 0.0610  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0504  decode.d5.loss_dice: 0.0605  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0506  decode.d6.loss_dice: 0.0590  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0504  decode.d7.loss_dice: 0.0590  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0496  decode.d8.loss_dice: 0.0581
2023/12/31 17:55:46 - mmengine - INFO - Iter(train) [ 9750/90000]  base_lr: 9.0196e-05 lr: 9.0196e-06  eta: 22:28:05  time: 1.0065  data_time: 0.0111  memory: 18544  grad_norm: 8.3328  loss: 1.3879  decode.loss_cls: 0.0000  decode.loss_mask: 0.0469  decode.loss_dice: 0.0885  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0487  decode.d0.loss_dice: 0.0961  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0473  decode.d1.loss_dice: 0.0853  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0461  decode.d2.loss_dice: 0.0862  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0476  decode.d3.loss_dice: 0.0879  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0477  decode.d4.loss_dice: 0.0903  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0480  decode.d5.loss_dice: 0.0924  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0482  decode.d6.loss_dice: 0.0928  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0467  decode.d7.loss_dice: 0.0845  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0469  decode.d8.loss_dice: 0.0850
2023/12/31 17:56:36 - mmengine - INFO - Iter(train) [ 9800/90000]  base_lr: 9.0145e-05 lr: 9.0145e-06  eta: 22:27:14  time: 1.0070  data_time: 0.0115  memory: 18544  grad_norm: 6.9080  loss: 1.3405  decode.loss_cls: 0.0000  decode.loss_mask: 0.0507  decode.loss_dice: 0.0814  decode.d0.loss_cls: 0.0304  decode.d0.loss_mask: 0.0503  decode.d0.loss_dice: 0.0756  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0508  decode.d1.loss_dice: 0.0973  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0505  decode.d2.loss_dice: 0.0768  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0499  decode.d3.loss_dice: 0.0803  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0503  decode.d4.loss_dice: 0.0872  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0491  decode.d5.loss_dice: 0.0712  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0496  decode.d6.loss_dice: 0.0850  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0506  decode.d7.loss_dice: 0.0808  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0505  decode.d8.loss_dice: 0.0720
2023/12/31 17:57:27 - mmengine - INFO - Iter(train) [ 9850/90000]  base_lr: 9.0095e-05 lr: 9.0095e-06  eta: 22:26:23  time: 1.0071  data_time: 0.0111  memory: 18544  grad_norm: 5.8826  loss: 1.2474  decode.loss_cls: 0.0007  decode.loss_mask: 0.0457  decode.loss_dice: 0.0788  decode.d0.loss_cls: 0.0241  decode.d0.loss_mask: 0.0464  decode.d0.loss_dice: 0.0789  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0466  decode.d1.loss_dice: 0.0796  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0449  decode.d2.loss_dice: 0.0770  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0447  decode.d3.loss_dice: 0.0755  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0447  decode.d4.loss_dice: 0.0763  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0446  decode.d5.loss_dice: 0.0714  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0460  decode.d6.loss_dice: 0.0807  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0441  decode.d7.loss_dice: 0.0790  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0450  decode.d8.loss_dice: 0.0728
2023/12/31 17:58:17 - mmengine - INFO - Iter(train) [ 9900/90000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 22:25:32  time: 1.0060  data_time: 0.0111  memory: 18544  grad_norm: 24.8761  loss: 1.5060  decode.loss_cls: 0.0000  decode.loss_mask: 0.0469  decode.loss_dice: 0.1250  decode.d0.loss_cls: 0.0193  decode.d0.loss_mask: 0.0484  decode.d0.loss_dice: 0.0841  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0466  decode.d1.loss_dice: 0.1251  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0481  decode.d2.loss_dice: 0.0912  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0471  decode.d3.loss_dice: 0.0932  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0456  decode.d4.loss_dice: 0.0783  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0467  decode.d5.loss_dice: 0.1073  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0467  decode.d6.loss_dice: 0.1198  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0475  decode.d7.loss_dice: 0.0949  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0471  decode.d8.loss_dice: 0.0972
2023/12/31 17:59:07 - mmengine - INFO - Iter(train) [ 9950/90000]  base_lr: 8.9994e-05 lr: 8.9994e-06  eta: 22:24:41  time: 1.0059  data_time: 0.0114  memory: 18544  grad_norm: 7.9690  loss: 1.2861  decode.loss_cls: 0.0001  decode.loss_mask: 0.0475  decode.loss_dice: 0.0756  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0470  decode.d0.loss_dice: 0.0787  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0477  decode.d1.loss_dice: 0.0731  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0484  decode.d2.loss_dice: 0.0761  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0483  decode.d3.loss_dice: 0.0827  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0488  decode.d4.loss_dice: 0.0811  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0479  decode.d5.loss_dice: 0.0824  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0478  decode.d6.loss_dice: 0.0785  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0468  decode.d7.loss_dice: 0.0765  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0476  decode.d8.loss_dice: 0.0753
2023/12/31 17:59:58 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 17:59:58 - mmengine - INFO - Iter(train) [10000/90000]  base_lr: 8.9943e-05 lr: 8.9943e-06  eta: 22:23:50  time: 1.0049  data_time: 0.0108  memory: 18544  grad_norm: 9.2051  loss: 1.3910  decode.loss_cls: 0.0000  decode.loss_mask: 0.0468  decode.loss_dice: 0.0901  decode.d0.loss_cls: 0.0220  decode.d0.loss_mask: 0.0460  decode.d0.loss_dice: 0.0926  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0460  decode.d1.loss_dice: 0.0904  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0470  decode.d2.loss_dice: 0.0961  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0467  decode.d3.loss_dice: 0.0930  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0469  decode.d4.loss_dice: 0.0850  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0456  decode.d5.loss_dice: 0.0840  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0478  decode.d6.loss_dice: 0.0880  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0471  decode.d7.loss_dice: 0.0960  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0463  decode.d8.loss_dice: 0.0875
2023/12/31 17:59:58 - mmengine - INFO - Saving checkpoint at 10000 iterations
2023/12/31 18:00:07 - mmengine - INFO - Iter(val) [ 50/370]    eta: 0:00:50  time: 0.1534  data_time: 0.0036  memory: 3090  
2023/12/31 18:00:15 - mmengine - INFO - Iter(val) [100/370]    eta: 0:00:41  time: 0.1534  data_time: 0.0036  memory: 3090  
2023/12/31 18:00:22 - mmengine - INFO - Iter(val) [150/370]    eta: 0:00:34  time: 0.1534  data_time: 0.0035  memory: 3090  
2023/12/31 18:00:30 - mmengine - INFO - Iter(val) [200/370]    eta: 0:00:26  time: 0.1532  data_time: 0.0036  memory: 3090  
2023/12/31 18:00:38 - mmengine - INFO - Iter(val) [250/370]    eta: 0:00:18  time: 0.1535  data_time: 0.0035  memory: 3090  
2023/12/31 18:00:45 - mmengine - INFO - Iter(val) [300/370]    eta: 0:00:10  time: 0.1537  data_time: 0.0037  memory: 3090  
2023/12/31 18:00:53 - mmengine - INFO - Iter(val) [350/370]    eta: 0:00:03  time: 0.1535  data_time: 0.0036  memory: 3090  
2023/12/31 18:00:56 - mmengine - INFO - per class results:
2023/12/31 18:00:56 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.44 | 99.91 |
|     Billboard      | 83.37 | 85.31 |
|      Goal net      | 60.07 | 77.68 |
+--------------------+-------+-------+
2023/12/31 18:00:56 - mmengine - INFO - Iter(val) [370/370]    aAcc: 99.3700  mIoU: 80.9600  mAcc: 87.6300  data_time: 0.0040  time: 0.1540
2023/12/31 18:00:56 - mmengine - INFO - The previous best checkpoint /scratch/users/vgaspar/work_dirs/mask2former_r50_4xb2-90k_soccernet-1080x1920/best_mIoU_iter_5000.pth is removed
2023/12/31 18:00:57 - mmengine - INFO - The best checkpoint with 80.9600 mIoU at 10000 iter is saved to best_mIoU_iter_10000.pth.
2023/12/31 18:01:48 - mmengine - INFO - Iter(train) [10050/90000]  base_lr: 8.9892e-05 lr: 8.9892e-06  eta: 22:23:14  time: 1.0046  data_time: 0.0111  memory: 18544  grad_norm: 7.2589  loss: 1.2592  decode.loss_cls: 0.0000  decode.loss_mask: 0.0508  decode.loss_dice: 0.0706  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0509  decode.d0.loss_dice: 0.0698  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0507  decode.d1.loss_dice: 0.0659  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0514  decode.d2.loss_dice: 0.0696  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0529  decode.d3.loss_dice: 0.0725  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0523  decode.d4.loss_dice: 0.0761  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0515  decode.d5.loss_dice: 0.0690  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0516  decode.d6.loss_dice: 0.0749  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0515  decode.d7.loss_dice: 0.0730  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0524  decode.d8.loss_dice: 0.0751
2023/12/31 18:02:39 - mmengine - INFO - Iter(train) [10100/90000]  base_lr: 8.9842e-05 lr: 8.9842e-06  eta: 22:22:23  time: 1.0081  data_time: 0.0126  memory: 18544  grad_norm: 8.6332  loss: 1.3667  decode.loss_cls: 0.0003  decode.loss_mask: 0.0472  decode.loss_dice: 0.0849  decode.d0.loss_cls: 0.0269  decode.d0.loss_mask: 0.0481  decode.d0.loss_dice: 0.0850  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0493  decode.d1.loss_dice: 0.0854  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0489  decode.d2.loss_dice: 0.0841  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0495  decode.d3.loss_dice: 0.0832  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.0479  decode.d4.loss_dice: 0.0807  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0496  decode.d5.loss_dice: 0.0934  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0471  decode.d6.loss_dice: 0.0815  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0494  decode.d7.loss_dice: 0.0885  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0481  decode.d8.loss_dice: 0.0856
2023/12/31 18:03:29 - mmengine - INFO - Iter(train) [10150/90000]  base_lr: 8.9791e-05 lr: 8.9791e-06  eta: 22:21:32  time: 1.0047  data_time: 0.0109  memory: 18544  grad_norm: 16.8628  loss: 2.1358  decode.loss_cls: 0.0771  decode.loss_mask: 0.0472  decode.loss_dice: 0.1209  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0485  decode.d0.loss_dice: 0.1243  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.0461  decode.d1.loss_dice: 0.0858  decode.d2.loss_cls: 0.0432  decode.d2.loss_mask: 0.0473  decode.d2.loss_dice: 0.1168  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.0489  decode.d3.loss_dice: 0.1457  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.0472  decode.d4.loss_dice: 0.1465  decode.d5.loss_cls: 0.0462  decode.d5.loss_mask: 0.0482  decode.d5.loss_dice: 0.1161  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 0.0482  decode.d6.loss_dice: 0.0730  decode.d7.loss_cls: 0.0814  decode.d7.loss_mask: 0.0488  decode.d7.loss_dice: 0.1134  decode.d8.loss_cls: 0.0790  decode.d8.loss_mask: 0.0468  decode.d8.loss_dice: 0.0718
2023/12/31 18:04:19 - mmengine - INFO - Iter(train) [10200/90000]  base_lr: 8.9741e-05 lr: 8.9741e-06  eta: 22:20:41  time: 1.0063  data_time: 0.0114  memory: 18544  grad_norm: 5.2504  loss: 1.1739  decode.loss_cls: 0.0001  decode.loss_mask: 0.0449  decode.loss_dice: 0.0755  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0446  decode.d0.loss_dice: 0.0728  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0442  decode.d1.loss_dice: 0.0725  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0434  decode.d2.loss_dice: 0.0670  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0446  decode.d3.loss_dice: 0.0716  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0442  decode.d4.loss_dice: 0.0668  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0442  decode.d5.loss_dice: 0.0684  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0433  decode.d6.loss_dice: 0.0695  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0440  decode.d7.loss_dice: 0.0722  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0444  decode.d8.loss_dice: 0.0685
2023/12/31 18:05:10 - mmengine - INFO - Iter(train) [10250/90000]  base_lr: 8.9690e-05 lr: 8.9690e-06  eta: 22:19:49  time: 1.0068  data_time: 0.0117  memory: 18544  grad_norm: 5.5606  loss: 1.2055  decode.loss_cls: 0.0000  decode.loss_mask: 0.0470  decode.loss_dice: 0.0729  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.0467  decode.d0.loss_dice: 0.0704  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0467  decode.d1.loss_dice: 0.0771  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0461  decode.d2.loss_dice: 0.0728  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0464  decode.d3.loss_dice: 0.0732  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0440  decode.d4.loss_dice: 0.0715  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0439  decode.d5.loss_dice: 0.0674  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0460  decode.d6.loss_dice: 0.0729  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0469  decode.d7.loss_dice: 0.0709  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0464  decode.d8.loss_dice: 0.0712
2023/12/31 18:06:00 - mmengine - INFO - Iter(train) [10300/90000]  base_lr: 8.9639e-05 lr: 8.9639e-06  eta: 22:18:58  time: 1.0049  data_time: 0.0111  memory: 18544  grad_norm: 6.0810  loss: 1.1973  decode.loss_cls: 0.0000  decode.loss_mask: 0.0428  decode.loss_dice: 0.0734  decode.d0.loss_cls: 0.0363  decode.d0.loss_mask: 0.0423  decode.d0.loss_dice: 0.0730  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0428  decode.d1.loss_dice: 0.0735  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0434  decode.d2.loss_dice: 0.0765  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0432  decode.d3.loss_dice: 0.0705  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0414  decode.d4.loss_dice: 0.0696  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0438  decode.d5.loss_dice: 0.0762  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0438  decode.d6.loss_dice: 0.0739  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0427  decode.d7.loss_dice: 0.0708  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0428  decode.d8.loss_dice: 0.0739
2023/12/31 18:06:50 - mmengine - INFO - Iter(train) [10350/90000]  base_lr: 8.9589e-05 lr: 8.9589e-06  eta: 22:18:07  time: 1.0064  data_time: 0.0118  memory: 18544  grad_norm: 5.5825  loss: 1.1721  decode.loss_cls: 0.0002  decode.loss_mask: 0.0434  decode.loss_dice: 0.0633  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0453  decode.d0.loss_dice: 0.0702  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0457  decode.d1.loss_dice: 0.0696  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0458  decode.d2.loss_dice: 0.0669  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0460  decode.d3.loss_dice: 0.0691  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0476  decode.d4.loss_dice: 0.0728  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0462  decode.d5.loss_dice: 0.0697  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0464  decode.d6.loss_dice: 0.0671  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0455  decode.d7.loss_dice: 0.0671  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0463  decode.d8.loss_dice: 0.0696
2023/12/31 18:07:40 - mmengine - INFO - Iter(train) [10400/90000]  base_lr: 8.9538e-05 lr: 8.9538e-06  eta: 22:17:16  time: 1.0071  data_time: 0.0119  memory: 18544  grad_norm: 8.1336  loss: 1.2751  decode.loss_cls: 0.0001  decode.loss_mask: 0.0473  decode.loss_dice: 0.0788  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0474  decode.d0.loss_dice: 0.0790  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0467  decode.d1.loss_dice: 0.0759  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0483  decode.d2.loss_dice: 0.0800  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0473  decode.d3.loss_dice: 0.0806  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0466  decode.d4.loss_dice: 0.0771  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0462  decode.d5.loss_dice: 0.0753  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0465  decode.d6.loss_dice: 0.0762  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0477  decode.d7.loss_dice: 0.0751  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0469  decode.d8.loss_dice: 0.0795
2023/12/31 18:08:31 - mmengine - INFO - Iter(train) [10450/90000]  base_lr: 8.9487e-05 lr: 8.9487e-06  eta: 22:16:25  time: 1.0047  data_time: 0.0110  memory: 18544  grad_norm: 6.5082  loss: 1.2883  decode.loss_cls: 0.0000  decode.loss_mask: 0.0512  decode.loss_dice: 0.0721  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0503  decode.d0.loss_dice: 0.0707  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0510  decode.d1.loss_dice: 0.0718  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0523  decode.d2.loss_dice: 0.0790  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0515  decode.d3.loss_dice: 0.0746  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0536  decode.d4.loss_dice: 0.0769  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0521  decode.d5.loss_dice: 0.0759  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0511  decode.d6.loss_dice: 0.0761  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0513  decode.d7.loss_dice: 0.0758  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0516  decode.d8.loss_dice: 0.0745
2023/12/31 18:09:21 - mmengine - INFO - Iter(train) [10500/90000]  base_lr: 8.9437e-05 lr: 8.9437e-06  eta: 22:15:34  time: 1.0055  data_time: 0.0113  memory: 18544  grad_norm: 9.5373  loss: 1.4134  decode.loss_cls: 0.0000  decode.loss_mask: 0.0537  decode.loss_dice: 0.0835  decode.d0.loss_cls: 0.0288  decode.d0.loss_mask: 0.0551  decode.d0.loss_dice: 0.0795  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0561  decode.d1.loss_dice: 0.0849  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0564  decode.d2.loss_dice: 0.0806  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0545  decode.d3.loss_dice: 0.0850  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0545  decode.d4.loss_dice: 0.0819  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0567  decode.d5.loss_dice: 0.0875  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0562  decode.d6.loss_dice: 0.0830  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0541  decode.d7.loss_dice: 0.0798  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0552  decode.d8.loss_dice: 0.0858
2023/12/31 18:10:11 - mmengine - INFO - Iter(train) [10550/90000]  base_lr: 8.9386e-05 lr: 8.9386e-06  eta: 22:14:42  time: 1.0054  data_time: 0.0117  memory: 18544  grad_norm: 7.1127  loss: 1.2231  decode.loss_cls: 0.0000  decode.loss_mask: 0.0473  decode.loss_dice: 0.0741  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0475  decode.d0.loss_dice: 0.0729  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0481  decode.d1.loss_dice: 0.0747  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0483  decode.d2.loss_dice: 0.0716  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0473  decode.d3.loss_dice: 0.0701  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0480  decode.d4.loss_dice: 0.0731  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0469  decode.d5.loss_dice: 0.0697  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0478  decode.d6.loss_dice: 0.0742  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0471  decode.d7.loss_dice: 0.0725  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0457  decode.d8.loss_dice: 0.0695
2023/12/31 18:11:02 - mmengine - INFO - Iter(train) [10600/90000]  base_lr: 8.9336e-05 lr: 8.9336e-06  eta: 22:13:52  time: 1.0055  data_time: 0.0113  memory: 18544  grad_norm: 7.9462  loss: 1.2357  decode.loss_cls: 0.0000  decode.loss_mask: 0.0436  decode.loss_dice: 0.0764  decode.d0.loss_cls: 0.0215  decode.d0.loss_mask: 0.0419  decode.d0.loss_dice: 0.0731  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0425  decode.d1.loss_dice: 0.0772  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0440  decode.d2.loss_dice: 0.0767  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0434  decode.d3.loss_dice: 0.0797  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0431  decode.d4.loss_dice: 0.0833  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0429  decode.d5.loss_dice: 0.0768  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0436  decode.d6.loss_dice: 0.0780  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0441  decode.d7.loss_dice: 0.0802  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0441  decode.d8.loss_dice: 0.0794
2023/12/31 18:11:52 - mmengine - INFO - Iter(train) [10650/90000]  base_lr: 8.9285e-05 lr: 8.9285e-06  eta: 22:13:01  time: 1.0059  data_time: 0.0116  memory: 18544  grad_norm: 6.4216  loss: 1.2574  decode.loss_cls: 0.0000  decode.loss_mask: 0.0509  decode.loss_dice: 0.0763  decode.d0.loss_cls: 0.0269  decode.d0.loss_mask: 0.0509  decode.d0.loss_dice: 0.0762  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0496  decode.d1.loss_dice: 0.0698  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0502  decode.d2.loss_dice: 0.0698  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0496  decode.d3.loss_dice: 0.0715  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0492  decode.d4.loss_dice: 0.0724  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0492  decode.d5.loss_dice: 0.0706  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0505  decode.d6.loss_dice: 0.0740  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0498  decode.d7.loss_dice: 0.0735  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0512  decode.d8.loss_dice: 0.0751
2023/12/31 18:12:42 - mmengine - INFO - Iter(train) [10700/90000]  base_lr: 8.9234e-05 lr: 8.9234e-06  eta: 22:12:10  time: 1.0062  data_time: 0.0114  memory: 18544  grad_norm: 27.9872  loss: 1.6806  decode.loss_cls: 0.0013  decode.loss_mask: 0.0440  decode.loss_dice: 0.1565  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0429  decode.d0.loss_dice: 0.1089  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0431  decode.d1.loss_dice: 0.1239  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0420  decode.d2.loss_dice: 0.1416  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0423  decode.d3.loss_dice: 0.1189  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0431  decode.d4.loss_dice: 0.1263  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0431  decode.d5.loss_dice: 0.1272  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0440  decode.d6.loss_dice: 0.1001  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0447  decode.d7.loss_dice: 0.1217  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0432  decode.d8.loss_dice: 0.0935
2023/12/31 18:13:33 - mmengine - INFO - Iter(train) [10750/90000]  base_lr: 8.9184e-05 lr: 8.9184e-06  eta: 22:11:19  time: 1.0068  data_time: 0.0114  memory: 18544  grad_norm: 12.3553  loss: 1.2907  decode.loss_cls: 0.0000  decode.loss_mask: 0.0473  decode.loss_dice: 0.0736  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0487  decode.d0.loss_dice: 0.0790  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0473  decode.d1.loss_dice: 0.0738  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0499  decode.d2.loss_dice: 0.0792  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0490  decode.d3.loss_dice: 0.0790  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0467  decode.d4.loss_dice: 0.0788  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0481  decode.d5.loss_dice: 0.0805  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0493  decode.d6.loss_dice: 0.0780  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0474  decode.d7.loss_dice: 0.0817  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0491  decode.d8.loss_dice: 0.0778
2023/12/31 18:14:23 - mmengine - INFO - Iter(train) [10800/90000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 22:10:29  time: 1.0080  data_time: 0.0119  memory: 18544  grad_norm: 19.6936  loss: 1.2307  decode.loss_cls: 0.0000  decode.loss_mask: 0.0441  decode.loss_dice: 0.0746  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0438  decode.d0.loss_dice: 0.0786  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0439  decode.d1.loss_dice: 0.0805  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0437  decode.d2.loss_dice: 0.0758  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0438  decode.d3.loss_dice: 0.0770  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0450  decode.d4.loss_dice: 0.0811  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0444  decode.d5.loss_dice: 0.0725  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0430  decode.d6.loss_dice: 0.0723  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0444  decode.d7.loss_dice: 0.0761  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0428  decode.d8.loss_dice: 0.0765
2023/12/31 18:15:13 - mmengine - INFO - Iter(train) [10850/90000]  base_lr: 8.9082e-05 lr: 8.9082e-06  eta: 22:09:38  time: 1.0059  data_time: 0.0113  memory: 18544  grad_norm: 24.7074  loss: 1.4414  decode.loss_cls: 0.0000  decode.loss_mask: 0.0630  decode.loss_dice: 0.0772  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0682  decode.d0.loss_dice: 0.0758  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0637  decode.d1.loss_dice: 0.0763  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0649  decode.d2.loss_dice: 0.0754  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0667  decode.d3.loss_dice: 0.0777  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0639  decode.d4.loss_dice: 0.0781  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0618  decode.d5.loss_dice: 0.0767  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0636  decode.d6.loss_dice: 0.0793  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0617  decode.d7.loss_dice: 0.0764  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0654  decode.d8.loss_dice: 0.0787
2023/12/31 18:16:04 - mmengine - INFO - Iter(train) [10900/90000]  base_lr: 8.9032e-05 lr: 8.9032e-06  eta: 22:08:47  time: 1.0051  data_time: 0.0114  memory: 18544  grad_norm: 8.0774  loss: 1.2393  decode.loss_cls: 0.0012  decode.loss_mask: 0.0449  decode.loss_dice: 0.0718  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0448  decode.d0.loss_dice: 0.0787  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0448  decode.d1.loss_dice: 0.0733  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0445  decode.d2.loss_dice: 0.0727  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0459  decode.d3.loss_dice: 0.0760  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0456  decode.d4.loss_dice: 0.0740  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0440  decode.d5.loss_dice: 0.0800  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0452  decode.d6.loss_dice: 0.0873  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0448  decode.d7.loss_dice: 0.0776  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0445  decode.d8.loss_dice: 0.0710
2023/12/31 18:16:54 - mmengine - INFO - Iter(train) [10950/90000]  base_lr: 8.8981e-05 lr: 8.8981e-06  eta: 22:07:56  time: 1.0085  data_time: 0.0126  memory: 18544  grad_norm: 5.3428  loss: 1.1555  decode.loss_cls: 0.0000  decode.loss_mask: 0.0454  decode.loss_dice: 0.0653  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0462  decode.d0.loss_dice: 0.0676  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0450  decode.d1.loss_dice: 0.0681  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0454  decode.d2.loss_dice: 0.0685  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0454  decode.d3.loss_dice: 0.0683  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0455  decode.d4.loss_dice: 0.0672  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0445  decode.d5.loss_dice: 0.0672  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0458  decode.d6.loss_dice: 0.0683  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0442  decode.d7.loss_dice: 0.0699  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0460  decode.d8.loss_dice: 0.0667
2023/12/31 18:17:45 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 18:17:45 - mmengine - INFO - Iter(train) [11000/90000]  base_lr: 8.8930e-05 lr: 8.8930e-06  eta: 22:07:06  time: 1.0071  data_time: 0.0122  memory: 18544  grad_norm: 11.0845  loss: 1.3305  decode.loss_cls: 0.0000  decode.loss_mask: 0.0573  decode.loss_dice: 0.0752  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.0560  decode.d0.loss_dice: 0.0694  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0582  decode.d1.loss_dice: 0.0717  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0568  decode.d2.loss_dice: 0.0715  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0564  decode.d3.loss_dice: 0.0722  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0576  decode.d4.loss_dice: 0.0744  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0575  decode.d5.loss_dice: 0.0766  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0563  decode.d6.loss_dice: 0.0705  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0576  decode.d7.loss_dice: 0.0733  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0584  decode.d8.loss_dice: 0.0736
2023/12/31 18:18:35 - mmengine - INFO - Iter(train) [11050/90000]  base_lr: 8.8880e-05 lr: 8.8880e-06  eta: 22:06:16  time: 1.0074  data_time: 0.0120  memory: 18544  grad_norm: 5.1743  loss: 1.1032  decode.loss_cls: 0.0000  decode.loss_mask: 0.0422  decode.loss_dice: 0.0651  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.0430  decode.d0.loss_dice: 0.0629  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0418  decode.d1.loss_dice: 0.0639  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0433  decode.d2.loss_dice: 0.0674  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0436  decode.d3.loss_dice: 0.0664  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0425  decode.d4.loss_dice: 0.0677  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0440  decode.d5.loss_dice: 0.0664  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0432  decode.d6.loss_dice: 0.0661  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0426  decode.d7.loss_dice: 0.0630  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0425  decode.d8.loss_dice: 0.0624
2023/12/31 18:19:26 - mmengine - INFO - Iter(train) [11100/90000]  base_lr: 8.8829e-05 lr: 8.8829e-06  eta: 22:05:26  time: 1.0078  data_time: 0.0128  memory: 18544  grad_norm: 5.4778  loss: 1.1590  decode.loss_cls: 0.0000  decode.loss_mask: 0.0473  decode.loss_dice: 0.0720  decode.d0.loss_cls: 0.0287  decode.d0.loss_mask: 0.0462  decode.d0.loss_dice: 0.0645  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0476  decode.d1.loss_dice: 0.0655  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0460  decode.d2.loss_dice: 0.0648  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0466  decode.d3.loss_dice: 0.0688  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0461  decode.d4.loss_dice: 0.0677  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0462  decode.d5.loss_dice: 0.0676  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0462  decode.d6.loss_dice: 0.0649  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0459  decode.d7.loss_dice: 0.0643  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0461  decode.d8.loss_dice: 0.0660
2023/12/31 18:20:16 - mmengine - INFO - Iter(train) [11150/90000]  base_lr: 8.8778e-05 lr: 8.8778e-06  eta: 22:04:36  time: 1.0067  data_time: 0.0119  memory: 18544  grad_norm: 5.1108  loss: 1.1163  decode.loss_cls: 0.0000  decode.loss_mask: 0.0438  decode.loss_dice: 0.0674  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.0430  decode.d0.loss_dice: 0.0661  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0438  decode.d1.loss_dice: 0.0652  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0441  decode.d2.loss_dice: 0.0686  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0433  decode.d3.loss_dice: 0.0641  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0432  decode.d4.loss_dice: 0.0643  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0428  decode.d5.loss_dice: 0.0641  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0439  decode.d6.loss_dice: 0.0672  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0439  decode.d7.loss_dice: 0.0631  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0440  decode.d8.loss_dice: 0.0671
2023/12/31 18:21:06 - mmengine - INFO - Iter(train) [11200/90000]  base_lr: 8.8728e-05 lr: 8.8728e-06  eta: 22:03:45  time: 1.0068  data_time: 0.0115  memory: 18544  grad_norm: 8.6705  loss: 1.2540  decode.loss_cls: 0.0000  decode.loss_mask: 0.0559  decode.loss_dice: 0.0663  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0562  decode.d0.loss_dice: 0.0651  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0556  decode.d1.loss_dice: 0.0669  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0553  decode.d2.loss_dice: 0.0651  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0553  decode.d3.loss_dice: 0.0681  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0563  decode.d4.loss_dice: 0.0695  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0551  decode.d5.loss_dice: 0.0676  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0557  decode.d6.loss_dice: 0.0651  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0562  decode.d7.loss_dice: 0.0686  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0544  decode.d8.loss_dice: 0.0688
2023/12/31 18:21:57 - mmengine - INFO - Iter(train) [11250/90000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 22:02:55  time: 1.0075  data_time: 0.0125  memory: 18544  grad_norm: 8.3629  loss: 1.2958  decode.loss_cls: 0.0000  decode.loss_mask: 0.0482  decode.loss_dice: 0.0810  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.0461  decode.d0.loss_dice: 0.0730  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0461  decode.d1.loss_dice: 0.0791  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0480  decode.d2.loss_dice: 0.0806  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0477  decode.d3.loss_dice: 0.0800  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0467  decode.d4.loss_dice: 0.0789  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0466  decode.d5.loss_dice: 0.0810  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0479  decode.d6.loss_dice: 0.0783  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0477  decode.d7.loss_dice: 0.0870  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0472  decode.d8.loss_dice: 0.0813
2023/12/31 18:22:47 - mmengine - INFO - Iter(train) [11300/90000]  base_lr: 8.8626e-05 lr: 8.8626e-06  eta: 22:02:03  time: 1.0067  data_time: 0.0120  memory: 18544  grad_norm: 15.6761  loss: 1.3551  decode.loss_cls: 0.0000  decode.loss_mask: 0.0480  decode.loss_dice: 0.0853  decode.d0.loss_cls: 0.0220  decode.d0.loss_mask: 0.0473  decode.d0.loss_dice: 0.0840  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0477  decode.d1.loss_dice: 0.0873  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0463  decode.d2.loss_dice: 0.0812  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0507  decode.d3.loss_dice: 0.0863  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0485  decode.d4.loss_dice: 0.0858  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0482  decode.d5.loss_dice: 0.0829  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0473  decode.d6.loss_dice: 0.0829  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0486  decode.d7.loss_dice: 0.0892  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0484  decode.d8.loss_dice: 0.0873
2023/12/31 18:23:37 - mmengine - INFO - Iter(train) [11350/90000]  base_lr: 8.8576e-05 lr: 8.8576e-06  eta: 22:01:13  time: 1.0052  data_time: 0.0118  memory: 18544  grad_norm: 25.5739  loss: 1.6058  decode.loss_cls: 0.0000  decode.loss_mask: 0.0753  decode.loss_dice: 0.0845  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0771  decode.d0.loss_dice: 0.0847  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0760  decode.d1.loss_dice: 0.0839  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0717  decode.d2.loss_dice: 0.0878  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0716  decode.d3.loss_dice: 0.0832  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0728  decode.d4.loss_dice: 0.0817  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0719  decode.d5.loss_dice: 0.0785  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0777  decode.d6.loss_dice: 0.0824  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0731  decode.d7.loss_dice: 0.0837  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0736  decode.d8.loss_dice: 0.0866
2023/12/31 18:24:28 - mmengine - INFO - Iter(train) [11400/90000]  base_lr: 8.8525e-05 lr: 8.8525e-06  eta: 22:00:22  time: 1.0082  data_time: 0.0128  memory: 18544  grad_norm: 41.2174  loss: 2.0053  decode.loss_cls: 0.0486  decode.loss_mask: 0.0435  decode.loss_dice: 0.1214  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.0437  decode.d0.loss_dice: 0.0971  decode.d1.loss_cls: 0.1483  decode.d1.loss_mask: 0.0440  decode.d1.loss_dice: 0.1117  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.0452  decode.d2.loss_dice: 0.0915  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.0437  decode.d3.loss_dice: 0.0775  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.0449  decode.d4.loss_dice: 0.1028  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.0458  decode.d5.loss_dice: 0.1002  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.0444  decode.d6.loss_dice: 0.0923  decode.d7.loss_cls: 0.0468  decode.d7.loss_mask: 0.0424  decode.d7.loss_dice: 0.0939  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.0424  decode.d8.loss_dice: 0.0713
2023/12/31 18:25:18 - mmengine - INFO - Iter(train) [11450/90000]  base_lr: 8.8474e-05 lr: 8.8474e-06  eta: 21:59:31  time: 1.0068  data_time: 0.0122  memory: 18544  grad_norm: 6.0970  loss: 1.2431  decode.loss_cls: 0.0000  decode.loss_mask: 0.0442  decode.loss_dice: 0.0753  decode.d0.loss_cls: 0.0222  decode.d0.loss_mask: 0.0432  decode.d0.loss_dice: 0.0809  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0438  decode.d1.loss_dice: 0.0768  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0446  decode.d2.loss_dice: 0.0828  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0439  decode.d3.loss_dice: 0.0785  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0441  decode.d4.loss_dice: 0.0749  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0435  decode.d5.loss_dice: 0.0751  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0444  decode.d6.loss_dice: 0.0792  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0430  decode.d7.loss_dice: 0.0727  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0458  decode.d8.loss_dice: 0.0842
2023/12/31 18:26:08 - mmengine - INFO - Iter(train) [11500/90000]  base_lr: 8.8424e-05 lr: 8.8424e-06  eta: 21:58:41  time: 1.0072  data_time: 0.0119  memory: 18544  grad_norm: 8.5082  loss: 1.1830  decode.loss_cls: 0.0000  decode.loss_mask: 0.0448  decode.loss_dice: 0.0719  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0441  decode.d0.loss_dice: 0.0716  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0440  decode.d1.loss_dice: 0.0707  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0435  decode.d2.loss_dice: 0.0712  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0441  decode.d3.loss_dice: 0.0728  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0456  decode.d4.loss_dice: 0.0718  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0447  decode.d5.loss_dice: 0.0657  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0448  decode.d6.loss_dice: 0.0701  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0449  decode.d7.loss_dice: 0.0743  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0436  decode.d8.loss_dice: 0.0722
2023/12/31 18:26:59 - mmengine - INFO - Iter(train) [11550/90000]  base_lr: 8.8373e-05 lr: 8.8373e-06  eta: 21:57:51  time: 1.0087  data_time: 0.0130  memory: 18544  grad_norm: 7.9981  loss: 1.1616  decode.loss_cls: 0.0000  decode.loss_mask: 0.0447  decode.loss_dice: 0.0679  decode.d0.loss_cls: 0.0258  decode.d0.loss_mask: 0.0449  decode.d0.loss_dice: 0.0664  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.0462  decode.d1.loss_dice: 0.0677  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0461  decode.d2.loss_dice: 0.0686  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0451  decode.d3.loss_dice: 0.0650  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0455  decode.d4.loss_dice: 0.0710  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0447  decode.d5.loss_dice: 0.0688  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0454  decode.d6.loss_dice: 0.0705  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0449  decode.d7.loss_dice: 0.0681  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0457  decode.d8.loss_dice: 0.0681
2023/12/31 18:27:49 - mmengine - INFO - Iter(train) [11600/90000]  base_lr: 8.8322e-05 lr: 8.8322e-06  eta: 21:57:00  time: 1.0077  data_time: 0.0123  memory: 18544  grad_norm: 18.4257  loss: 1.2503  decode.loss_cls: 0.0000  decode.loss_mask: 0.0442  decode.loss_dice: 0.0793  decode.d0.loss_cls: 0.0321  decode.d0.loss_mask: 0.0423  decode.d0.loss_dice: 0.0773  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0427  decode.d1.loss_dice: 0.0816  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0429  decode.d2.loss_dice: 0.0771  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0420  decode.d3.loss_dice: 0.0774  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0431  decode.d4.loss_dice: 0.0792  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0442  decode.d5.loss_dice: 0.0817  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0435  decode.d6.loss_dice: 0.0770  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0421  decode.d7.loss_dice: 0.0780  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0420  decode.d8.loss_dice: 0.0805
2023/12/31 18:28:40 - mmengine - INFO - Iter(train) [11650/90000]  base_lr: 8.8272e-05 lr: 8.8272e-06  eta: 21:56:09  time: 1.0063  data_time: 0.0119  memory: 18544  grad_norm: 5.6848  loss: 1.1775  decode.loss_cls: 0.0000  decode.loss_mask: 0.0440  decode.loss_dice: 0.0723  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.0439  decode.d0.loss_dice: 0.0705  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0444  decode.d1.loss_dice: 0.0732  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0437  decode.d2.loss_dice: 0.0697  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0443  decode.d3.loss_dice: 0.0717  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0435  decode.d4.loss_dice: 0.0709  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0434  decode.d5.loss_dice: 0.0685  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0429  decode.d6.loss_dice: 0.0744  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0445  decode.d7.loss_dice: 0.0739  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0432  decode.d8.loss_dice: 0.0695
2023/12/31 18:29:30 - mmengine - INFO - Iter(train) [11700/90000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 21:55:19  time: 1.0066  data_time: 0.0131  memory: 18544  grad_norm: 10.6320  loss: 1.2759  decode.loss_cls: 0.0000  decode.loss_mask: 0.0506  decode.loss_dice: 0.0738  decode.d0.loss_cls: 0.0390  decode.d0.loss_mask: 0.0505  decode.d0.loss_dice: 0.0750  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0518  decode.d1.loss_dice: 0.0753  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0498  decode.d2.loss_dice: 0.0739  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0499  decode.d3.loss_dice: 0.0725  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0512  decode.d4.loss_dice: 0.0735  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0520  decode.d5.loss_dice: 0.0716  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0500  decode.d6.loss_dice: 0.0697  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0501  decode.d7.loss_dice: 0.0734  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0495  decode.d8.loss_dice: 0.0725
2023/12/31 18:30:20 - mmengine - INFO - Iter(train) [11750/90000]  base_lr: 8.8170e-05 lr: 8.8170e-06  eta: 21:54:28  time: 1.0080  data_time: 0.0125  memory: 18544  grad_norm: 6.7498  loss: 1.1660  decode.loss_cls: 0.0000  decode.loss_mask: 0.0471  decode.loss_dice: 0.0656  decode.d0.loss_cls: 0.0284  decode.d0.loss_mask: 0.0485  decode.d0.loss_dice: 0.0642  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0501  decode.d1.loss_dice: 0.0670  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0484  decode.d2.loss_dice: 0.0644  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0478  decode.d3.loss_dice: 0.0606  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0484  decode.d4.loss_dice: 0.0678  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0494  decode.d5.loss_dice: 0.0669  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0494  decode.d6.loss_dice: 0.0655  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0489  decode.d7.loss_dice: 0.0642  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0492  decode.d8.loss_dice: 0.0641
2023/12/31 18:31:11 - mmengine - INFO - Iter(train) [11800/90000]  base_lr: 8.8120e-05 lr: 8.8120e-06  eta: 21:53:38  time: 1.0078  data_time: 0.0127  memory: 18544  grad_norm: 6.5126  loss: 1.1356  decode.loss_cls: 0.0000  decode.loss_mask: 0.0478  decode.loss_dice: 0.0613  decode.d0.loss_cls: 0.0296  decode.d0.loss_mask: 0.0491  decode.d0.loss_dice: 0.0637  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0485  decode.d1.loss_dice: 0.0634  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0487  decode.d2.loss_dice: 0.0646  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0480  decode.d3.loss_dice: 0.0613  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0472  decode.d4.loss_dice: 0.0643  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0471  decode.d5.loss_dice: 0.0606  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0471  decode.d6.loss_dice: 0.0609  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0477  decode.d7.loss_dice: 0.0652  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0472  decode.d8.loss_dice: 0.0622
2023/12/31 18:32:01 - mmengine - INFO - Iter(train) [11850/90000]  base_lr: 8.8069e-05 lr: 8.8069e-06  eta: 21:52:48  time: 1.0079  data_time: 0.0128  memory: 18544  grad_norm: 14.0763  loss: 1.1668  decode.loss_cls: 0.0000  decode.loss_mask: 0.0424  decode.loss_dice: 0.0635  decode.d0.loss_cls: 0.0383  decode.d0.loss_mask: 0.0424  decode.d0.loss_dice: 0.0954  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.0424  decode.d1.loss_dice: 0.0681  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0415  decode.d2.loss_dice: 0.0606  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0436  decode.d3.loss_dice: 0.0718  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0429  decode.d4.loss_dice: 0.0659  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0413  decode.d5.loss_dice: 0.0658  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0416  decode.d6.loss_dice: 0.0654  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0424  decode.d7.loss_dice: 0.0656  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0417  decode.d8.loss_dice: 0.0794
2023/12/31 18:32:51 - mmengine - INFO - Iter(train) [11900/90000]  base_lr: 8.8018e-05 lr: 8.8018e-06  eta: 21:51:57  time: 1.0070  data_time: 0.0122  memory: 18544  grad_norm: 7.8759  loss: 1.3066  decode.loss_cls: 0.0000  decode.loss_mask: 0.0424  decode.loss_dice: 0.0917  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0413  decode.d0.loss_dice: 0.0922  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0423  decode.d1.loss_dice: 0.0836  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.0411  decode.d2.loss_dice: 0.0787  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.0416  decode.d3.loss_dice: 0.0718  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0422  decode.d4.loss_dice: 0.0733  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0435  decode.d5.loss_dice: 0.0791  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0411  decode.d6.loss_dice: 0.0892  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0432  decode.d7.loss_dice: 0.1071  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0414  decode.d8.loss_dice: 0.0931
2023/12/31 18:33:42 - mmengine - INFO - Iter(train) [11950/90000]  base_lr: 8.7967e-05 lr: 8.7967e-06  eta: 21:51:07  time: 1.0061  data_time: 0.0120  memory: 18544  grad_norm: 5.9066  loss: 1.0881  decode.loss_cls: 0.0000  decode.loss_mask: 0.0430  decode.loss_dice: 0.0644  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0421  decode.d0.loss_dice: 0.0633  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0420  decode.d1.loss_dice: 0.0617  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0430  decode.d2.loss_dice: 0.0626  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0435  decode.d3.loss_dice: 0.0648  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0423  decode.d4.loss_dice: 0.0609  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0427  decode.d5.loss_dice: 0.0650  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0429  decode.d6.loss_dice: 0.0651  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0438  decode.d7.loss_dice: 0.0664  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0423  decode.d8.loss_dice: 0.0599
2023/12/31 18:34:32 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 18:34:32 - mmengine - INFO - Iter(train) [12000/90000]  base_lr: 8.7917e-05 lr: 8.7917e-06  eta: 21:50:16  time: 1.0085  data_time: 0.0136  memory: 18544  grad_norm: 12.1968  loss: 1.1534  decode.loss_cls: 0.0000  decode.loss_mask: 0.0430  decode.loss_dice: 0.0713  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.0408  decode.d0.loss_dice: 0.0681  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0419  decode.d1.loss_dice: 0.0677  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0427  decode.d2.loss_dice: 0.0718  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0424  decode.d3.loss_dice: 0.0670  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0420  decode.d4.loss_dice: 0.0714  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0438  decode.d5.loss_dice: 0.0777  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0429  decode.d6.loss_dice: 0.0676  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0432  decode.d7.loss_dice: 0.0756  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0419  decode.d8.loss_dice: 0.0657
2023/12/31 18:35:23 - mmengine - INFO - Iter(train) [12050/90000]  base_lr: 8.7866e-05 lr: 8.7866e-06  eta: 21:49:25  time: 1.0065  data_time: 0.0124  memory: 18544  grad_norm: 8.2858  loss: 1.2798  decode.loss_cls: 0.0000  decode.loss_mask: 0.0469  decode.loss_dice: 0.0763  decode.d0.loss_cls: 0.0322  decode.d0.loss_mask: 0.0473  decode.d0.loss_dice: 0.0911  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0470  decode.d1.loss_dice: 0.0892  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0483  decode.d2.loss_dice: 0.0680  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0463  decode.d3.loss_dice: 0.0898  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0488  decode.d4.loss_dice: 0.0843  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0474  decode.d5.loss_dice: 0.0655  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0466  decode.d6.loss_dice: 0.0645  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0460  decode.d7.loss_dice: 0.0660  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0489  decode.d8.loss_dice: 0.0793
2023/12/31 18:36:13 - mmengine - INFO - Iter(train) [12100/90000]  base_lr: 8.7815e-05 lr: 8.7815e-06  eta: 21:48:35  time: 1.0061  data_time: 0.0124  memory: 18544  grad_norm: 11.7425  loss: 1.2858  decode.loss_cls: 0.0001  decode.loss_mask: 0.0508  decode.loss_dice: 0.0695  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0508  decode.d0.loss_dice: 0.0728  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0505  decode.d1.loss_dice: 0.0772  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0486  decode.d2.loss_dice: 0.0727  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0488  decode.d3.loss_dice: 0.0728  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0502  decode.d4.loss_dice: 0.0711  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0495  decode.d5.loss_dice: 0.0709  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0504  decode.d6.loss_dice: 0.0690  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0509  decode.d7.loss_dice: 0.0736  decode.d8.loss_cls: 0.0356  decode.d8.loss_mask: 0.0498  decode.d8.loss_dice: 0.0709
2023/12/31 18:37:03 - mmengine - INFO - Iter(train) [12150/90000]  base_lr: 8.7764e-05 lr: 8.7764e-06  eta: 21:47:45  time: 1.0091  data_time: 0.0135  memory: 18544  grad_norm: 5.4938  loss: 1.0966  decode.loss_cls: 0.0000  decode.loss_mask: 0.0452  decode.loss_dice: 0.0622  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0453  decode.d0.loss_dice: 0.0610  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0447  decode.d1.loss_dice: 0.0606  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0449  decode.d2.loss_dice: 0.0609  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0448  decode.d3.loss_dice: 0.0611  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0461  decode.d4.loss_dice: 0.0629  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0451  decode.d5.loss_dice: 0.0621  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0461  decode.d6.loss_dice: 0.0642  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0460  decode.d7.loss_dice: 0.0593  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0441  decode.d8.loss_dice: 0.0631
2023/12/31 18:37:54 - mmengine - INFO - Iter(train) [12200/90000]  base_lr: 8.7714e-05 lr: 8.7714e-06  eta: 21:46:54  time: 1.0078  data_time: 0.0121  memory: 18544  grad_norm: 17.3752  loss: 1.7815  decode.loss_cls: 0.0000  decode.loss_mask: 0.0703  decode.loss_dice: 0.0942  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0737  decode.d0.loss_dice: 0.0773  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0718  decode.d1.loss_dice: 0.1014  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0736  decode.d2.loss_dice: 0.1323  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0707  decode.d3.loss_dice: 0.1153  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0708  decode.d4.loss_dice: 0.0847  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0718  decode.d5.loss_dice: 0.1326  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0720  decode.d6.loss_dice: 0.0978  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0703  decode.d7.loss_dice: 0.1137  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0708  decode.d8.loss_dice: 0.0915
2023/12/31 18:38:44 - mmengine - INFO - Iter(train) [12250/90000]  base_lr: 8.7663e-05 lr: 8.7663e-06  eta: 21:46:04  time: 1.0087  data_time: 0.0126  memory: 18544  grad_norm: 13.6843  loss: 1.4090  decode.loss_cls: 0.0000  decode.loss_mask: 0.0504  decode.loss_dice: 0.0917  decode.d0.loss_cls: 0.0193  decode.d0.loss_mask: 0.0510  decode.d0.loss_dice: 0.0878  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0494  decode.d1.loss_dice: 0.0875  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0503  decode.d2.loss_dice: 0.0874  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0517  decode.d3.loss_dice: 0.0927  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0512  decode.d4.loss_dice: 0.0899  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0497  decode.d5.loss_dice: 0.0873  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0493  decode.d6.loss_dice: 0.0887  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0487  decode.d7.loss_dice: 0.0870  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0501  decode.d8.loss_dice: 0.0878
2023/12/31 18:39:35 - mmengine - INFO - Iter(train) [12300/90000]  base_lr: 8.7612e-05 lr: 8.7612e-06  eta: 21:45:14  time: 1.0099  data_time: 0.0137  memory: 18544  grad_norm: 5.8525  loss: 1.1487  decode.loss_cls: 0.0000  decode.loss_mask: 0.0421  decode.loss_dice: 0.0679  decode.d0.loss_cls: 0.0236  decode.d0.loss_mask: 0.0443  decode.d0.loss_dice: 0.0696  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0430  decode.d1.loss_dice: 0.0696  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0432  decode.d2.loss_dice: 0.0716  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0428  decode.d3.loss_dice: 0.0711  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0425  decode.d4.loss_dice: 0.0686  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0435  decode.d5.loss_dice: 0.0708  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0427  decode.d6.loss_dice: 0.0700  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0438  decode.d7.loss_dice: 0.0673  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0426  decode.d8.loss_dice: 0.0678
2023/12/31 18:40:25 - mmengine - INFO - Iter(train) [12350/90000]  base_lr: 8.7562e-05 lr: 8.7562e-06  eta: 21:44:24  time: 1.0074  data_time: 0.0117  memory: 18544  grad_norm: 17.5615  loss: 1.9224  decode.loss_cls: 0.0000  decode.loss_mask: 0.0419  decode.loss_dice: 0.1468  decode.d0.loss_cls: 0.0166  decode.d0.loss_mask: 0.0427  decode.d0.loss_dice: 0.1491  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0424  decode.d1.loss_dice: 0.1426  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0429  decode.d2.loss_dice: 0.1451  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0425  decode.d3.loss_dice: 0.1531  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0436  decode.d4.loss_dice: 0.1543  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0415  decode.d5.loss_dice: 0.1334  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0424  decode.d6.loss_dice: 0.1523  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0415  decode.d7.loss_dice: 0.1520  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0433  decode.d8.loss_dice: 0.1525
2023/12/31 18:41:16 - mmengine - INFO - Iter(train) [12400/90000]  base_lr: 8.7511e-05 lr: 8.7511e-06  eta: 21:43:34  time: 1.0078  data_time: 0.0125  memory: 18544  grad_norm: 7.2212  loss: 1.1292  decode.loss_cls: 0.0001  decode.loss_mask: 0.0418  decode.loss_dice: 0.0703  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.0425  decode.d0.loss_dice: 0.0776  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0421  decode.d1.loss_dice: 0.0662  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0414  decode.d2.loss_dice: 0.0643  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0421  decode.d3.loss_dice: 0.0722  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0416  decode.d4.loss_dice: 0.0633  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0414  decode.d5.loss_dice: 0.0632  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0413  decode.d6.loss_dice: 0.0646  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0426  decode.d7.loss_dice: 0.0722  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0418  decode.d8.loss_dice: 0.0696
2023/12/31 18:42:06 - mmengine - INFO - Iter(train) [12450/90000]  base_lr: 8.7460e-05 lr: 8.7460e-06  eta: 21:42:44  time: 1.0081  data_time: 0.0131  memory: 18544  grad_norm: 6.9248  loss: 1.2079  decode.loss_cls: 0.0000  decode.loss_mask: 0.0497  decode.loss_dice: 0.0682  decode.d0.loss_cls: 0.0321  decode.d0.loss_mask: 0.0492  decode.d0.loss_dice: 0.0685  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0500  decode.d1.loss_dice: 0.0651  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0499  decode.d2.loss_dice: 0.0733  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0493  decode.d3.loss_dice: 0.0697  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0495  decode.d4.loss_dice: 0.0689  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0477  decode.d5.loss_dice: 0.0679  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0492  decode.d6.loss_dice: 0.0692  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0494  decode.d7.loss_dice: 0.0675  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0486  decode.d8.loss_dice: 0.0649
2023/12/31 18:42:56 - mmengine - INFO - Iter(train) [12500/90000]  base_lr: 8.7409e-05 lr: 8.7409e-06  eta: 21:41:54  time: 1.0066  data_time: 0.0120  memory: 18544  grad_norm: 6.3535  loss: 1.1601  decode.loss_cls: 0.0000  decode.loss_mask: 0.0444  decode.loss_dice: 0.0651  decode.d0.loss_cls: 0.0333  decode.d0.loss_mask: 0.0428  decode.d0.loss_dice: 0.0690  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0440  decode.d1.loss_dice: 0.0695  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0429  decode.d2.loss_dice: 0.0679  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0430  decode.d3.loss_dice: 0.0738  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0426  decode.d4.loss_dice: 0.0676  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0424  decode.d5.loss_dice: 0.0685  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0434  decode.d6.loss_dice: 0.0715  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0433  decode.d7.loss_dice: 0.0694  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0451  decode.d8.loss_dice: 0.0705
2023/12/31 18:43:47 - mmengine - INFO - Iter(train) [12550/90000]  base_lr: 8.7359e-05 lr: 8.7359e-06  eta: 21:41:04  time: 1.0058  data_time: 0.0120  memory: 18544  grad_norm: 9.3182  loss: 1.2798  decode.loss_cls: 0.0000  decode.loss_mask: 0.0432  decode.loss_dice: 0.0813  decode.d0.loss_cls: 0.0353  decode.d0.loss_mask: 0.0442  decode.d0.loss_dice: 0.0816  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0435  decode.d1.loss_dice: 0.0823  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0439  decode.d2.loss_dice: 0.0776  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0445  decode.d3.loss_dice: 0.0782  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0431  decode.d4.loss_dice: 0.0776  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0427  decode.d5.loss_dice: 0.0747  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0450  decode.d6.loss_dice: 0.0831  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0440  decode.d7.loss_dice: 0.0889  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0448  decode.d8.loss_dice: 0.0803
2023/12/31 18:44:37 - mmengine - INFO - Iter(train) [12600/90000]  base_lr: 8.7308e-05 lr: 8.7308e-06  eta: 21:40:13  time: 1.0080  data_time: 0.0132  memory: 18544  grad_norm: 6.9216  loss: 1.2555  decode.loss_cls: 0.0000  decode.loss_mask: 0.0432  decode.loss_dice: 0.0862  decode.d0.loss_cls: 0.0239  decode.d0.loss_mask: 0.0416  decode.d0.loss_dice: 0.0831  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0413  decode.d1.loss_dice: 0.0792  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0428  decode.d2.loss_dice: 0.0779  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0419  decode.d3.loss_dice: 0.0800  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0432  decode.d4.loss_dice: 0.0788  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0438  decode.d5.loss_dice: 0.0801  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0437  decode.d6.loss_dice: 0.0815  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0420  decode.d7.loss_dice: 0.0794  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0424  decode.d8.loss_dice: 0.0796
2023/12/31 18:45:28 - mmengine - INFO - Iter(train) [12650/90000]  base_lr: 8.7257e-05 lr: 8.7257e-06  eta: 21:39:22  time: 1.0067  data_time: 0.0117  memory: 18544  grad_norm: 11.2067  loss: 1.2944  decode.loss_cls: 0.0000  decode.loss_mask: 0.0460  decode.loss_dice: 0.0824  decode.d0.loss_cls: 0.0220  decode.d0.loss_mask: 0.0450  decode.d0.loss_dice: 0.0799  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0465  decode.d1.loss_dice: 0.0801  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0471  decode.d2.loss_dice: 0.0859  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0446  decode.d3.loss_dice: 0.0769  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0448  decode.d4.loss_dice: 0.0783  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0447  decode.d5.loss_dice: 0.0842  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0453  decode.d6.loss_dice: 0.0831  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0460  decode.d7.loss_dice: 0.0842  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0454  decode.d8.loss_dice: 0.0819
2023/12/31 18:46:18 - mmengine - INFO - Iter(train) [12700/90000]  base_lr: 8.7206e-05 lr: 8.7206e-06  eta: 21:38:32  time: 1.0073  data_time: 0.0125  memory: 18544  grad_norm: 8.6557  loss: 1.2546  decode.loss_cls: 0.0000  decode.loss_mask: 0.0462  decode.loss_dice: 0.0761  decode.d0.loss_cls: 0.0343  decode.d0.loss_mask: 0.0457  decode.d0.loss_dice: 0.0720  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0461  decode.d1.loss_dice: 0.0774  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0459  decode.d2.loss_dice: 0.0737  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0464  decode.d3.loss_dice: 0.0754  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0467  decode.d4.loss_dice: 0.0758  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0459  decode.d5.loss_dice: 0.0778  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0447  decode.d6.loss_dice: 0.0755  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0464  decode.d7.loss_dice: 0.0738  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0483  decode.d8.loss_dice: 0.0806
2023/12/31 18:47:08 - mmengine - INFO - Iter(train) [12750/90000]  base_lr: 8.7155e-05 lr: 8.7155e-06  eta: 21:37:41  time: 1.0078  data_time: 0.0128  memory: 18544  grad_norm: 7.9821  loss: 1.2379  decode.loss_cls: 0.0029  decode.loss_mask: 0.0505  decode.loss_dice: 0.0702  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.0515  decode.d0.loss_dice: 0.0701  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0510  decode.d1.loss_dice: 0.0686  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0511  decode.d2.loss_dice: 0.0728  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0520  decode.d3.loss_dice: 0.0653  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0505  decode.d4.loss_dice: 0.0714  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0513  decode.d5.loss_dice: 0.0696  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0498  decode.d6.loss_dice: 0.0700  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0521  decode.d7.loss_dice: 0.0715  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0496  decode.d8.loss_dice: 0.0663
2023/12/31 18:47:59 - mmengine - INFO - Iter(train) [12800/90000]  base_lr: 8.7105e-05 lr: 8.7105e-06  eta: 21:36:51  time: 1.0057  data_time: 0.0116  memory: 18544  grad_norm: 12.8178  loss: 1.1738  decode.loss_cls: 0.0000  decode.loss_mask: 0.0457  decode.loss_dice: 0.0737  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0445  decode.d0.loss_dice: 0.0702  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0445  decode.d1.loss_dice: 0.0670  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0447  decode.d2.loss_dice: 0.0670  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0431  decode.d3.loss_dice: 0.0668  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0448  decode.d4.loss_dice: 0.0729  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0453  decode.d5.loss_dice: 0.0705  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0461  decode.d6.loss_dice: 0.0750  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0450  decode.d7.loss_dice: 0.0666  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0456  decode.d8.loss_dice: 0.0701
2023/12/31 18:48:49 - mmengine - INFO - Iter(train) [12850/90000]  base_lr: 8.7054e-05 lr: 8.7054e-06  eta: 21:36:00  time: 1.0054  data_time: 0.0122  memory: 18544  grad_norm: 7.4883  loss: 1.2311  decode.loss_cls: 0.0000  decode.loss_mask: 0.0557  decode.loss_dice: 0.0684  decode.d0.loss_cls: 0.0315  decode.d0.loss_mask: 0.0564  decode.d0.loss_dice: 0.0665  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0526  decode.d1.loss_dice: 0.0635  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0531  decode.d2.loss_dice: 0.0668  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0538  decode.d3.loss_dice: 0.0623  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0554  decode.d4.loss_dice: 0.0661  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0541  decode.d5.loss_dice: 0.0634  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0553  decode.d6.loss_dice: 0.0647  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0550  decode.d7.loss_dice: 0.0614  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0570  decode.d8.loss_dice: 0.0681
2023/12/31 18:49:39 - mmengine - INFO - Iter(train) [12900/90000]  base_lr: 8.7003e-05 lr: 8.7003e-06  eta: 21:35:09  time: 1.0063  data_time: 0.0123  memory: 18544  grad_norm: 6.4994  loss: 1.1876  decode.loss_cls: 0.0000  decode.loss_mask: 0.0440  decode.loss_dice: 0.0735  decode.d0.loss_cls: 0.0276  decode.d0.loss_mask: 0.0449  decode.d0.loss_dice: 0.0711  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0448  decode.d1.loss_dice: 0.0745  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0436  decode.d2.loss_dice: 0.0702  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0456  decode.d3.loss_dice: 0.0726  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0438  decode.d4.loss_dice: 0.0698  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0448  decode.d5.loss_dice: 0.0717  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0444  decode.d6.loss_dice: 0.0714  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0453  decode.d7.loss_dice: 0.0708  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0444  decode.d8.loss_dice: 0.0687
2023/12/31 18:50:30 - mmengine - INFO - Iter(train) [12950/90000]  base_lr: 8.6952e-05 lr: 8.6952e-06  eta: 21:34:18  time: 1.0057  data_time: 0.0113  memory: 18544  grad_norm: 8.0803  loss: 1.3833  decode.loss_cls: 0.0001  decode.loss_mask: 0.0461  decode.loss_dice: 0.0704  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0469  decode.d0.loss_dice: 0.0694  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0454  decode.d1.loss_dice: 0.1219  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0473  decode.d2.loss_dice: 0.1092  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0447  decode.d3.loss_dice: 0.0979  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0455  decode.d4.loss_dice: 0.0861  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0458  decode.d5.loss_dice: 0.1101  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0459  decode.d6.loss_dice: 0.0673  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0446  decode.d7.loss_dice: 0.0687  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0456  decode.d8.loss_dice: 0.0976
2023/12/31 18:51:20 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 18:51:20 - mmengine - INFO - Iter(train) [13000/90000]  base_lr: 8.6902e-05 lr: 8.6902e-06  eta: 21:33:27  time: 1.0066  data_time: 0.0116  memory: 18544  grad_norm: 6.5780  loss: 1.1073  decode.loss_cls: 0.0000  decode.loss_mask: 0.0394  decode.loss_dice: 0.0681  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0390  decode.d0.loss_dice: 0.0691  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0386  decode.d1.loss_dice: 0.0670  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0388  decode.d2.loss_dice: 0.0692  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0400  decode.d3.loss_dice: 0.0705  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0409  decode.d4.loss_dice: 0.0703  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0394  decode.d5.loss_dice: 0.0692  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0399  decode.d6.loss_dice: 0.0724  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0395  decode.d7.loss_dice: 0.0667  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0396  decode.d8.loss_dice: 0.0669
2023/12/31 18:52:10 - mmengine - INFO - Iter(train) [13050/90000]  base_lr: 8.6851e-05 lr: 8.6851e-06  eta: 21:32:36  time: 1.0044  data_time: 0.0116  memory: 18544  grad_norm: 7.4284  loss: 1.1247  decode.loss_cls: 0.0000  decode.loss_mask: 0.0467  decode.loss_dice: 0.0622  decode.d0.loss_cls: 0.0335  decode.d0.loss_mask: 0.0481  decode.d0.loss_dice: 0.0642  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0471  decode.d1.loss_dice: 0.0642  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0459  decode.d2.loss_dice: 0.0614  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0469  decode.d3.loss_dice: 0.0632  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0457  decode.d4.loss_dice: 0.0629  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0469  decode.d5.loss_dice: 0.0653  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0463  decode.d6.loss_dice: 0.0621  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0457  decode.d7.loss_dice: 0.0616  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0455  decode.d8.loss_dice: 0.0592
2023/12/31 18:53:01 - mmengine - INFO - Iter(train) [13100/90000]  base_lr: 8.6800e-05 lr: 8.6800e-06  eta: 21:31:46  time: 1.0065  data_time: 0.0116  memory: 18544  grad_norm: 5.8829  loss: 1.0759  decode.loss_cls: 0.0000  decode.loss_mask: 0.0408  decode.loss_dice: 0.0645  decode.d0.loss_cls: 0.0292  decode.d0.loss_mask: 0.0418  decode.d0.loss_dice: 0.0662  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0393  decode.d1.loss_dice: 0.0584  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0397  decode.d2.loss_dice: 0.0592  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0411  decode.d3.loss_dice: 0.0659  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0400  decode.d4.loss_dice: 0.0664  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0404  decode.d5.loss_dice: 0.0619  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0409  decode.d6.loss_dice: 0.0673  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0410  decode.d7.loss_dice: 0.0660  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0407  decode.d8.loss_dice: 0.0652
2023/12/31 18:53:51 - mmengine - INFO - Iter(train) [13150/90000]  base_lr: 8.6749e-05 lr: 8.6749e-06  eta: 21:30:55  time: 1.0069  data_time: 0.0118  memory: 18544  grad_norm: 6.6113  loss: 1.1503  decode.loss_cls: 0.0000  decode.loss_mask: 0.0423  decode.loss_dice: 0.0686  decode.d0.loss_cls: 0.0174  decode.d0.loss_mask: 0.0431  decode.d0.loss_dice: 0.0722  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0439  decode.d1.loss_dice: 0.0727  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0419  decode.d2.loss_dice: 0.0725  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0418  decode.d3.loss_dice: 0.0703  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0413  decode.d4.loss_dice: 0.0710  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0423  decode.d5.loss_dice: 0.0688  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0417  decode.d6.loss_dice: 0.0711  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0417  decode.d7.loss_dice: 0.0715  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0415  decode.d8.loss_dice: 0.0724
2023/12/31 18:54:41 - mmengine - INFO - Iter(train) [13200/90000]  base_lr: 8.6698e-05 lr: 8.6698e-06  eta: 21:30:04  time: 1.0048  data_time: 0.0118  memory: 18544  grad_norm: 7.6183  loss: 1.1380  decode.loss_cls: 0.0000  decode.loss_mask: 0.0466  decode.loss_dice: 0.0632  decode.d0.loss_cls: 0.0316  decode.d0.loss_mask: 0.0455  decode.d0.loss_dice: 0.0624  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0483  decode.d1.loss_dice: 0.0634  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0460  decode.d2.loss_dice: 0.0648  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0472  decode.d3.loss_dice: 0.0589  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0481  decode.d4.loss_dice: 0.0654  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0466  decode.d5.loss_dice: 0.0632  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0471  decode.d6.loss_dice: 0.0632  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0475  decode.d7.loss_dice: 0.0631  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0467  decode.d8.loss_dice: 0.0692
2023/12/31 18:55:32 - mmengine - INFO - Iter(train) [13250/90000]  base_lr: 8.6648e-05 lr: 8.6648e-06  eta: 21:29:14  time: 1.0040  data_time: 0.0111  memory: 18544  grad_norm: 7.2779  loss: 1.1536  decode.loss_cls: 0.0000  decode.loss_mask: 0.0480  decode.loss_dice: 0.0606  decode.d0.loss_cls: 0.0360  decode.d0.loss_mask: 0.0475  decode.d0.loss_dice: 0.0671  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.0475  decode.d1.loss_dice: 0.0644  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0476  decode.d2.loss_dice: 0.0615  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0486  decode.d3.loss_dice: 0.0642  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0476  decode.d4.loss_dice: 0.0630  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0498  decode.d5.loss_dice: 0.0652  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0483  decode.d6.loss_dice: 0.0635  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0475  decode.d7.loss_dice: 0.0608  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0488  decode.d8.loss_dice: 0.0660
2023/12/31 18:56:22 - mmengine - INFO - Iter(train) [13300/90000]  base_lr: 8.6597e-05 lr: 8.6597e-06  eta: 21:28:23  time: 1.0054  data_time: 0.0112  memory: 18544  grad_norm: 9.2465  loss: 1.1725  decode.loss_cls: 0.0000  decode.loss_mask: 0.0489  decode.loss_dice: 0.0643  decode.d0.loss_cls: 0.0293  decode.d0.loss_mask: 0.0503  decode.d0.loss_dice: 0.0660  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0476  decode.d1.loss_dice: 0.0641  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0492  decode.d2.loss_dice: 0.0656  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0503  decode.d3.loss_dice: 0.0692  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0485  decode.d4.loss_dice: 0.0637  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0487  decode.d5.loss_dice: 0.0647  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0506  decode.d6.loss_dice: 0.0678  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0477  decode.d7.loss_dice: 0.0631  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0487  decode.d8.loss_dice: 0.0642
2023/12/31 18:57:12 - mmengine - INFO - Iter(train) [13350/90000]  base_lr: 8.6546e-05 lr: 8.6546e-06  eta: 21:27:32  time: 1.0055  data_time: 0.0113  memory: 18544  grad_norm: 7.3369  loss: 1.1960  decode.loss_cls: 0.0000  decode.loss_mask: 0.0402  decode.loss_dice: 0.0762  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.0391  decode.d0.loss_dice: 0.0711  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0401  decode.d1.loss_dice: 0.0754  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0413  decode.d2.loss_dice: 0.0775  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0410  decode.d3.loss_dice: 0.0776  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0396  decode.d4.loss_dice: 0.0729  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0408  decode.d5.loss_dice: 0.0795  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0418  decode.d6.loss_dice: 0.0799  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0398  decode.d7.loss_dice: 0.0749  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0403  decode.d8.loss_dice: 0.0818
2023/12/31 18:58:03 - mmengine - INFO - Iter(train) [13400/90000]  base_lr: 8.6495e-05 lr: 8.6495e-06  eta: 21:26:41  time: 1.0073  data_time: 0.0112  memory: 18544  grad_norm: 6.0696  loss: 1.2024  decode.loss_cls: 0.0000  decode.loss_mask: 0.0449  decode.loss_dice: 0.0757  decode.d0.loss_cls: 0.0217  decode.d0.loss_mask: 0.0445  decode.d0.loss_dice: 0.0727  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0437  decode.d1.loss_dice: 0.0743  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0432  decode.d2.loss_dice: 0.0695  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0455  decode.d3.loss_dice: 0.0776  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0442  decode.d4.loss_dice: 0.0724  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0433  decode.d5.loss_dice: 0.0706  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0436  decode.d6.loss_dice: 0.0735  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0446  decode.d7.loss_dice: 0.0740  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0454  decode.d8.loss_dice: 0.0772
2023/12/31 18:58:53 - mmengine - INFO - Iter(train) [13450/90000]  base_lr: 8.6444e-05 lr: 8.6444e-06  eta: 21:25:51  time: 1.0074  data_time: 0.0116  memory: 18544  grad_norm: 8.0197  loss: 1.1560  decode.loss_cls: 0.0000  decode.loss_mask: 0.0432  decode.loss_dice: 0.0689  decode.d0.loss_cls: 0.0238  decode.d0.loss_mask: 0.0417  decode.d0.loss_dice: 0.0698  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0433  decode.d1.loss_dice: 0.0707  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0431  decode.d2.loss_dice: 0.0673  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0423  decode.d3.loss_dice: 0.0677  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0438  decode.d4.loss_dice: 0.0722  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0435  decode.d5.loss_dice: 0.0682  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0443  decode.d6.loss_dice: 0.0750  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0436  decode.d7.loss_dice: 0.0706  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0433  decode.d8.loss_dice: 0.0696
2023/12/31 18:59:43 - mmengine - INFO - Iter(train) [13500/90000]  base_lr: 8.6394e-05 lr: 8.6394e-06  eta: 21:25:00  time: 1.0088  data_time: 0.0124  memory: 18544  grad_norm: 8.0262  loss: 1.1473  decode.loss_cls: 0.0000  decode.loss_mask: 0.0389  decode.loss_dice: 0.0747  decode.d0.loss_cls: 0.0208  decode.d0.loss_mask: 0.0383  decode.d0.loss_dice: 0.0736  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0694  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0387  decode.d2.loss_dice: 0.0781  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0377  decode.d3.loss_dice: 0.0696  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0398  decode.d4.loss_dice: 0.0761  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0380  decode.d5.loss_dice: 0.0752  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0382  decode.d6.loss_dice: 0.0724  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0380  decode.d7.loss_dice: 0.0719  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0385  decode.d8.loss_dice: 0.0698
2023/12/31 19:00:34 - mmengine - INFO - Iter(train) [13550/90000]  base_lr: 8.6343e-05 lr: 8.6343e-06  eta: 21:24:10  time: 1.0072  data_time: 0.0114  memory: 18544  grad_norm: 6.4962  loss: 1.1398  decode.loss_cls: 0.0000  decode.loss_mask: 0.0416  decode.loss_dice: 0.0696  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0428  decode.d0.loss_dice: 0.0728  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0419  decode.d1.loss_dice: 0.0692  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0427  decode.d2.loss_dice: 0.0768  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0413  decode.d3.loss_dice: 0.0675  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0419  decode.d4.loss_dice: 0.0670  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0421  decode.d5.loss_dice: 0.0709  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0409  decode.d6.loss_dice: 0.0690  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0416  decode.d7.loss_dice: 0.0679  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0425  decode.d8.loss_dice: 0.0668
2023/12/31 19:01:24 - mmengine - INFO - Iter(train) [13600/90000]  base_lr: 8.6292e-05 lr: 8.6292e-06  eta: 21:23:19  time: 1.0058  data_time: 0.0114  memory: 18544  grad_norm: 22.1754  loss: 1.7271  decode.loss_cls: 0.0000  decode.loss_mask: 0.0466  decode.loss_dice: 0.1182  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.0475  decode.d0.loss_dice: 0.1084  decode.d1.loss_cls: 0.1134  decode.d1.loss_mask: 0.0456  decode.d1.loss_dice: 0.0842  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.0456  decode.d2.loss_dice: 0.1043  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.0463  decode.d3.loss_dice: 0.0994  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.0467  decode.d4.loss_dice: 0.0724  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.0469  decode.d5.loss_dice: 0.1022  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0469  decode.d6.loss_dice: 0.0681  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0456  decode.d7.loss_dice: 0.1015  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0456  decode.d8.loss_dice: 0.0853
2023/12/31 19:02:14 - mmengine - INFO - Iter(train) [13650/90000]  base_lr: 8.6241e-05 lr: 8.6241e-06  eta: 21:22:28  time: 1.0076  data_time: 0.0128  memory: 18544  grad_norm: 6.3887  loss: 1.1155  decode.loss_cls: 0.0000  decode.loss_mask: 0.0439  decode.loss_dice: 0.0681  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0426  decode.d0.loss_dice: 0.0647  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0440  decode.d1.loss_dice: 0.0680  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0439  decode.d2.loss_dice: 0.0652  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0430  decode.d3.loss_dice: 0.0632  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0431  decode.d4.loss_dice: 0.0654  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0442  decode.d5.loss_dice: 0.0681  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0433  decode.d6.loss_dice: 0.0643  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0419  decode.d7.loss_dice: 0.0613  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0444  decode.d8.loss_dice: 0.0664
2023/12/31 19:03:05 - mmengine - INFO - Iter(train) [13700/90000]  base_lr: 8.6190e-05 lr: 8.6190e-06  eta: 21:21:38  time: 1.0050  data_time: 0.0116  memory: 18544  grad_norm: 7.5931  loss: 1.1209  decode.loss_cls: 0.0000  decode.loss_mask: 0.0399  decode.loss_dice: 0.0676  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.0395  decode.d0.loss_dice: 0.0679  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0407  decode.d1.loss_dice: 0.0716  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0394  decode.d2.loss_dice: 0.0670  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0398  decode.d3.loss_dice: 0.0728  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0401  decode.d4.loss_dice: 0.0680  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0406  decode.d5.loss_dice: 0.0720  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0394  decode.d6.loss_dice: 0.0660  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0404  decode.d7.loss_dice: 0.0699  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0401  decode.d8.loss_dice: 0.0692
2023/12/31 19:03:55 - mmengine - INFO - Iter(train) [13750/90000]  base_lr: 8.6139e-05 lr: 8.6139e-06  eta: 21:20:48  time: 1.0066  data_time: 0.0120  memory: 18544  grad_norm: 9.1680  loss: 1.1691  decode.loss_cls: 0.0000  decode.loss_mask: 0.0456  decode.loss_dice: 0.0668  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.0454  decode.d0.loss_dice: 0.0672  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0466  decode.d1.loss_dice: 0.0707  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0460  decode.d2.loss_dice: 0.0669  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0462  decode.d3.loss_dice: 0.0679  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0456  decode.d4.loss_dice: 0.0698  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0455  decode.d5.loss_dice: 0.0683  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0456  decode.d6.loss_dice: 0.0689  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0451  decode.d7.loss_dice: 0.0690  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0460  decode.d8.loss_dice: 0.0679
2023/12/31 19:04:46 - mmengine - INFO - Iter(train) [13800/90000]  base_lr: 8.6089e-05 lr: 8.6089e-06  eta: 21:19:57  time: 1.0086  data_time: 0.0131  memory: 18544  grad_norm: 9.3237  loss: 1.1114  decode.loss_cls: 0.0000  decode.loss_mask: 0.0468  decode.loss_dice: 0.0659  decode.d0.loss_cls: 0.0301  decode.d0.loss_mask: 0.0455  decode.d0.loss_dice: 0.0606  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0460  decode.d1.loss_dice: 0.0575  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0458  decode.d2.loss_dice: 0.0596  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0451  decode.d3.loss_dice: 0.0619  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0464  decode.d4.loss_dice: 0.0630  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0460  decode.d5.loss_dice: 0.0625  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0455  decode.d6.loss_dice: 0.0633  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0469  decode.d7.loss_dice: 0.0632  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0471  decode.d8.loss_dice: 0.0626
2023/12/31 19:05:36 - mmengine - INFO - Iter(train) [13850/90000]  base_lr: 8.6038e-05 lr: 8.6038e-06  eta: 21:19:06  time: 1.0048  data_time: 0.0114  memory: 18544  grad_norm: 6.5731  loss: 1.2212  decode.loss_cls: 0.0000  decode.loss_mask: 0.0417  decode.loss_dice: 0.0816  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0406  decode.d0.loss_dice: 0.0747  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0407  decode.d1.loss_dice: 0.0832  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0412  decode.d2.loss_dice: 0.0769  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0406  decode.d3.loss_dice: 0.0794  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0404  decode.d4.loss_dice: 0.0786  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0421  decode.d5.loss_dice: 0.0765  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0412  decode.d6.loss_dice: 0.0752  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0415  decode.d7.loss_dice: 0.0801  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0418  decode.d8.loss_dice: 0.0803
2023/12/31 19:06:26 - mmengine - INFO - Iter(train) [13900/90000]  base_lr: 8.5987e-05 lr: 8.5987e-06  eta: 21:18:15  time: 1.0082  data_time: 0.0126  memory: 18544  grad_norm: 6.1384  loss: 1.1237  decode.loss_cls: 0.0000  decode.loss_mask: 0.0431  decode.loss_dice: 0.0669  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0435  decode.d0.loss_dice: 0.0634  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0440  decode.d1.loss_dice: 0.0772  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0440  decode.d2.loss_dice: 0.0644  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0430  decode.d3.loss_dice: 0.0613  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0427  decode.d4.loss_dice: 0.0646  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0415  decode.d5.loss_dice: 0.0639  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0425  decode.d6.loss_dice: 0.0685  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0440  decode.d7.loss_dice: 0.0671  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0434  decode.d8.loss_dice: 0.0716
2023/12/31 19:07:17 - mmengine - INFO - Iter(train) [13950/90000]  base_lr: 8.5936e-05 lr: 8.5936e-06  eta: 21:17:24  time: 1.0074  data_time: 0.0129  memory: 18544  grad_norm: 6.8952  loss: 1.1358  decode.loss_cls: 0.0000  decode.loss_mask: 0.0431  decode.loss_dice: 0.0637  decode.d0.loss_cls: 0.0301  decode.d0.loss_mask: 0.0425  decode.d0.loss_dice: 0.0653  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0432  decode.d1.loss_dice: 0.0668  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0431  decode.d2.loss_dice: 0.0668  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0425  decode.d3.loss_dice: 0.0663  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0432  decode.d4.loss_dice: 0.0677  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0425  decode.d5.loss_dice: 0.0692  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0434  decode.d6.loss_dice: 0.0696  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0432  decode.d7.loss_dice: 0.0701  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0439  decode.d8.loss_dice: 0.0696
2023/12/31 19:08:07 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 19:08:07 - mmengine - INFO - Iter(train) [14000/90000]  base_lr: 8.5885e-05 lr: 8.5885e-06  eta: 21:16:34  time: 1.0050  data_time: 0.0113  memory: 18544  grad_norm: 6.7790  loss: 1.1992  decode.loss_cls: 0.0000  decode.loss_mask: 0.0440  decode.loss_dice: 0.0718  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0443  decode.d0.loss_dice: 0.0769  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0436  decode.d1.loss_dice: 0.0727  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0443  decode.d2.loss_dice: 0.0740  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0455  decode.d3.loss_dice: 0.0706  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0447  decode.d4.loss_dice: 0.0745  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0439  decode.d5.loss_dice: 0.0730  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0453  decode.d6.loss_dice: 0.0715  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0438  decode.d7.loss_dice: 0.0705  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0443  decode.d8.loss_dice: 0.0719
2023/12/31 19:08:57 - mmengine - INFO - Iter(train) [14050/90000]  base_lr: 8.5834e-05 lr: 8.5834e-06  eta: 21:15:43  time: 1.0072  data_time: 0.0126  memory: 18544  grad_norm: 6.0389  loss: 1.1424  decode.loss_cls: 0.0000  decode.loss_mask: 0.0416  decode.loss_dice: 0.0648  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.0434  decode.d0.loss_dice: 0.0710  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0437  decode.d1.loss_dice: 0.0686  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0420  decode.d2.loss_dice: 0.0703  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0432  decode.d3.loss_dice: 0.0699  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0429  decode.d4.loss_dice: 0.0717  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0419  decode.d5.loss_dice: 0.0653  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0425  decode.d6.loss_dice: 0.0704  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0433  decode.d7.loss_dice: 0.0714  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0421  decode.d8.loss_dice: 0.0687
2023/12/31 19:09:47 - mmengine - INFO - Iter(train) [14100/90000]  base_lr: 8.5783e-05 lr: 8.5783e-06  eta: 21:14:52  time: 1.0068  data_time: 0.0126  memory: 18544  grad_norm: 6.9075  loss: 1.1428  decode.loss_cls: 0.0000  decode.loss_mask: 0.0461  decode.loss_dice: 0.0650  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0457  decode.d0.loss_dice: 0.0618  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0461  decode.d1.loss_dice: 0.0682  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0447  decode.d2.loss_dice: 0.0650  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0446  decode.d3.loss_dice: 0.0640  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0444  decode.d4.loss_dice: 0.0656  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0458  decode.d5.loss_dice: 0.0673  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0465  decode.d6.loss_dice: 0.0669  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0449  decode.d7.loss_dice: 0.0648  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0454  decode.d8.loss_dice: 0.0733
2023/12/31 19:10:38 - mmengine - INFO - Iter(train) [14150/90000]  base_lr: 8.5733e-05 lr: 8.5733e-06  eta: 21:14:01  time: 1.0043  data_time: 0.0116  memory: 18544  grad_norm: 7.6436  loss: 1.1186  decode.loss_cls: 0.0001  decode.loss_mask: 0.0438  decode.loss_dice: 0.0668  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0431  decode.d0.loss_dice: 0.0701  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0419  decode.d1.loss_dice: 0.0622  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0426  decode.d2.loss_dice: 0.0680  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0437  decode.d3.loss_dice: 0.0660  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0427  decode.d4.loss_dice: 0.0637  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0430  decode.d5.loss_dice: 0.0662  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0440  decode.d6.loss_dice: 0.0664  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0433  decode.d7.loss_dice: 0.0675  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0416  decode.d8.loss_dice: 0.0641
2023/12/31 19:11:28 - mmengine - INFO - Iter(train) [14200/90000]  base_lr: 8.5682e-05 lr: 8.5682e-06  eta: 21:13:10  time: 1.0064  data_time: 0.0122  memory: 18544  grad_norm: 9.3131  loss: 1.1798  decode.loss_cls: 0.0000  decode.loss_mask: 0.0424  decode.loss_dice: 0.0756  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0407  decode.d0.loss_dice: 0.0721  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0417  decode.d1.loss_dice: 0.0762  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0417  decode.d2.loss_dice: 0.0774  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0412  decode.d3.loss_dice: 0.0753  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0401  decode.d4.loss_dice: 0.0700  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0414  decode.d5.loss_dice: 0.0761  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0414  decode.d6.loss_dice: 0.0760  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0407  decode.d7.loss_dice: 0.0716  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0409  decode.d8.loss_dice: 0.0718
2023/12/31 19:12:18 - mmengine - INFO - Iter(train) [14250/90000]  base_lr: 8.5631e-05 lr: 8.5631e-06  eta: 21:12:19  time: 1.0060  data_time: 0.0124  memory: 18544  grad_norm: 5.2938  loss: 1.0788  decode.loss_cls: 0.0000  decode.loss_mask: 0.0420  decode.loss_dice: 0.0631  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0420  decode.d0.loss_dice: 0.0651  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0413  decode.d1.loss_dice: 0.0631  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0412  decode.d2.loss_dice: 0.0616  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0412  decode.d3.loss_dice: 0.0649  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0414  decode.d4.loss_dice: 0.0630  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0424  decode.d5.loss_dice: 0.0631  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0418  decode.d6.loss_dice: 0.0662  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0422  decode.d7.loss_dice: 0.0639  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0411  decode.d8.loss_dice: 0.0613
2023/12/31 19:13:09 - mmengine - INFO - Iter(train) [14300/90000]  base_lr: 8.5580e-05 lr: 8.5580e-06  eta: 21:11:28  time: 1.0054  data_time: 0.0115  memory: 18544  grad_norm: 6.7453  loss: 1.1081  decode.loss_cls: 0.0000  decode.loss_mask: 0.0411  decode.loss_dice: 0.0685  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.0417  decode.d0.loss_dice: 0.0665  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0404  decode.d1.loss_dice: 0.0685  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0390  decode.d2.loss_dice: 0.0710  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0419  decode.d3.loss_dice: 0.0688  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0417  decode.d4.loss_dice: 0.0714  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0400  decode.d5.loss_dice: 0.0712  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0394  decode.d6.loss_dice: 0.0646  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0398  decode.d7.loss_dice: 0.0624  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0395  decode.d8.loss_dice: 0.0657
2023/12/31 19:13:59 - mmengine - INFO - Iter(train) [14350/90000]  base_lr: 8.5529e-05 lr: 8.5529e-06  eta: 21:10:38  time: 1.0069  data_time: 0.0135  memory: 18544  grad_norm: 12.2572  loss: 1.0678  decode.loss_cls: 0.0000  decode.loss_mask: 0.0410  decode.loss_dice: 0.0710  decode.d0.loss_cls: 0.0306  decode.d0.loss_mask: 0.0410  decode.d0.loss_dice: 0.0618  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0402  decode.d1.loss_dice: 0.0569  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0496  decode.d2.loss_dice: 0.0626  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0398  decode.d3.loss_dice: 0.0620  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0398  decode.d4.loss_dice: 0.0689  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0403  decode.d5.loss_dice: 0.0597  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0414  decode.d6.loss_dice: 0.0631  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0400  decode.d7.loss_dice: 0.0645  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0403  decode.d8.loss_dice: 0.0531
2023/12/31 19:14:49 - mmengine - INFO - Iter(train) [14400/90000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 21:09:47  time: 1.0061  data_time: 0.0125  memory: 18544  grad_norm: 5.7007  loss: 1.0579  decode.loss_cls: 0.0000  decode.loss_mask: 0.0448  decode.loss_dice: 0.0573  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.0455  decode.d0.loss_dice: 0.0582  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0450  decode.d1.loss_dice: 0.0574  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0457  decode.d2.loss_dice: 0.0609  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0438  decode.d3.loss_dice: 0.0583  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0435  decode.d4.loss_dice: 0.0571  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0456  decode.d5.loss_dice: 0.0594  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0441  decode.d6.loss_dice: 0.0583  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0437  decode.d7.loss_dice: 0.0602  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0438  decode.d8.loss_dice: 0.0571
2023/12/31 19:15:40 - mmengine - INFO - Iter(train) [14450/90000]  base_lr: 8.5427e-05 lr: 8.5427e-06  eta: 21:08:57  time: 1.0065  data_time: 0.0120  memory: 18544  grad_norm: 7.2116  loss: 1.1451  decode.loss_cls: 0.0000  decode.loss_mask: 0.0421  decode.loss_dice: 0.0673  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0419  decode.d0.loss_dice: 0.0712  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0430  decode.d1.loss_dice: 0.0689  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0422  decode.d2.loss_dice: 0.0695  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0411  decode.d3.loss_dice: 0.0708  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0426  decode.d4.loss_dice: 0.0726  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0423  decode.d5.loss_dice: 0.0693  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0415  decode.d6.loss_dice: 0.0676  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0420  decode.d7.loss_dice: 0.0671  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0427  decode.d8.loss_dice: 0.0712
2023/12/31 19:16:30 - mmengine - INFO - Iter(train) [14500/90000]  base_lr: 8.5376e-05 lr: 8.5376e-06  eta: 21:08:06  time: 1.0075  data_time: 0.0134  memory: 18544  grad_norm: 6.8482  loss: 1.0591  decode.loss_cls: 0.0000  decode.loss_mask: 0.0441  decode.loss_dice: 0.0643  decode.d0.loss_cls: 0.0370  decode.d0.loss_mask: 0.0420  decode.d0.loss_dice: 0.0583  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0434  decode.d1.loss_dice: 0.0582  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0429  decode.d2.loss_dice: 0.0583  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0430  decode.d3.loss_dice: 0.0559  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0432  decode.d4.loss_dice: 0.0568  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0430  decode.d5.loss_dice: 0.0639  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0427  decode.d6.loss_dice: 0.0566  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0430  decode.d7.loss_dice: 0.0591  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0428  decode.d8.loss_dice: 0.0605
2023/12/31 19:17:20 - mmengine - INFO - Iter(train) [14550/90000]  base_lr: 8.5326e-05 lr: 8.5326e-06  eta: 21:07:15  time: 1.0065  data_time: 0.0126  memory: 18544  grad_norm: 12.2163  loss: 1.1602  decode.loss_cls: 0.0003  decode.loss_mask: 0.0465  decode.loss_dice: 0.0645  decode.d0.loss_cls: 0.0309  decode.d0.loss_mask: 0.0480  decode.d0.loss_dice: 0.0694  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0465  decode.d1.loss_dice: 0.0664  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0464  decode.d2.loss_dice: 0.0656  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0454  decode.d3.loss_dice: 0.0635  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0464  decode.d4.loss_dice: 0.0678  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0455  decode.d5.loss_dice: 0.0678  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0464  decode.d6.loss_dice: 0.0677  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0465  decode.d7.loss_dice: 0.0642  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0470  decode.d8.loss_dice: 0.0675
2023/12/31 19:18:11 - mmengine - INFO - Iter(train) [14600/90000]  base_lr: 8.5275e-05 lr: 8.5275e-06  eta: 21:06:25  time: 1.0055  data_time: 0.0118  memory: 18544  grad_norm: 5.4030  loss: 1.1494  decode.loss_cls: 0.0000  decode.loss_mask: 0.0412  decode.loss_dice: 0.0757  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0401  decode.d0.loss_dice: 0.0739  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0412  decode.d1.loss_dice: 0.0729  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0400  decode.d2.loss_dice: 0.0695  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0405  decode.d3.loss_dice: 0.0705  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0407  decode.d4.loss_dice: 0.0703  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0391  decode.d5.loss_dice: 0.0683  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0409  decode.d6.loss_dice: 0.0724  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0400  decode.d7.loss_dice: 0.0718  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0415  decode.d8.loss_dice: 0.0739
2023/12/31 19:19:01 - mmengine - INFO - Iter(train) [14650/90000]  base_lr: 8.5224e-05 lr: 8.5224e-06  eta: 21:05:34  time: 1.0063  data_time: 0.0137  memory: 18544  grad_norm: 9.2742  loss: 1.2023  decode.loss_cls: 0.0000  decode.loss_mask: 0.0490  decode.loss_dice: 0.0696  decode.d0.loss_cls: 0.0345  decode.d0.loss_mask: 0.0486  decode.d0.loss_dice: 0.0727  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0484  decode.d1.loss_dice: 0.0714  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0480  decode.d2.loss_dice: 0.0681  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0477  decode.d3.loss_dice: 0.0708  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0487  decode.d4.loss_dice: 0.0690  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0472  decode.d5.loss_dice: 0.0648  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0471  decode.d6.loss_dice: 0.0671  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0474  decode.d7.loss_dice: 0.0675  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0479  decode.d8.loss_dice: 0.0665
2023/12/31 19:19:51 - mmengine - INFO - Iter(train) [14700/90000]  base_lr: 8.5173e-05 lr: 8.5173e-06  eta: 21:04:43  time: 1.0044  data_time: 0.0116  memory: 18544  grad_norm: 13.8036  loss: 1.1581  decode.loss_cls: 0.0000  decode.loss_mask: 0.0428  decode.loss_dice: 0.0648  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.0431  decode.d0.loss_dice: 0.0698  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0441  decode.d1.loss_dice: 0.0656  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0443  decode.d2.loss_dice: 0.0776  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0431  decode.d3.loss_dice: 0.0792  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0422  decode.d4.loss_dice: 0.0674  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0427  decode.d5.loss_dice: 0.0697  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0436  decode.d6.loss_dice: 0.0693  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0424  decode.d7.loss_dice: 0.0685  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0437  decode.d8.loss_dice: 0.0660
2023/12/31 19:20:42 - mmengine - INFO - Iter(train) [14750/90000]  base_lr: 8.5122e-05 lr: 8.5122e-06  eta: 21:03:52  time: 1.0051  data_time: 0.0120  memory: 18544  grad_norm: 6.6411  loss: 1.1614  decode.loss_cls: 0.0000  decode.loss_mask: 0.0422  decode.loss_dice: 0.0660  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.0440  decode.d0.loss_dice: 0.0777  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0427  decode.d1.loss_dice: 0.0638  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0415  decode.d2.loss_dice: 0.0620  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0430  decode.d3.loss_dice: 0.0722  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0426  decode.d4.loss_dice: 0.0655  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0431  decode.d5.loss_dice: 0.0689  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0435  decode.d6.loss_dice: 0.0820  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0427  decode.d7.loss_dice: 0.0809  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0429  decode.d8.loss_dice: 0.0675
2023/12/31 19:21:32 - mmengine - INFO - Iter(train) [14800/90000]  base_lr: 8.5071e-05 lr: 8.5071e-06  eta: 21:03:01  time: 1.0080  data_time: 0.0132  memory: 18544  grad_norm: 6.6180  loss: 1.1563  decode.loss_cls: 0.0000  decode.loss_mask: 0.0422  decode.loss_dice: 0.0777  decode.d0.loss_cls: 0.0185  decode.d0.loss_mask: 0.0405  decode.d0.loss_dice: 0.0738  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0708  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0394  decode.d2.loss_dice: 0.0731  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0410  decode.d3.loss_dice: 0.0707  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0406  decode.d4.loss_dice: 0.0698  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0407  decode.d5.loss_dice: 0.0746  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0413  decode.d6.loss_dice: 0.0730  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0410  decode.d7.loss_dice: 0.0785  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0395  decode.d8.loss_dice: 0.0704
2023/12/31 19:22:22 - mmengine - INFO - Iter(train) [14850/90000]  base_lr: 8.5020e-05 lr: 8.5020e-06  eta: 21:02:10  time: 1.0051  data_time: 0.0121  memory: 18544  grad_norm: 5.7178  loss: 1.0830  decode.loss_cls: 0.0000  decode.loss_mask: 0.0420  decode.loss_dice: 0.0605  decode.d0.loss_cls: 0.0307  decode.d0.loss_mask: 0.0422  decode.d0.loss_dice: 0.0631  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0436  decode.d1.loss_dice: 0.0615  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0427  decode.d2.loss_dice: 0.0657  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0425  decode.d3.loss_dice: 0.0624  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0423  decode.d4.loss_dice: 0.0599  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0424  decode.d5.loss_dice: 0.0680  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0421  decode.d6.loss_dice: 0.0607  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0420  decode.d7.loss_dice: 0.0611  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0415  decode.d8.loss_dice: 0.0663
2023/12/31 19:23:13 - mmengine - INFO - Iter(train) [14900/90000]  base_lr: 8.4969e-05 lr: 8.4969e-06  eta: 21:01:20  time: 1.0072  data_time: 0.0127  memory: 18544  grad_norm: 8.0965  loss: 1.1970  decode.loss_cls: 0.0000  decode.loss_mask: 0.0482  decode.loss_dice: 0.0675  decode.d0.loss_cls: 0.0246  decode.d0.loss_mask: 0.0489  decode.d0.loss_dice: 0.0711  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0485  decode.d1.loss_dice: 0.0688  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0472  decode.d2.loss_dice: 0.0710  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0473  decode.d3.loss_dice: 0.0675  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0476  decode.d4.loss_dice: 0.0672  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0475  decode.d5.loss_dice: 0.0668  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0478  decode.d6.loss_dice: 0.0674  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0488  decode.d7.loss_dice: 0.0772  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0483  decode.d8.loss_dice: 0.0680
2023/12/31 19:24:03 - mmengine - INFO - Iter(train) [14950/90000]  base_lr: 8.4918e-05 lr: 8.4918e-06  eta: 21:00:30  time: 1.0086  data_time: 0.0140  memory: 18544  grad_norm: 7.2946  loss: 1.1522  decode.loss_cls: 0.0000  decode.loss_mask: 0.0419  decode.loss_dice: 0.0701  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.0415  decode.d0.loss_dice: 0.0731  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0431  decode.d1.loss_dice: 0.0717  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0409  decode.d2.loss_dice: 0.0676  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0422  decode.d3.loss_dice: 0.0694  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0427  decode.d4.loss_dice: 0.0742  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0408  decode.d5.loss_dice: 0.0708  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0425  decode.d6.loss_dice: 0.0671  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0425  decode.d7.loss_dice: 0.0720  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0412  decode.d8.loss_dice: 0.0721
2023/12/31 19:24:53 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 19:24:53 - mmengine - INFO - Iter(train) [15000/90000]  base_lr: 8.4867e-05 lr: 8.4867e-06  eta: 20:59:39  time: 1.0063  data_time: 0.0123  memory: 18544  grad_norm: 15.0254  loss: 1.2744  decode.loss_cls: 0.0000  decode.loss_mask: 0.0463  decode.loss_dice: 0.0769  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0439  decode.d0.loss_dice: 0.0762  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0462  decode.d1.loss_dice: 0.0784  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0461  decode.d2.loss_dice: 0.0811  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0440  decode.d3.loss_dice: 0.0745  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0453  decode.d4.loss_dice: 0.0810  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0472  decode.d5.loss_dice: 0.0853  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0469  decode.d6.loss_dice: 0.0826  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0454  decode.d7.loss_dice: 0.0805  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0444  decode.d8.loss_dice: 0.0757
2023/12/31 19:24:53 - mmengine - INFO - Saving checkpoint at 15000 iterations
2023/12/31 19:25:03 - mmengine - INFO - Iter(val) [ 50/370]    eta: 0:00:51  time: 0.1541  data_time: 0.0042  memory: 3090  
2023/12/31 19:25:11 - mmengine - INFO - Iter(val) [100/370]    eta: 0:00:42  time: 0.1542  data_time: 0.0044  memory: 3090  
2023/12/31 19:25:19 - mmengine - INFO - Iter(val) [150/370]    eta: 0:00:34  time: 0.1548  data_time: 0.0046  memory: 3090  
2023/12/31 19:25:26 - mmengine - INFO - Iter(val) [200/370]    eta: 0:00:26  time: 0.1549  data_time: 0.0046  memory: 3090  
2023/12/31 19:25:34 - mmengine - INFO - Iter(val) [250/370]    eta: 0:00:18  time: 0.1547  data_time: 0.0045  memory: 3090  
2023/12/31 19:25:42 - mmengine - INFO - Iter(val) [300/370]    eta: 0:00:10  time: 0.1550  data_time: 0.0045  memory: 3090  
2023/12/31 19:25:50 - mmengine - INFO - Iter(val) [350/370]    eta: 0:00:03  time: 0.1545  data_time: 0.0043  memory: 3090  
2023/12/31 19:25:53 - mmengine - INFO - per class results:
2023/12/31 19:25:53 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.54 | 99.89 |
|     Billboard      | 88.43 | 90.88 |
|      Goal net      | 71.12 | 79.31 |
+--------------------+-------+-------+
2023/12/31 19:25:53 - mmengine - INFO - Iter(val) [370/370]    aAcc: 99.5400  mIoU: 86.3600  mAcc: 90.0300  data_time: 0.0049  time: 0.1553
2023/12/31 19:25:53 - mmengine - INFO - The previous best checkpoint /scratch/users/vgaspar/work_dirs/mask2former_r50_4xb2-90k_soccernet-1080x1920/best_mIoU_iter_10000.pth is removed
2023/12/31 19:25:53 - mmengine - INFO - The best checkpoint with 86.3600 mIoU at 15000 iter is saved to best_mIoU_iter_15000.pth.
2023/12/31 19:26:45 - mmengine - INFO - Iter(train) [15050/90000]  base_lr: 8.4817e-05 lr: 8.4817e-06  eta: 20:58:59  time: 1.0078  data_time: 0.0132  memory: 18544  grad_norm: 9.8786  loss: 1.1963  decode.loss_cls: 0.0000  decode.loss_mask: 0.0386  decode.loss_dice: 0.0763  decode.d0.loss_cls: 0.0193  decode.d0.loss_mask: 0.0393  decode.d0.loss_dice: 0.0798  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0382  decode.d1.loss_dice: 0.0748  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0396  decode.d2.loss_dice: 0.0830  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0382  decode.d3.loss_dice: 0.0813  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0387  decode.d4.loss_dice: 0.0791  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0392  decode.d5.loss_dice: 0.0781  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0383  decode.d6.loss_dice: 0.0788  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0395  decode.d7.loss_dice: 0.0821  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0376  decode.d8.loss_dice: 0.0763
2023/12/31 19:27:35 - mmengine - INFO - Iter(train) [15100/90000]  base_lr: 8.4766e-05 lr: 8.4766e-06  eta: 20:58:09  time: 1.0082  data_time: 0.0136  memory: 18544  grad_norm: 7.8761  loss: 1.1401  decode.loss_cls: 0.0001  decode.loss_mask: 0.0417  decode.loss_dice: 0.0696  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.0428  decode.d0.loss_dice: 0.0692  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0408  decode.d1.loss_dice: 0.0670  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0416  decode.d2.loss_dice: 0.0691  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0418  decode.d3.loss_dice: 0.0664  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0432  decode.d4.loss_dice: 0.0695  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0416  decode.d5.loss_dice: 0.0697  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0433  decode.d6.loss_dice: 0.0692  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0430  decode.d7.loss_dice: 0.0728  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0427  decode.d8.loss_dice: 0.0721
2023/12/31 19:28:26 - mmengine - INFO - Iter(train) [15150/90000]  base_lr: 8.4715e-05 lr: 8.4715e-06  eta: 20:57:18  time: 1.0053  data_time: 0.0124  memory: 18544  grad_norm: 8.3864  loss: 1.2144  decode.loss_cls: 0.0000  decode.loss_mask: 0.0459  decode.loss_dice: 0.0726  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.0435  decode.d0.loss_dice: 0.0751  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0446  decode.d1.loss_dice: 0.0743  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0451  decode.d2.loss_dice: 0.0729  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0454  decode.d3.loss_dice: 0.0724  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0446  decode.d4.loss_dice: 0.0796  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0430  decode.d5.loss_dice: 0.0733  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0435  decode.d6.loss_dice: 0.0756  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0445  decode.d7.loss_dice: 0.0725  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0446  decode.d8.loss_dice: 0.0753
2023/12/31 19:29:16 - mmengine - INFO - Iter(train) [15200/90000]  base_lr: 8.4664e-05 lr: 8.4664e-06  eta: 20:56:28  time: 1.0070  data_time: 0.0126  memory: 18544  grad_norm: 8.3219  loss: 1.1834  decode.loss_cls: 0.0001  decode.loss_mask: 0.0440  decode.loss_dice: 0.0701  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0453  decode.d0.loss_dice: 0.0681  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0455  decode.d1.loss_dice: 0.0670  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0446  decode.d2.loss_dice: 0.0733  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0467  decode.d3.loss_dice: 0.0708  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0453  decode.d4.loss_dice: 0.0683  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0453  decode.d5.loss_dice: 0.0749  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0452  decode.d6.loss_dice: 0.0719  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0459  decode.d7.loss_dice: 0.0711  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.0445  decode.d8.loss_dice: 0.0672
2023/12/31 19:30:07 - mmengine - INFO - Iter(train) [15250/90000]  base_lr: 8.4613e-05 lr: 8.4613e-06  eta: 20:55:37  time: 1.0065  data_time: 0.0128  memory: 18544  grad_norm: 5.5686  loss: 1.1768  decode.loss_cls: 0.0000  decode.loss_mask: 0.0402  decode.loss_dice: 0.0770  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.0376  decode.d0.loss_dice: 0.0625  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0390  decode.d1.loss_dice: 0.0955  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0384  decode.d2.loss_dice: 0.0663  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0395  decode.d3.loss_dice: 0.1085  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0382  decode.d4.loss_dice: 0.0719  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0390  decode.d5.loss_dice: 0.0797  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0394  decode.d6.loss_dice: 0.0714  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0385  decode.d7.loss_dice: 0.0655  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0385  decode.d8.loss_dice: 0.0670
2023/12/31 19:30:57 - mmengine - INFO - Iter(train) [15300/90000]  base_lr: 8.4562e-05 lr: 8.4562e-06  eta: 20:54:46  time: 1.0066  data_time: 0.0124  memory: 18544  grad_norm: 8.7538  loss: 1.2314  decode.loss_cls: 0.0000  decode.loss_mask: 0.0435  decode.loss_dice: 0.0791  decode.d0.loss_cls: 0.0149  decode.d0.loss_mask: 0.0434  decode.d0.loss_dice: 0.0733  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0433  decode.d1.loss_dice: 0.0765  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0432  decode.d2.loss_dice: 0.0776  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0431  decode.d3.loss_dice: 0.0810  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0418  decode.d4.loss_dice: 0.0720  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0418  decode.d5.loss_dice: 0.0725  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0441  decode.d6.loss_dice: 0.0832  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0423  decode.d7.loss_dice: 0.0847  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0417  decode.d8.loss_dice: 0.0884
2023/12/31 19:31:47 - mmengine - INFO - Iter(train) [15350/90000]  base_lr: 8.4511e-05 lr: 8.4511e-06  eta: 20:53:56  time: 1.0068  data_time: 0.0135  memory: 18544  grad_norm: 8.8740  loss: 1.1658  decode.loss_cls: 0.0000  decode.loss_mask: 0.0477  decode.loss_dice: 0.0658  decode.d0.loss_cls: 0.0353  decode.d0.loss_mask: 0.0477  decode.d0.loss_dice: 0.0655  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0469  decode.d1.loss_dice: 0.0628  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0464  decode.d2.loss_dice: 0.0647  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0472  decode.d3.loss_dice: 0.0671  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0467  decode.d4.loss_dice: 0.0630  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0480  decode.d5.loss_dice: 0.0647  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0470  decode.d6.loss_dice: 0.0678  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0483  decode.d7.loss_dice: 0.0670  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0484  decode.d8.loss_dice: 0.0677
2023/12/31 19:32:38 - mmengine - INFO - Iter(train) [15400/90000]  base_lr: 8.4460e-05 lr: 8.4460e-06  eta: 20:53:05  time: 1.0079  data_time: 0.0135  memory: 18544  grad_norm: 10.3143  loss: 1.0372  decode.loss_cls: 0.0000  decode.loss_mask: 0.0445  decode.loss_dice: 0.0572  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.0435  decode.d0.loss_dice: 0.0530  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0452  decode.d1.loss_dice: 0.0593  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0454  decode.d2.loss_dice: 0.0554  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0451  decode.d3.loss_dice: 0.0550  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0448  decode.d4.loss_dice: 0.0589  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0439  decode.d5.loss_dice: 0.0580  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0439  decode.d6.loss_dice: 0.0591  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0433  decode.d7.loss_dice: 0.0543  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0441  decode.d8.loss_dice: 0.0545
2023/12/31 19:33:28 - mmengine - INFO - Iter(train) [15450/90000]  base_lr: 8.4409e-05 lr: 8.4409e-06  eta: 20:52:15  time: 1.0051  data_time: 0.0123  memory: 18544  grad_norm: 83.2979  loss: 1.5236  decode.loss_cls: 0.0000  decode.loss_mask: 0.0690  decode.loss_dice: 0.0812  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0703  decode.d0.loss_dice: 0.0768  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0700  decode.d1.loss_dice: 0.0754  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0723  decode.d2.loss_dice: 0.0800  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0710  decode.d3.loss_dice: 0.0757  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0712  decode.d4.loss_dice: 0.0813  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0692  decode.d5.loss_dice: 0.0782  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0724  decode.d6.loss_dice: 0.0826  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0716  decode.d7.loss_dice: 0.0838  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0683  decode.d8.loss_dice: 0.0769
2023/12/31 19:34:18 - mmengine - INFO - Iter(train) [15500/90000]  base_lr: 8.4358e-05 lr: 8.4358e-06  eta: 20:51:24  time: 1.0072  data_time: 0.0127  memory: 18544  grad_norm: 6.6587  loss: 1.1256  decode.loss_cls: 0.0000  decode.loss_mask: 0.0418  decode.loss_dice: 0.0710  decode.d0.loss_cls: 0.0257  decode.d0.loss_mask: 0.0401  decode.d0.loss_dice: 0.0688  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0423  decode.d1.loss_dice: 0.0710  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0411  decode.d2.loss_dice: 0.0663  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0419  decode.d3.loss_dice: 0.0752  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0395  decode.d4.loss_dice: 0.0677  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0401  decode.d5.loss_dice: 0.0676  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0414  decode.d6.loss_dice: 0.0661  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0413  decode.d7.loss_dice: 0.0635  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0414  decode.d8.loss_dice: 0.0720
2023/12/31 19:35:09 - mmengine - INFO - Iter(train) [15550/90000]  base_lr: 8.4307e-05 lr: 8.4307e-06  eta: 20:50:33  time: 1.0084  data_time: 0.0131  memory: 18544  grad_norm: 12.9700  loss: 1.3478  decode.loss_cls: 0.0000  decode.loss_mask: 0.0573  decode.loss_dice: 0.0712  decode.d0.loss_cls: 0.0301  decode.d0.loss_mask: 0.0580  decode.d0.loss_dice: 0.0779  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0574  decode.d1.loss_dice: 0.0737  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0576  decode.d2.loss_dice: 0.0734  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0575  decode.d3.loss_dice: 0.0741  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0581  decode.d4.loss_dice: 0.0752  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0578  decode.d5.loss_dice: 0.0755  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0577  decode.d6.loss_dice: 0.0715  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0574  decode.d7.loss_dice: 0.0714  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0588  decode.d8.loss_dice: 0.0760
2023/12/31 19:35:59 - mmengine - INFO - Iter(train) [15600/90000]  base_lr: 8.4256e-05 lr: 8.4256e-06  eta: 20:49:43  time: 1.0059  data_time: 0.0125  memory: 18544  grad_norm: 6.0892  loss: 1.1030  decode.loss_cls: 0.0000  decode.loss_mask: 0.0444  decode.loss_dice: 0.0639  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0467  decode.d0.loss_dice: 0.0619  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0447  decode.d1.loss_dice: 0.0626  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0461  decode.d2.loss_dice: 0.0627  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0456  decode.d3.loss_dice: 0.0619  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0444  decode.d4.loss_dice: 0.0651  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0455  decode.d5.loss_dice: 0.0613  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0451  decode.d6.loss_dice: 0.0607  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0456  decode.d7.loss_dice: 0.0608  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0442  decode.d8.loss_dice: 0.0616
2023/12/31 19:36:49 - mmengine - INFO - Iter(train) [15650/90000]  base_lr: 8.4205e-05 lr: 8.4205e-06  eta: 20:48:52  time: 1.0069  data_time: 0.0132  memory: 18544  grad_norm: 7.3087  loss: 1.1947  decode.loss_cls: 0.0000  decode.loss_mask: 0.0437  decode.loss_dice: 0.0692  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0448  decode.d0.loss_dice: 0.0715  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0444  decode.d1.loss_dice: 0.0757  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0433  decode.d2.loss_dice: 0.0688  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0450  decode.d3.loss_dice: 0.0698  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0448  decode.d4.loss_dice: 0.0741  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0443  decode.d5.loss_dice: 0.0767  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0455  decode.d6.loss_dice: 0.0717  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0441  decode.d7.loss_dice: 0.0761  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0448  decode.d8.loss_dice: 0.0695
2023/12/31 19:37:40 - mmengine - INFO - Iter(train) [15700/90000]  base_lr: 8.4154e-05 lr: 8.4154e-06  eta: 20:48:01  time: 1.0077  data_time: 0.0136  memory: 18544  grad_norm: 16.5746  loss: 1.1552  decode.loss_cls: 0.0000  decode.loss_mask: 0.0418  decode.loss_dice: 0.0710  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0407  decode.d0.loss_dice: 0.0778  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0408  decode.d1.loss_dice: 0.0756  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0410  decode.d2.loss_dice: 0.0728  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0399  decode.d3.loss_dice: 0.0720  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0401  decode.d4.loss_dice: 0.0703  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0405  decode.d5.loss_dice: 0.0641  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0398  decode.d6.loss_dice: 0.0741  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0416  decode.d7.loss_dice: 0.0735  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0404  decode.d8.loss_dice: 0.0708
2023/12/31 19:38:30 - mmengine - INFO - Iter(train) [15750/90000]  base_lr: 8.4103e-05 lr: 8.4103e-06  eta: 20:47:11  time: 1.0054  data_time: 0.0121  memory: 18544  grad_norm: 13.6268  loss: 1.2439  decode.loss_cls: 0.0000  decode.loss_mask: 0.0488  decode.loss_dice: 0.0744  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0473  decode.d0.loss_dice: 0.0770  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0476  decode.d1.loss_dice: 0.0723  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0471  decode.d2.loss_dice: 0.0765  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0456  decode.d3.loss_dice: 0.0749  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0479  decode.d4.loss_dice: 0.0743  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0469  decode.d5.loss_dice: 0.0783  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0459  decode.d6.loss_dice: 0.0726  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0460  decode.d7.loss_dice: 0.0733  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0478  decode.d8.loss_dice: 0.0728
2023/12/31 19:39:20 - mmengine - INFO - Iter(train) [15800/90000]  base_lr: 8.4052e-05 lr: 8.4052e-06  eta: 20:46:20  time: 1.0073  data_time: 0.0130  memory: 18544  grad_norm: 7.2245  loss: 1.0872  decode.loss_cls: 0.0000  decode.loss_mask: 0.0394  decode.loss_dice: 0.0640  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0390  decode.d0.loss_dice: 0.0642  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0401  decode.d1.loss_dice: 0.0693  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0400  decode.d2.loss_dice: 0.0693  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0401  decode.d3.loss_dice: 0.0659  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0394  decode.d4.loss_dice: 0.0683  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0401  decode.d5.loss_dice: 0.0674  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0394  decode.d6.loss_dice: 0.0655  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0399  decode.d7.loss_dice: 0.0668  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0391  decode.d8.loss_dice: 0.0648
2023/12/31 19:40:11 - mmengine - INFO - Iter(train) [15850/90000]  base_lr: 8.4001e-05 lr: 8.4001e-06  eta: 20:45:29  time: 1.0080  data_time: 0.0137  memory: 18544  grad_norm: 6.3642  loss: 1.1674  decode.loss_cls: 0.0000  decode.loss_mask: 0.0421  decode.loss_dice: 0.0719  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.0421  decode.d0.loss_dice: 0.0711  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0416  decode.d1.loss_dice: 0.0715  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0422  decode.d2.loss_dice: 0.0726  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0426  decode.d3.loss_dice: 0.0728  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0415  decode.d4.loss_dice: 0.0716  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0440  decode.d5.loss_dice: 0.0743  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0423  decode.d6.loss_dice: 0.0724  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0422  decode.d7.loss_dice: 0.0720  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0423  decode.d8.loss_dice: 0.0695
2023/12/31 19:41:01 - mmengine - INFO - Iter(train) [15900/90000]  base_lr: 8.3950e-05 lr: 8.3950e-06  eta: 20:44:39  time: 1.0064  data_time: 0.0122  memory: 18544  grad_norm: 10.4370  loss: 1.1505  decode.loss_cls: 0.0000  decode.loss_mask: 0.0431  decode.loss_dice: 0.0720  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.0435  decode.d0.loss_dice: 0.0713  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0437  decode.d1.loss_dice: 0.0705  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0437  decode.d2.loss_dice: 0.0707  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0443  decode.d3.loss_dice: 0.0674  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0444  decode.d4.loss_dice: 0.0716  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0432  decode.d5.loss_dice: 0.0663  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0429  decode.d6.loss_dice: 0.0637  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0439  decode.d7.loss_dice: 0.0698  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0429  decode.d8.loss_dice: 0.0668
2023/12/31 19:41:51 - mmengine - INFO - Iter(train) [15950/90000]  base_lr: 8.3899e-05 lr: 8.3899e-06  eta: 20:43:48  time: 1.0068  data_time: 0.0133  memory: 18544  grad_norm: 7.2040  loss: 1.1752  decode.loss_cls: 0.0000  decode.loss_mask: 0.0377  decode.loss_dice: 0.0752  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0378  decode.d0.loss_dice: 0.0759  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0385  decode.d1.loss_dice: 0.0772  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0401  decode.d2.loss_dice: 0.0804  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0377  decode.d3.loss_dice: 0.0734  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0383  decode.d4.loss_dice: 0.0721  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0389  decode.d5.loss_dice: 0.0817  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0377  decode.d6.loss_dice: 0.0756  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0385  decode.d7.loss_dice: 0.0813  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0380  decode.d8.loss_dice: 0.0763
2023/12/31 19:42:42 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 19:42:42 - mmengine - INFO - Iter(train) [16000/90000]  base_lr: 8.3848e-05 lr: 8.3848e-06  eta: 20:42:58  time: 1.0080  data_time: 0.0137  memory: 18544  grad_norm: 6.9511  loss: 1.0487  decode.loss_cls: 0.0000  decode.loss_mask: 0.0401  decode.loss_dice: 0.0597  decode.d0.loss_cls: 0.0298  decode.d0.loss_mask: 0.0421  decode.d0.loss_dice: 0.0645  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0408  decode.d1.loss_dice: 0.0597  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0398  decode.d2.loss_dice: 0.0574  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0418  decode.d3.loss_dice: 0.0586  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0413  decode.d4.loss_dice: 0.0603  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0411  decode.d5.loss_dice: 0.0610  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0413  decode.d6.loss_dice: 0.0620  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0425  decode.d7.loss_dice: 0.0628  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0415  decode.d8.loss_dice: 0.0607
2023/12/31 19:43:32 - mmengine - INFO - Iter(train) [16050/90000]  base_lr: 8.3797e-05 lr: 8.3797e-06  eta: 20:42:07  time: 1.0058  data_time: 0.0119  memory: 18544  grad_norm: 6.8747  loss: 1.1255  decode.loss_cls: 0.0000  decode.loss_mask: 0.0430  decode.loss_dice: 0.0659  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0433  decode.d0.loss_dice: 0.0696  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0423  decode.d1.loss_dice: 0.0652  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0426  decode.d2.loss_dice: 0.0667  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0435  decode.d3.loss_dice: 0.0656  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0425  decode.d4.loss_dice: 0.0660  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0452  decode.d5.loss_dice: 0.0703  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0446  decode.d6.loss_dice: 0.0661  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0433  decode.d7.loss_dice: 0.0692  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0417  decode.d8.loss_dice: 0.0641
2023/12/31 19:44:22 - mmengine - INFO - Iter(train) [16100/90000]  base_lr: 8.3746e-05 lr: 8.3746e-06  eta: 20:41:17  time: 1.0089  data_time: 0.0133  memory: 18544  grad_norm: 6.6319  loss: 1.1239  decode.loss_cls: 0.0000  decode.loss_mask: 0.0417  decode.loss_dice: 0.0662  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.0421  decode.d0.loss_dice: 0.0667  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0434  decode.d1.loss_dice: 0.0684  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0412  decode.d2.loss_dice: 0.0645  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0426  decode.d3.loss_dice: 0.0667  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0420  decode.d4.loss_dice: 0.0658  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0420  decode.d5.loss_dice: 0.0680  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0430  decode.d6.loss_dice: 0.0717  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0430  decode.d7.loss_dice: 0.0686  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0431  decode.d8.loss_dice: 0.0701
2023/12/31 19:45:13 - mmengine - INFO - Iter(train) [16150/90000]  base_lr: 8.3695e-05 lr: 8.3695e-06  eta: 20:40:26  time: 1.0086  data_time: 0.0135  memory: 18544  grad_norm: 5.6044  loss: 1.0415  decode.loss_cls: 0.0000  decode.loss_mask: 0.0406  decode.loss_dice: 0.0614  decode.d0.loss_cls: 0.0212  decode.d0.loss_mask: 0.0397  decode.d0.loss_dice: 0.0617  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0393  decode.d1.loss_dice: 0.0593  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0404  decode.d2.loss_dice: 0.0618  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0406  decode.d3.loss_dice: 0.0632  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0404  decode.d4.loss_dice: 0.0625  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0392  decode.d5.loss_dice: 0.0598  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0410  decode.d6.loss_dice: 0.0621  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0402  decode.d7.loss_dice: 0.0615  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0412  decode.d8.loss_dice: 0.0644
2023/12/31 19:46:03 - mmengine - INFO - Iter(train) [16200/90000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 20:39:35  time: 1.0069  data_time: 0.0123  memory: 18544  grad_norm: 5.6147  loss: 1.0105  decode.loss_cls: 0.0000  decode.loss_mask: 0.0427  decode.loss_dice: 0.0598  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0412  decode.d0.loss_dice: 0.0569  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0414  decode.d1.loss_dice: 0.0570  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0409  decode.d2.loss_dice: 0.0565  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0408  decode.d3.loss_dice: 0.0580  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0410  decode.d4.loss_dice: 0.0545  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0406  decode.d5.loss_dice: 0.0568  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0420  decode.d6.loss_dice: 0.0604  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0413  decode.d7.loss_dice: 0.0580  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0414  decode.d8.loss_dice: 0.0564
2023/12/31 19:46:53 - mmengine - INFO - Iter(train) [16250/90000]  base_lr: 8.3593e-05 lr: 8.3593e-06  eta: 20:38:45  time: 1.0071  data_time: 0.0135  memory: 18544  grad_norm: 5.9222  loss: 1.0068  decode.loss_cls: 0.0000  decode.loss_mask: 0.0415  decode.loss_dice: 0.0571  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0416  decode.d0.loss_dice: 0.0542  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0424  decode.d1.loss_dice: 0.0572  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0406  decode.d2.loss_dice: 0.0563  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0419  decode.d3.loss_dice: 0.0570  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0415  decode.d4.loss_dice: 0.0561  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0403  decode.d5.loss_dice: 0.0577  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0419  decode.d6.loss_dice: 0.0586  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0410  decode.d7.loss_dice: 0.0560  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0424  decode.d8.loss_dice: 0.0567
2023/12/31 19:47:44 - mmengine - INFO - Iter(train) [16300/90000]  base_lr: 8.3542e-05 lr: 8.3542e-06  eta: 20:37:54  time: 1.0115  data_time: 0.0142  memory: 18544  grad_norm: 14.5165  loss: 1.1643  decode.loss_cls: 0.0000  decode.loss_mask: 0.0456  decode.loss_dice: 0.0679  decode.d0.loss_cls: 0.0227  decode.d0.loss_mask: 0.0481  decode.d0.loss_dice: 0.0688  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0455  decode.d1.loss_dice: 0.0660  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0467  decode.d2.loss_dice: 0.0658  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0472  decode.d3.loss_dice: 0.0702  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0471  decode.d4.loss_dice: 0.0678  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0471  decode.d5.loss_dice: 0.0683  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0454  decode.d6.loss_dice: 0.0674  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0468  decode.d7.loss_dice: 0.0683  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0459  decode.d8.loss_dice: 0.0655
2023/12/31 19:48:34 - mmengine - INFO - Iter(train) [16350/90000]  base_lr: 8.3491e-05 lr: 8.3491e-06  eta: 20:37:03  time: 1.0069  data_time: 0.0118  memory: 18544  grad_norm: 7.2553  loss: 1.0881  decode.loss_cls: 0.0000  decode.loss_mask: 0.0385  decode.loss_dice: 0.0708  decode.d0.loss_cls: 0.0175  decode.d0.loss_mask: 0.0375  decode.d0.loss_dice: 0.0654  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0388  decode.d1.loss_dice: 0.0694  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0379  decode.d2.loss_dice: 0.0696  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0389  decode.d3.loss_dice: 0.0720  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0380  decode.d4.loss_dice: 0.0650  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0377  decode.d5.loss_dice: 0.0655  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0384  decode.d6.loss_dice: 0.0705  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0375  decode.d7.loss_dice: 0.0696  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0386  decode.d8.loss_dice: 0.0709
2023/12/31 19:49:24 - mmengine - INFO - Iter(train) [16400/90000]  base_lr: 8.3440e-05 lr: 8.3440e-06  eta: 20:36:13  time: 1.0079  data_time: 0.0133  memory: 18544  grad_norm: 7.0705  loss: 1.1238  decode.loss_cls: 0.0000  decode.loss_mask: 0.0397  decode.loss_dice: 0.0737  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.0379  decode.d0.loss_dice: 0.0703  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0376  decode.d1.loss_dice: 0.0711  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0389  decode.d2.loss_dice: 0.0745  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0390  decode.d3.loss_dice: 0.0696  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0392  decode.d4.loss_dice: 0.0734  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0382  decode.d5.loss_dice: 0.0681  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0388  decode.d6.loss_dice: 0.0666  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0389  decode.d7.loss_dice: 0.0704  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0389  decode.d8.loss_dice: 0.0726
2023/12/31 19:50:15 - mmengine - INFO - Iter(train) [16450/90000]  base_lr: 8.3389e-05 lr: 8.3389e-06  eta: 20:35:22  time: 1.0065  data_time: 0.0129  memory: 18544  grad_norm: 6.9844  loss: 1.1068  decode.loss_cls: 0.0000  decode.loss_mask: 0.0417  decode.loss_dice: 0.0680  decode.d0.loss_cls: 0.0302  decode.d0.loss_mask: 0.0417  decode.d0.loss_dice: 0.0631  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0425  decode.d1.loss_dice: 0.0647  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0417  decode.d2.loss_dice: 0.0643  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0428  decode.d3.loss_dice: 0.0640  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0418  decode.d4.loss_dice: 0.0629  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0427  decode.d5.loss_dice: 0.0669  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0431  decode.d6.loss_dice: 0.0672  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0417  decode.d7.loss_dice: 0.0663  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0424  decode.d8.loss_dice: 0.0672
2023/12/31 19:51:05 - mmengine - INFO - Iter(train) [16500/90000]  base_lr: 8.3338e-05 lr: 8.3338e-06  eta: 20:34:31  time: 1.0052  data_time: 0.0118  memory: 18544  grad_norm: 7.9879  loss: 1.1712  decode.loss_cls: 0.0000  decode.loss_mask: 0.0445  decode.loss_dice: 0.0742  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.0440  decode.d0.loss_dice: 0.0714  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0444  decode.d1.loss_dice: 0.0706  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0416  decode.d2.loss_dice: 0.0692  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0452  decode.d3.loss_dice: 0.0724  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0443  decode.d4.loss_dice: 0.0696  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0438  decode.d5.loss_dice: 0.0704  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0433  decode.d6.loss_dice: 0.0679  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0443  decode.d7.loss_dice: 0.0710  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0435  decode.d8.loss_dice: 0.0708
2023/12/31 19:51:55 - mmengine - INFO - Iter(train) [16550/90000]  base_lr: 8.3287e-05 lr: 8.3287e-06  eta: 20:33:41  time: 1.0077  data_time: 0.0133  memory: 18544  grad_norm: 10.1581  loss: 1.1535  decode.loss_cls: 0.0000  decode.loss_mask: 0.0423  decode.loss_dice: 0.0723  decode.d0.loss_cls: 0.0334  decode.d0.loss_mask: 0.0420  decode.d0.loss_dice: 0.0700  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0411  decode.d1.loss_dice: 0.0642  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0424  decode.d2.loss_dice: 0.0680  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0414  decode.d3.loss_dice: 0.0667  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0428  decode.d4.loss_dice: 0.0709  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0429  decode.d5.loss_dice: 0.0762  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0428  decode.d6.loss_dice: 0.0673  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0425  decode.d7.loss_dice: 0.0719  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0429  decode.d8.loss_dice: 0.0695
2023/12/31 19:52:46 - mmengine - INFO - Iter(train) [16600/90000]  base_lr: 8.3236e-05 lr: 8.3236e-06  eta: 20:32:50  time: 1.0071  data_time: 0.0132  memory: 18544  grad_norm: 6.8923  loss: 1.0757  decode.loss_cls: 0.0000  decode.loss_mask: 0.0402  decode.loss_dice: 0.0734  decode.d0.loss_cls: 0.0228  decode.d0.loss_mask: 0.0400  decode.d0.loss_dice: 0.0687  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0396  decode.d1.loss_dice: 0.0665  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0393  decode.d2.loss_dice: 0.0609  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0393  decode.d3.loss_dice: 0.0649  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0406  decode.d4.loss_dice: 0.0676  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0406  decode.d5.loss_dice: 0.0668  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0390  decode.d6.loss_dice: 0.0633  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0390  decode.d7.loss_dice: 0.0616  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0389  decode.d8.loss_dice: 0.0625
2023/12/31 19:53:36 - mmengine - INFO - Iter(train) [16650/90000]  base_lr: 8.3185e-05 lr: 8.3185e-06  eta: 20:31:59  time: 1.0064  data_time: 0.0123  memory: 18544  grad_norm: 8.3144  loss: 1.1092  decode.loss_cls: 0.0000  decode.loss_mask: 0.0405  decode.loss_dice: 0.0701  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.0378  decode.d0.loss_dice: 0.0656  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0400  decode.d1.loss_dice: 0.0711  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0391  decode.d2.loss_dice: 0.0674  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0391  decode.d3.loss_dice: 0.0667  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0399  decode.d4.loss_dice: 0.0671  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0412  decode.d5.loss_dice: 0.0670  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0394  decode.d6.loss_dice: 0.0716  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0396  decode.d7.loss_dice: 0.0651  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0401  decode.d8.loss_dice: 0.0722
2023/12/31 19:54:26 - mmengine - INFO - Iter(train) [16700/90000]  base_lr: 8.3134e-05 lr: 8.3134e-06  eta: 20:31:09  time: 1.0073  data_time: 0.0138  memory: 18544  grad_norm: 6.9440  loss: 1.0562  decode.loss_cls: 0.0000  decode.loss_mask: 0.0383  decode.loss_dice: 0.0629  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0395  decode.d0.loss_dice: 0.0688  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0372  decode.d1.loss_dice: 0.0618  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0383  decode.d2.loss_dice: 0.0671  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0381  decode.d3.loss_dice: 0.0670  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0387  decode.d4.loss_dice: 0.0602  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0380  decode.d5.loss_dice: 0.0643  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0390  decode.d6.loss_dice: 0.0668  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0382  decode.d7.loss_dice: 0.0644  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0380  decode.d8.loss_dice: 0.0666
2023/12/31 19:55:17 - mmengine - INFO - Iter(train) [16750/90000]  base_lr: 8.3083e-05 lr: 8.3083e-06  eta: 20:30:18  time: 1.0062  data_time: 0.0131  memory: 18544  grad_norm: 6.6461  loss: 1.0460  decode.loss_cls: 0.0000  decode.loss_mask: 0.0437  decode.loss_dice: 0.0621  decode.d0.loss_cls: 0.0269  decode.d0.loss_mask: 0.0432  decode.d0.loss_dice: 0.0564  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0433  decode.d1.loss_dice: 0.0570  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0441  decode.d2.loss_dice: 0.0583  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0418  decode.d3.loss_dice: 0.0574  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0426  decode.d4.loss_dice: 0.0590  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0440  decode.d5.loss_dice: 0.0573  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0440  decode.d6.loss_dice: 0.0570  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0431  decode.d7.loss_dice: 0.0603  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0439  decode.d8.loss_dice: 0.0605
2023/12/31 19:56:07 - mmengine - INFO - Iter(train) [16800/90000]  base_lr: 8.3032e-05 lr: 8.3032e-06  eta: 20:29:28  time: 1.0050  data_time: 0.0120  memory: 18544  grad_norm: 7.1339  loss: 1.0831  decode.loss_cls: 0.0000  decode.loss_mask: 0.0421  decode.loss_dice: 0.0634  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0416  decode.d0.loss_dice: 0.0642  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0412  decode.d1.loss_dice: 0.0658  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0404  decode.d2.loss_dice: 0.0650  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0401  decode.d3.loss_dice: 0.0602  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0411  decode.d4.loss_dice: 0.0630  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0411  decode.d5.loss_dice: 0.0647  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0422  decode.d6.loss_dice: 0.0644  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0413  decode.d7.loss_dice: 0.0658  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0413  decode.d8.loss_dice: 0.0661
2023/12/31 19:56:57 - mmengine - INFO - Iter(train) [16850/90000]  base_lr: 8.2981e-05 lr: 8.2981e-06  eta: 20:28:37  time: 1.0060  data_time: 0.0122  memory: 18544  grad_norm: 9.5643  loss: 1.1798  decode.loss_cls: 0.0000  decode.loss_mask: 0.0435  decode.loss_dice: 0.0714  decode.d0.loss_cls: 0.0335  decode.d0.loss_mask: 0.0439  decode.d0.loss_dice: 0.0723  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0426  decode.d1.loss_dice: 0.0708  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0439  decode.d2.loss_dice: 0.0671  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0439  decode.d3.loss_dice: 0.0701  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0432  decode.d4.loss_dice: 0.0697  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0427  decode.d5.loss_dice: 0.0720  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0438  decode.d6.loss_dice: 0.0764  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0419  decode.d7.loss_dice: 0.0705  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0442  decode.d8.loss_dice: 0.0726
2023/12/31 19:57:48 - mmengine - INFO - Iter(train) [16900/90000]  base_lr: 8.2930e-05 lr: 8.2930e-06  eta: 20:27:46  time: 1.0072  data_time: 0.0136  memory: 18544  grad_norm: 6.6219  loss: 1.1051  decode.loss_cls: 0.0000  decode.loss_mask: 0.0493  decode.loss_dice: 0.0603  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0477  decode.d0.loss_dice: 0.0580  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0488  decode.d1.loss_dice: 0.0629  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0476  decode.d2.loss_dice: 0.0614  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0490  decode.d3.loss_dice: 0.0606  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0491  decode.d4.loss_dice: 0.0584  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0490  decode.d5.loss_dice: 0.0600  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0474  decode.d6.loss_dice: 0.0577  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0478  decode.d7.loss_dice: 0.0581  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0475  decode.d8.loss_dice: 0.0581
2023/12/31 19:58:38 - mmengine - INFO - Iter(train) [16950/90000]  base_lr: 8.2879e-05 lr: 8.2879e-06  eta: 20:26:55  time: 1.0050  data_time: 0.0118  memory: 18544  grad_norm: 8.1117  loss: 1.1607  decode.loss_cls: 0.0000  decode.loss_mask: 0.0412  decode.loss_dice: 0.0737  decode.d0.loss_cls: 0.0236  decode.d0.loss_mask: 0.0404  decode.d0.loss_dice: 0.0728  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0398  decode.d1.loss_dice: 0.0727  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0412  decode.d2.loss_dice: 0.0746  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0407  decode.d3.loss_dice: 0.0743  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0396  decode.d4.loss_dice: 0.0716  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0407  decode.d5.loss_dice: 0.0683  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0411  decode.d6.loss_dice: 0.0783  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0403  decode.d7.loss_dice: 0.0676  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0407  decode.d8.loss_dice: 0.0775
2023/12/31 19:59:28 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 19:59:28 - mmengine - INFO - Iter(train) [17000/90000]  base_lr: 8.2828e-05 lr: 8.2828e-06  eta: 20:26:05  time: 1.0073  data_time: 0.0133  memory: 18544  grad_norm: 6.9631  loss: 1.1470  decode.loss_cls: 0.0000  decode.loss_mask: 0.0432  decode.loss_dice: 0.0659  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0422  decode.d0.loss_dice: 0.0643  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0433  decode.d1.loss_dice: 0.0712  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0424  decode.d2.loss_dice: 0.0660  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0433  decode.d3.loss_dice: 0.0662  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0430  decode.d4.loss_dice: 0.0722  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0437  decode.d5.loss_dice: 0.0703  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0442  decode.d6.loss_dice: 0.0668  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0438  decode.d7.loss_dice: 0.0692  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0440  decode.d8.loss_dice: 0.0740
2023/12/31 20:00:19 - mmengine - INFO - Iter(train) [17050/90000]  base_lr: 8.2777e-05 lr: 8.2777e-06  eta: 20:25:14  time: 1.0078  data_time: 0.0134  memory: 18544  grad_norm: 7.0767  loss: 1.0985  decode.loss_cls: 0.0000  decode.loss_mask: 0.0420  decode.loss_dice: 0.0651  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0409  decode.d0.loss_dice: 0.0650  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0427  decode.d1.loss_dice: 0.0679  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0414  decode.d2.loss_dice: 0.0621  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0424  decode.d3.loss_dice: 0.0612  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0430  decode.d4.loss_dice: 0.0647  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0421  decode.d5.loss_dice: 0.0676  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0428  decode.d6.loss_dice: 0.0650  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0421  decode.d7.loss_dice: 0.0646  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0431  decode.d8.loss_dice: 0.0665
2023/12/31 20:01:09 - mmengine - INFO - Iter(train) [17100/90000]  base_lr: 8.2726e-05 lr: 8.2726e-06  eta: 20:24:23  time: 1.0055  data_time: 0.0117  memory: 18544  grad_norm: 6.7797  loss: 1.1039  decode.loss_cls: 0.0000  decode.loss_mask: 0.0433  decode.loss_dice: 0.0615  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0432  decode.d0.loss_dice: 0.0644  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0424  decode.d1.loss_dice: 0.0639  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0418  decode.d2.loss_dice: 0.0650  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0423  decode.d3.loss_dice: 0.0629  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0424  decode.d4.loss_dice: 0.0646  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0443  decode.d5.loss_dice: 0.0690  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0423  decode.d6.loss_dice: 0.0656  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0432  decode.d7.loss_dice: 0.0670  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0429  decode.d8.loss_dice: 0.0671
2023/12/31 20:01:59 - mmengine - INFO - Iter(train) [17150/90000]  base_lr: 8.2675e-05 lr: 8.2675e-06  eta: 20:23:33  time: 1.0059  data_time: 0.0121  memory: 18544  grad_norm: 7.0971  loss: 1.1091  decode.loss_cls: 0.0000  decode.loss_mask: 0.0405  decode.loss_dice: 0.0671  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.0418  decode.d0.loss_dice: 0.0786  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0413  decode.d1.loss_dice: 0.0641  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0402  decode.d2.loss_dice: 0.0691  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0408  decode.d3.loss_dice: 0.0596  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0404  decode.d4.loss_dice: 0.0604  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0401  decode.d5.loss_dice: 0.0674  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0421  decode.d6.loss_dice: 0.0657  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0405  decode.d7.loss_dice: 0.0804  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0404  decode.d8.loss_dice: 0.0673
2023/12/31 20:02:50 - mmengine - INFO - Iter(train) [17200/90000]  base_lr: 8.2624e-05 lr: 8.2624e-06  eta: 20:22:42  time: 1.0061  data_time: 0.0128  memory: 18544  grad_norm: 6.0623  loss: 1.0536  decode.loss_cls: 0.0000  decode.loss_mask: 0.0428  decode.loss_dice: 0.0573  decode.d0.loss_cls: 0.0340  decode.d0.loss_mask: 0.0443  decode.d0.loss_dice: 0.0569  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0441  decode.d1.loss_dice: 0.0599  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0440  decode.d2.loss_dice: 0.0575  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0439  decode.d3.loss_dice: 0.0565  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0438  decode.d4.loss_dice: 0.0580  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0434  decode.d5.loss_dice: 0.0581  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0440  decode.d6.loss_dice: 0.0567  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0445  decode.d7.loss_dice: 0.0602  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0442  decode.d8.loss_dice: 0.0596
2023/12/31 20:03:40 - mmengine - INFO - Iter(train) [17250/90000]  base_lr: 8.2573e-05 lr: 8.2573e-06  eta: 20:21:52  time: 1.0050  data_time: 0.0117  memory: 18544  grad_norm: 10.7661  loss: 1.2036  decode.loss_cls: 0.0000  decode.loss_mask: 0.0425  decode.loss_dice: 0.0760  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0414  decode.d0.loss_dice: 0.0757  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0412  decode.d1.loss_dice: 0.0783  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0425  decode.d2.loss_dice: 0.0752  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0416  decode.d3.loss_dice: 0.0757  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0423  decode.d4.loss_dice: 0.0747  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0407  decode.d5.loss_dice: 0.0747  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0411  decode.d6.loss_dice: 0.0780  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0407  decode.d7.loss_dice: 0.0785  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0417  decode.d8.loss_dice: 0.0780
2023/12/31 20:04:30 - mmengine - INFO - Iter(train) [17300/90000]  base_lr: 8.2521e-05 lr: 8.2521e-06  eta: 20:21:01  time: 1.0055  data_time: 0.0122  memory: 18544  grad_norm: 7.2546  loss: 1.1573  decode.loss_cls: 0.0000  decode.loss_mask: 0.0395  decode.loss_dice: 0.0738  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0389  decode.d0.loss_dice: 0.0748  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0388  decode.d1.loss_dice: 0.0728  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0394  decode.d2.loss_dice: 0.0713  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0401  decode.d3.loss_dice: 0.0783  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0388  decode.d4.loss_dice: 0.0738  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0401  decode.d5.loss_dice: 0.0766  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0389  decode.d6.loss_dice: 0.0710  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0395  decode.d7.loss_dice: 0.0740  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0397  decode.d8.loss_dice: 0.0708
2023/12/31 20:05:21 - mmengine - INFO - Iter(train) [17350/90000]  base_lr: 8.2470e-05 lr: 8.2470e-06  eta: 20:20:10  time: 1.0057  data_time: 0.0116  memory: 18544  grad_norm: 6.4575  loss: 1.0295  decode.loss_cls: 0.0000  decode.loss_mask: 0.0401  decode.loss_dice: 0.0568  decode.d0.loss_cls: 0.0278  decode.d0.loss_mask: 0.0410  decode.d0.loss_dice: 0.0601  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0410  decode.d1.loss_dice: 0.0594  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0393  decode.d2.loss_dice: 0.0595  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0403  decode.d3.loss_dice: 0.0567  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0417  decode.d4.loss_dice: 0.0613  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0402  decode.d5.loss_dice: 0.0590  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0422  decode.d6.loss_dice: 0.0635  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0404  decode.d7.loss_dice: 0.0582  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0405  decode.d8.loss_dice: 0.0605
2023/12/31 20:06:11 - mmengine - INFO - Iter(train) [17400/90000]  base_lr: 8.2419e-05 lr: 8.2419e-06  eta: 20:19:19  time: 1.0045  data_time: 0.0116  memory: 18544  grad_norm: 7.6641  loss: 1.1283  decode.loss_cls: 0.0000  decode.loss_mask: 0.0449  decode.loss_dice: 0.0624  decode.d0.loss_cls: 0.0314  decode.d0.loss_mask: 0.0459  decode.d0.loss_dice: 0.0641  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0464  decode.d1.loss_dice: 0.0627  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0471  decode.d2.loss_dice: 0.0655  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0473  decode.d3.loss_dice: 0.0651  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0461  decode.d4.loss_dice: 0.0609  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0451  decode.d5.loss_dice: 0.0621  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0453  decode.d6.loss_dice: 0.0628  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0467  decode.d7.loss_dice: 0.0657  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0458  decode.d8.loss_dice: 0.0652
2023/12/31 20:07:01 - mmengine - INFO - Iter(train) [17450/90000]  base_lr: 8.2368e-05 lr: 8.2368e-06  eta: 20:18:28  time: 1.0054  data_time: 0.0122  memory: 18544  grad_norm: 8.8045  loss: 1.2091  decode.loss_cls: 0.0003  decode.loss_mask: 0.0415  decode.loss_dice: 0.0748  decode.d0.loss_cls: 0.0292  decode.d0.loss_mask: 0.0400  decode.d0.loss_dice: 0.0635  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0403  decode.d1.loss_dice: 0.0841  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0402  decode.d2.loss_dice: 0.0744  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0409  decode.d3.loss_dice: 0.0732  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0407  decode.d4.loss_dice: 0.0910  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0415  decode.d5.loss_dice: 0.0770  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0414  decode.d6.loss_dice: 0.0711  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0417  decode.d7.loss_dice: 0.0783  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0420  decode.d8.loss_dice: 0.0818
2023/12/31 20:07:51 - mmengine - INFO - Iter(train) [17500/90000]  base_lr: 8.2317e-05 lr: 8.2317e-06  eta: 20:17:38  time: 1.0054  data_time: 0.0118  memory: 18544  grad_norm: 5.8074  loss: 1.0606  decode.loss_cls: 0.0000  decode.loss_mask: 0.0430  decode.loss_dice: 0.0601  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0425  decode.d0.loss_dice: 0.0582  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0428  decode.d1.loss_dice: 0.0596  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0421  decode.d2.loss_dice: 0.0606  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0431  decode.d3.loss_dice: 0.0628  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0428  decode.d4.loss_dice: 0.0634  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0416  decode.d5.loss_dice: 0.0617  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0423  decode.d6.loss_dice: 0.0609  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0427  decode.d7.loss_dice: 0.0583  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0435  decode.d8.loss_dice: 0.0621
2023/12/31 20:08:42 - mmengine - INFO - Iter(train) [17550/90000]  base_lr: 8.2266e-05 lr: 8.2266e-06  eta: 20:16:47  time: 1.0058  data_time: 0.0117  memory: 18544  grad_norm: 6.8162  loss: 1.1119  decode.loss_cls: 0.0000  decode.loss_mask: 0.0407  decode.loss_dice: 0.0674  decode.d0.loss_cls: 0.0219  decode.d0.loss_mask: 0.0398  decode.d0.loss_dice: 0.0690  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0400  decode.d1.loss_dice: 0.0674  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0410  decode.d2.loss_dice: 0.0691  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0402  decode.d3.loss_dice: 0.0680  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0404  decode.d4.loss_dice: 0.0657  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0400  decode.d5.loss_dice: 0.0671  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0409  decode.d6.loss_dice: 0.0703  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0405  decode.d7.loss_dice: 0.0738  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0407  decode.d8.loss_dice: 0.0682
2023/12/31 20:09:32 - mmengine - INFO - Iter(train) [17600/90000]  base_lr: 8.2215e-05 lr: 8.2215e-06  eta: 20:15:56  time: 1.0067  data_time: 0.0118  memory: 18544  grad_norm: 5.1160  loss: 1.0325  decode.loss_cls: 0.0000  decode.loss_mask: 0.0372  decode.loss_dice: 0.0681  decode.d0.loss_cls: 0.0189  decode.d0.loss_mask: 0.0358  decode.d0.loss_dice: 0.0646  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0362  decode.d1.loss_dice: 0.0657  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0356  decode.d2.loss_dice: 0.0701  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0345  decode.d3.loss_dice: 0.0605  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0357  decode.d4.loss_dice: 0.0622  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0356  decode.d5.loss_dice: 0.0629  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0368  decode.d6.loss_dice: 0.0650  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0354  decode.d7.loss_dice: 0.0665  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0360  decode.d8.loss_dice: 0.0693
2023/12/31 20:10:22 - mmengine - INFO - Iter(train) [17650/90000]  base_lr: 8.2164e-05 lr: 8.2164e-06  eta: 20:15:05  time: 1.0048  data_time: 0.0121  memory: 18544  grad_norm: 6.1017  loss: 1.0154  decode.loss_cls: 0.0001  decode.loss_mask: 0.0416  decode.loss_dice: 0.0531  decode.d0.loss_cls: 0.0285  decode.d0.loss_mask: 0.0417  decode.d0.loss_dice: 0.0590  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0417  decode.d1.loss_dice: 0.0582  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0417  decode.d2.loss_dice: 0.0554  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0418  decode.d3.loss_dice: 0.0579  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0412  decode.d4.loss_dice: 0.0540  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0425  decode.d5.loss_dice: 0.0576  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0421  decode.d6.loss_dice: 0.0579  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0410  decode.d7.loss_dice: 0.0563  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0424  decode.d8.loss_dice: 0.0593
2023/12/31 20:11:13 - mmengine - INFO - Iter(train) [17700/90000]  base_lr: 8.2113e-05 lr: 8.2113e-06  eta: 20:14:15  time: 1.0063  data_time: 0.0121  memory: 18544  grad_norm: 6.3862  loss: 1.1184  decode.loss_cls: 0.0000  decode.loss_mask: 0.0408  decode.loss_dice: 0.0723  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0408  decode.d0.loss_dice: 0.0695  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.0406  decode.d1.loss_dice: 0.0676  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.0408  decode.d2.loss_dice: 0.0688  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0403  decode.d3.loss_dice: 0.0718  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0412  decode.d4.loss_dice: 0.0659  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0395  decode.d5.loss_dice: 0.0655  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0398  decode.d6.loss_dice: 0.0670  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0394  decode.d7.loss_dice: 0.0664  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0413  decode.d8.loss_dice: 0.0710
2023/12/31 20:12:03 - mmengine - INFO - Iter(train) [17750/90000]  base_lr: 8.2062e-05 lr: 8.2062e-06  eta: 20:13:24  time: 1.0045  data_time: 0.0120  memory: 18544  grad_norm: 13.7057  loss: 1.1622  decode.loss_cls: 0.0000  decode.loss_mask: 0.0428  decode.loss_dice: 0.0704  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.0427  decode.d0.loss_dice: 0.0708  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0432  decode.d1.loss_dice: 0.0703  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0433  decode.d2.loss_dice: 0.0705  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0419  decode.d3.loss_dice: 0.0697  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0425  decode.d4.loss_dice: 0.0667  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0439  decode.d5.loss_dice: 0.0714  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0421  decode.d6.loss_dice: 0.0699  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0426  decode.d7.loss_dice: 0.0715  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0439  decode.d8.loss_dice: 0.0731
2023/12/31 20:12:53 - mmengine - INFO - Iter(train) [17800/90000]  base_lr: 8.2011e-05 lr: 8.2011e-06  eta: 20:12:33  time: 1.0065  data_time: 0.0126  memory: 18544  grad_norm: 5.9808  loss: 1.0679  decode.loss_cls: 0.0007  decode.loss_mask: 0.0392  decode.loss_dice: 0.0701  decode.d0.loss_cls: 0.0193  decode.d0.loss_mask: 0.0398  decode.d0.loss_dice: 0.0678  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0640  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0387  decode.d2.loss_dice: 0.0668  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0388  decode.d3.loss_dice: 0.0666  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0383  decode.d4.loss_dice: 0.0645  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0401  decode.d5.loss_dice: 0.0667  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.0384  decode.d6.loss_dice: 0.0637  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.0369  decode.d7.loss_dice: 0.0625  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0387  decode.d8.loss_dice: 0.0669
2023/12/31 20:13:44 - mmengine - INFO - Iter(train) [17850/90000]  base_lr: 8.1959e-05 lr: 8.1959e-06  eta: 20:11:43  time: 1.0059  data_time: 0.0120  memory: 18544  grad_norm: 10.0399  loss: 1.1128  decode.loss_cls: 0.0000  decode.loss_mask: 0.0436  decode.loss_dice: 0.0703  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.0432  decode.d0.loss_dice: 0.0660  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0435  decode.d1.loss_dice: 0.0725  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0434  decode.d2.loss_dice: 0.0635  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0438  decode.d3.loss_dice: 0.0667  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0432  decode.d4.loss_dice: 0.0680  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0427  decode.d5.loss_dice: 0.0609  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0421  decode.d6.loss_dice: 0.0621  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0414  decode.d7.loss_dice: 0.0630  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0430  decode.d8.loss_dice: 0.0632
2023/12/31 20:14:34 - mmengine - INFO - Iter(train) [17900/90000]  base_lr: 8.1908e-05 lr: 8.1908e-06  eta: 20:10:52  time: 1.0055  data_time: 0.0116  memory: 18544  grad_norm: 5.7556  loss: 1.0588  decode.loss_cls: 0.0000  decode.loss_mask: 0.0417  decode.loss_dice: 0.0590  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.0415  decode.d0.loss_dice: 0.0664  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0409  decode.d1.loss_dice: 0.0623  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0410  decode.d2.loss_dice: 0.0608  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0407  decode.d3.loss_dice: 0.0625  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0399  decode.d4.loss_dice: 0.0580  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0417  decode.d5.loss_dice: 0.0653  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0404  decode.d6.loss_dice: 0.0602  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0410  decode.d7.loss_dice: 0.0655  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0419  decode.d8.loss_dice: 0.0648
2023/12/31 20:15:24 - mmengine - INFO - Iter(train) [17950/90000]  base_lr: 8.1857e-05 lr: 8.1857e-06  eta: 20:10:01  time: 1.0057  data_time: 0.0128  memory: 18544  grad_norm: 7.9167  loss: 1.0610  decode.loss_cls: 0.0001  decode.loss_mask: 0.0430  decode.loss_dice: 0.0616  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0415  decode.d0.loss_dice: 0.0613  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0428  decode.d1.loss_dice: 0.0585  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0438  decode.d2.loss_dice: 0.0615  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0436  decode.d3.loss_dice: 0.0596  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0424  decode.d4.loss_dice: 0.0589  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0433  decode.d5.loss_dice: 0.0607  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0444  decode.d6.loss_dice: 0.0597  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0432  decode.d7.loss_dice: 0.0573  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.0424  decode.d8.loss_dice: 0.0627
2023/12/31 20:16:14 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 20:16:14 - mmengine - INFO - Iter(train) [18000/90000]  base_lr: 8.1806e-05 lr: 8.1806e-06  eta: 20:09:10  time: 1.0042  data_time: 0.0117  memory: 18544  grad_norm: 7.9868  loss: 1.1564  decode.loss_cls: 0.0000  decode.loss_mask: 0.0409  decode.loss_dice: 0.0741  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0404  decode.d0.loss_dice: 0.0717  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0424  decode.d1.loss_dice: 0.0738  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0411  decode.d2.loss_dice: 0.0741  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0399  decode.d3.loss_dice: 0.0726  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0410  decode.d4.loss_dice: 0.0706  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0410  decode.d5.loss_dice: 0.0722  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0396  decode.d6.loss_dice: 0.0683  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0404  decode.d7.loss_dice: 0.0711  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.0420  decode.d8.loss_dice: 0.0714
2023/12/31 20:17:05 - mmengine - INFO - Iter(train) [18050/90000]  base_lr: 8.1755e-05 lr: 8.1755e-06  eta: 20:08:20  time: 1.0066  data_time: 0.0122  memory: 18544  grad_norm: 6.1427  loss: 1.0357  decode.loss_cls: 0.0000  decode.loss_mask: 0.0397  decode.loss_dice: 0.0644  decode.d0.loss_cls: 0.0167  decode.d0.loss_mask: 0.0402  decode.d0.loss_dice: 0.0618  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0600  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0387  decode.d2.loss_dice: 0.0596  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0405  decode.d3.loss_dice: 0.0638  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0396  decode.d4.loss_dice: 0.0619  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0388  decode.d5.loss_dice: 0.0628  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0402  decode.d6.loss_dice: 0.0631  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0394  decode.d7.loss_dice: 0.0633  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0400  decode.d8.loss_dice: 0.0621
2023/12/31 20:17:55 - mmengine - INFO - Iter(train) [18100/90000]  base_lr: 8.1704e-05 lr: 8.1704e-06  eta: 20:07:29  time: 1.0065  data_time: 0.0127  memory: 18544  grad_norm: 6.3896  loss: 1.0597  decode.loss_cls: 0.0000  decode.loss_mask: 0.0419  decode.loss_dice: 0.0629  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0400  decode.d0.loss_dice: 0.0590  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0419  decode.d1.loss_dice: 0.0612  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0406  decode.d2.loss_dice: 0.0598  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0419  decode.d3.loss_dice: 0.0639  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0408  decode.d4.loss_dice: 0.0620  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0414  decode.d5.loss_dice: 0.0620  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0426  decode.d6.loss_dice: 0.0648  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0409  decode.d7.loss_dice: 0.0619  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0414  decode.d8.loss_dice: 0.0621
2023/12/31 20:18:45 - mmengine - INFO - Iter(train) [18150/90000]  base_lr: 8.1653e-05 lr: 8.1653e-06  eta: 20:06:38  time: 1.0049  data_time: 0.0118  memory: 18544  grad_norm: 8.2150  loss: 1.1251  decode.loss_cls: 0.0000  decode.loss_mask: 0.0426  decode.loss_dice: 0.0598  decode.d0.loss_cls: 0.0319  decode.d0.loss_mask: 0.0420  decode.d0.loss_dice: 0.0660  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0436  decode.d1.loss_dice: 0.0703  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0415  decode.d2.loss_dice: 0.0643  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0424  decode.d3.loss_dice: 0.0672  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0415  decode.d4.loss_dice: 0.0604  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0412  decode.d5.loss_dice: 0.0686  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0429  decode.d6.loss_dice: 0.0717  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0434  decode.d7.loss_dice: 0.0771  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0426  decode.d8.loss_dice: 0.0640
2023/12/31 20:19:36 - mmengine - INFO - Iter(train) [18200/90000]  base_lr: 8.1601e-05 lr: 8.1601e-06  eta: 20:05:48  time: 1.0046  data_time: 0.0120  memory: 18544  grad_norm: 7.5327  loss: 1.1294  decode.loss_cls: 0.0001  decode.loss_mask: 0.0422  decode.loss_dice: 0.0646  decode.d0.loss_cls: 0.0329  decode.d0.loss_mask: 0.0417  decode.d0.loss_dice: 0.0636  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0403  decode.d1.loss_dice: 0.0592  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0411  decode.d2.loss_dice: 0.0731  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0427  decode.d3.loss_dice: 0.0626  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0411  decode.d4.loss_dice: 0.0617  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0414  decode.d5.loss_dice: 0.0724  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0404  decode.d6.loss_dice: 0.0734  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0414  decode.d7.loss_dice: 0.0689  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0409  decode.d8.loss_dice: 0.0839
2023/12/31 20:20:26 - mmengine - INFO - Iter(train) [18250/90000]  base_lr: 8.1550e-05 lr: 8.1550e-06  eta: 20:04:57  time: 1.0082  data_time: 0.0128  memory: 18544  grad_norm: 5.4232  loss: 1.0058  decode.loss_cls: 0.0001  decode.loss_mask: 0.0407  decode.loss_dice: 0.0579  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0407  decode.d0.loss_dice: 0.0571  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0410  decode.d1.loss_dice: 0.0573  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0425  decode.d2.loss_dice: 0.0596  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0408  decode.d3.loss_dice: 0.0560  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0414  decode.d4.loss_dice: 0.0584  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0411  decode.d5.loss_dice: 0.0562  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0409  decode.d6.loss_dice: 0.0560  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0406  decode.d7.loss_dice: 0.0568  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0411  decode.d8.loss_dice: 0.0564
2023/12/31 20:21:16 - mmengine - INFO - Iter(train) [18300/90000]  base_lr: 8.1499e-05 lr: 8.1499e-06  eta: 20:04:07  time: 1.0054  data_time: 0.0120  memory: 18544  grad_norm: 7.6773  loss: 1.1119  decode.loss_cls: 0.0001  decode.loss_mask: 0.0444  decode.loss_dice: 0.0680  decode.d0.loss_cls: 0.0348  decode.d0.loss_mask: 0.0437  decode.d0.loss_dice: 0.0666  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0429  decode.d1.loss_dice: 0.0614  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0423  decode.d2.loss_dice: 0.0597  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0435  decode.d3.loss_dice: 0.0629  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0454  decode.d4.loss_dice: 0.0672  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0441  decode.d5.loss_dice: 0.0668  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0448  decode.d6.loss_dice: 0.0638  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0438  decode.d7.loss_dice: 0.0604  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0435  decode.d8.loss_dice: 0.0617
2023/12/31 20:22:07 - mmengine - INFO - Iter(train) [18350/90000]  base_lr: 8.1448e-05 lr: 8.1448e-06  eta: 20:03:16  time: 1.0065  data_time: 0.0121  memory: 18544  grad_norm: 6.4607  loss: 1.0586  decode.loss_cls: 0.0000  decode.loss_mask: 0.0397  decode.loss_dice: 0.0626  decode.d0.loss_cls: 0.0252  decode.d0.loss_mask: 0.0392  decode.d0.loss_dice: 0.0595  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0412  decode.d1.loss_dice: 0.0649  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0403  decode.d2.loss_dice: 0.0646  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0414  decode.d3.loss_dice: 0.0635  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0389  decode.d4.loss_dice: 0.0610  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0406  decode.d5.loss_dice: 0.0634  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0397  decode.d6.loss_dice: 0.0652  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0388  decode.d7.loss_dice: 0.0604  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0413  decode.d8.loss_dice: 0.0671
2023/12/31 20:22:57 - mmengine - INFO - Iter(train) [18400/90000]  base_lr: 8.1397e-05 lr: 8.1397e-06  eta: 20:02:26  time: 1.0076  data_time: 0.0124  memory: 18544  grad_norm: 6.9349  loss: 1.1175  decode.loss_cls: 0.0000  decode.loss_mask: 0.0385  decode.loss_dice: 0.0695  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.0372  decode.d0.loss_dice: 0.0677  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0380  decode.d1.loss_dice: 0.0659  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0394  decode.d2.loss_dice: 0.0745  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0404  decode.d3.loss_dice: 0.0716  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0396  decode.d4.loss_dice: 0.0749  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0405  decode.d5.loss_dice: 0.0760  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0384  decode.d6.loss_dice: 0.0683  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0393  decode.d7.loss_dice: 0.0680  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0390  decode.d8.loss_dice: 0.0694
2023/12/31 20:23:48 - mmengine - INFO - Iter(train) [18450/90000]  base_lr: 8.1346e-05 lr: 8.1346e-06  eta: 20:01:35  time: 1.0074  data_time: 0.0121  memory: 18544  grad_norm: 6.7416  loss: 1.0375  decode.loss_cls: 0.0000  decode.loss_mask: 0.0389  decode.loss_dice: 0.0626  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.0379  decode.d0.loss_dice: 0.0596  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0395  decode.d1.loss_dice: 0.0614  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0401  decode.d2.loss_dice: 0.0654  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0393  decode.d3.loss_dice: 0.0629  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0395  decode.d4.loss_dice: 0.0630  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0383  decode.d5.loss_dice: 0.0586  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0406  decode.d6.loss_dice: 0.0656  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0398  decode.d7.loss_dice: 0.0602  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0393  decode.d8.loss_dice: 0.0584
2023/12/31 20:24:38 - mmengine - INFO - Iter(train) [18500/90000]  base_lr: 8.1295e-05 lr: 8.1295e-06  eta: 20:00:45  time: 1.0061  data_time: 0.0122  memory: 18544  grad_norm: 6.8815  loss: 1.0294  decode.loss_cls: 0.0000  decode.loss_mask: 0.0403  decode.loss_dice: 0.0614  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0412  decode.d0.loss_dice: 0.0603  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0395  decode.d1.loss_dice: 0.0584  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0411  decode.d2.loss_dice: 0.0614  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0419  decode.d3.loss_dice: 0.0627  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0411  decode.d4.loss_dice: 0.0620  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0409  decode.d5.loss_dice: 0.0601  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0394  decode.d6.loss_dice: 0.0564  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0401  decode.d7.loss_dice: 0.0571  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0404  decode.d8.loss_dice: 0.0573
2023/12/31 20:25:28 - mmengine - INFO - Iter(train) [18550/90000]  base_lr: 8.1243e-05 lr: 8.1243e-06  eta: 19:59:54  time: 1.0058  data_time: 0.0123  memory: 18544  grad_norm: 7.9037  loss: 1.1463  decode.loss_cls: 0.0000  decode.loss_mask: 0.0390  decode.loss_dice: 0.0678  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0403  decode.d0.loss_dice: 0.0737  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0397  decode.d1.loss_dice: 0.0655  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0401  decode.d2.loss_dice: 0.0717  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0397  decode.d3.loss_dice: 0.0719  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0405  decode.d4.loss_dice: 0.0765  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0403  decode.d5.loss_dice: 0.0786  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0397  decode.d6.loss_dice: 0.0700  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0394  decode.d7.loss_dice: 0.0754  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0387  decode.d8.loss_dice: 0.0712
2023/12/31 20:26:19 - mmengine - INFO - Iter(train) [18600/90000]  base_lr: 8.1192e-05 lr: 8.1192e-06  eta: 19:59:04  time: 1.0064  data_time: 0.0125  memory: 18544  grad_norm: 6.2961  loss: 1.0005  decode.loss_cls: 0.0000  decode.loss_mask: 0.0391  decode.loss_dice: 0.0563  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.0409  decode.d0.loss_dice: 0.0600  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0401  decode.d1.loss_dice: 0.0608  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0402  decode.d2.loss_dice: 0.0595  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0391  decode.d3.loss_dice: 0.0549  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0385  decode.d4.loss_dice: 0.0544  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0395  decode.d5.loss_dice: 0.0597  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0402  decode.d6.loss_dice: 0.0579  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0394  decode.d7.loss_dice: 0.0566  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0400  decode.d8.loss_dice: 0.0583
2023/12/31 20:27:09 - mmengine - INFO - Iter(train) [18650/90000]  base_lr: 8.1141e-05 lr: 8.1141e-06  eta: 19:58:13  time: 1.0066  data_time: 0.0126  memory: 18544  grad_norm: 7.2043  loss: 1.1163  decode.loss_cls: 0.0000  decode.loss_mask: 0.0390  decode.loss_dice: 0.0764  decode.d0.loss_cls: 0.0205  decode.d0.loss_mask: 0.0373  decode.d0.loss_dice: 0.0705  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0380  decode.d1.loss_dice: 0.0736  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0386  decode.d2.loss_dice: 0.0708  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0368  decode.d3.loss_dice: 0.0691  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0377  decode.d4.loss_dice: 0.0698  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0384  decode.d5.loss_dice: 0.0768  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0367  decode.d6.loss_dice: 0.0682  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0381  decode.d7.loss_dice: 0.0714  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0707
2023/12/31 20:27:59 - mmengine - INFO - Iter(train) [18700/90000]  base_lr: 8.1090e-05 lr: 8.1090e-06  eta: 19:57:23  time: 1.0069  data_time: 0.0126  memory: 18544  grad_norm: 28.1454  loss: 1.3494  decode.loss_cls: 0.0000  decode.loss_mask: 0.0651  decode.loss_dice: 0.0685  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0646  decode.d0.loss_dice: 0.0697  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0649  decode.d1.loss_dice: 0.0697  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0623  decode.d2.loss_dice: 0.0684  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0623  decode.d3.loss_dice: 0.0658  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0632  decode.d4.loss_dice: 0.0661  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0614  decode.d5.loss_dice: 0.0702  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0639  decode.d6.loss_dice: 0.0709  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0638  decode.d7.loss_dice: 0.0711  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0624  decode.d8.loss_dice: 0.0671
2023/12/31 20:28:50 - mmengine - INFO - Iter(train) [18750/90000]  base_lr: 8.1039e-05 lr: 8.1039e-06  eta: 19:56:33  time: 1.0071  data_time: 0.0125  memory: 18544  grad_norm: 6.6859  loss: 1.0594  decode.loss_cls: 0.0000  decode.loss_mask: 0.0384  decode.loss_dice: 0.0667  decode.d0.loss_cls: 0.0186  decode.d0.loss_mask: 0.0401  decode.d0.loss_dice: 0.0662  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0385  decode.d1.loss_dice: 0.0665  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0393  decode.d2.loss_dice: 0.0662  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0385  decode.d3.loss_dice: 0.0639  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0371  decode.d4.loss_dice: 0.0607  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0385  decode.d5.loss_dice: 0.0661  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0387  decode.d6.loss_dice: 0.0692  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0381  decode.d7.loss_dice: 0.0649  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0388  decode.d8.loss_dice: 0.0642
2023/12/31 20:29:40 - mmengine - INFO - Iter(train) [18800/90000]  base_lr: 8.0988e-05 lr: 8.0988e-06  eta: 19:55:42  time: 1.0058  data_time: 0.0120  memory: 18544  grad_norm: 5.4360  loss: 1.0218  decode.loss_cls: 0.0000  decode.loss_mask: 0.0427  decode.loss_dice: 0.0594  decode.d0.loss_cls: 0.0276  decode.d0.loss_mask: 0.0428  decode.d0.loss_dice: 0.0580  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0412  decode.d1.loss_dice: 0.0573  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0415  decode.d2.loss_dice: 0.0580  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0397  decode.d3.loss_dice: 0.0580  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0413  decode.d4.loss_dice: 0.0587  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0410  decode.d5.loss_dice: 0.0596  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0414  decode.d6.loss_dice: 0.0573  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0405  decode.d7.loss_dice: 0.0563  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0411  decode.d8.loss_dice: 0.0584
2023/12/31 20:30:30 - mmengine - INFO - Iter(train) [18850/90000]  base_lr: 8.0936e-05 lr: 8.0936e-06  eta: 19:54:51  time: 1.0079  data_time: 0.0129  memory: 18544  grad_norm: 9.5472  loss: 1.1317  decode.loss_cls: 0.0000  decode.loss_mask: 0.0444  decode.loss_dice: 0.0672  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0454  decode.d0.loss_dice: 0.0682  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0442  decode.d1.loss_dice: 0.0651  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0432  decode.d2.loss_dice: 0.0620  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0450  decode.d3.loss_dice: 0.0644  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0461  decode.d4.loss_dice: 0.0694  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0434  decode.d5.loss_dice: 0.0647  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0453  decode.d6.loss_dice: 0.0656  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0432  decode.d7.loss_dice: 0.0630  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0454  decode.d8.loss_dice: 0.0701
2023/12/31 20:31:21 - mmengine - INFO - Iter(train) [18900/90000]  base_lr: 8.0885e-05 lr: 8.0885e-06  eta: 19:54:01  time: 1.0072  data_time: 0.0129  memory: 18544  grad_norm: 14.1883  loss: 1.8614  decode.loss_cls: 0.8350  decode.loss_mask: 0.0381  decode.loss_dice: 0.0673  decode.d0.loss_cls: 0.0371  decode.d0.loss_mask: 0.0377  decode.d0.loss_dice: 0.0641  decode.d1.loss_cls: 0.0001  decode.d1.loss_mask: 0.0381  decode.d1.loss_dice: 0.0593  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0383  decode.d2.loss_dice: 0.0585  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0375  decode.d3.loss_dice: 0.0613  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0372  decode.d4.loss_dice: 0.0561  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0387  decode.d5.loss_dice: 0.0626  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0376  decode.d6.loss_dice: 0.0618  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0378  decode.d7.loss_dice: 0.0578  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0385  decode.d8.loss_dice: 0.0608
2023/12/31 20:32:11 - mmengine - INFO - Iter(train) [18950/90000]  base_lr: 8.0834e-05 lr: 8.0834e-06  eta: 19:53:11  time: 1.0086  data_time: 0.0135  memory: 18544  grad_norm: 7.2643  loss: 1.0515  decode.loss_cls: 0.0000  decode.loss_mask: 0.0364  decode.loss_dice: 0.0703  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.0360  decode.d0.loss_dice: 0.0657  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0369  decode.d1.loss_dice: 0.0802  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0364  decode.d2.loss_dice: 0.0729  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0351  decode.d3.loss_dice: 0.0662  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0344  decode.d4.loss_dice: 0.0614  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0354  decode.d5.loss_dice: 0.0622  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0356  decode.d6.loss_dice: 0.0614  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0352  decode.d7.loss_dice: 0.0640  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0362  decode.d8.loss_dice: 0.0664
2023/12/31 20:33:02 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 20:33:02 - mmengine - INFO - Iter(train) [19000/90000]  base_lr: 8.0783e-05 lr: 8.0783e-06  eta: 19:52:20  time: 1.0073  data_time: 0.0130  memory: 18544  grad_norm: 7.8391  loss: 1.0624  decode.loss_cls: 0.0000  decode.loss_mask: 0.0446  decode.loss_dice: 0.0600  decode.d0.loss_cls: 0.0295  decode.d0.loss_mask: 0.0454  decode.d0.loss_dice: 0.0578  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0442  decode.d1.loss_dice: 0.0592  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0435  decode.d2.loss_dice: 0.0605  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0436  decode.d3.loss_dice: 0.0598  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0441  decode.d4.loss_dice: 0.0560  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0438  decode.d5.loss_dice: 0.0606  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0446  decode.d6.loss_dice: 0.0607  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0449  decode.d7.loss_dice: 0.0592  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0447  decode.d8.loss_dice: 0.0558
2023/12/31 20:33:52 - mmengine - INFO - Iter(train) [19050/90000]  base_lr: 8.0732e-05 lr: 8.0732e-06  eta: 19:51:30  time: 1.0063  data_time: 0.0128  memory: 18544  grad_norm: 9.1836  loss: 1.0594  decode.loss_cls: 0.0000  decode.loss_mask: 0.0422  decode.loss_dice: 0.0560  decode.d0.loss_cls: 0.0304  decode.d0.loss_mask: 0.0430  decode.d0.loss_dice: 0.0574  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0447  decode.d1.loss_dice: 0.0612  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0430  decode.d2.loss_dice: 0.0562  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0436  decode.d3.loss_dice: 0.0587  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0443  decode.d4.loss_dice: 0.0607  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0432  decode.d5.loss_dice: 0.0640  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0436  decode.d6.loss_dice: 0.0579  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0441  decode.d7.loss_dice: 0.0588  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0456  decode.d8.loss_dice: 0.0610
2023/12/31 20:34:42 - mmengine - INFO - Iter(train) [19100/90000]  base_lr: 8.0680e-05 lr: 8.0680e-06  eta: 19:50:40  time: 1.0081  data_time: 0.0130  memory: 18544  grad_norm: 7.3494  loss: 1.0632  decode.loss_cls: 0.0000  decode.loss_mask: 0.0395  decode.loss_dice: 0.0621  decode.d0.loss_cls: 0.0243  decode.d0.loss_mask: 0.0401  decode.d0.loss_dice: 0.0653  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0394  decode.d1.loss_dice: 0.0650  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0391  decode.d2.loss_dice: 0.0651  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0395  decode.d3.loss_dice: 0.0672  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0395  decode.d4.loss_dice: 0.0654  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0394  decode.d5.loss_dice: 0.0651  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0400  decode.d6.loss_dice: 0.0641  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0398  decode.d7.loss_dice: 0.0653  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0383  decode.d8.loss_dice: 0.0596
2023/12/31 20:35:33 - mmengine - INFO - Iter(train) [19150/90000]  base_lr: 8.0629e-05 lr: 8.0629e-06  eta: 19:49:49  time: 1.0099  data_time: 0.0137  memory: 18544  grad_norm: 6.3123  loss: 1.1092  decode.loss_cls: 0.0000  decode.loss_mask: 0.0411  decode.loss_dice: 0.0654  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.0415  decode.d0.loss_dice: 0.0686  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0403  decode.d1.loss_dice: 0.0681  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0400  decode.d2.loss_dice: 0.0630  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0413  decode.d3.loss_dice: 0.0659  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0421  decode.d4.loss_dice: 0.0676  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0417  decode.d5.loss_dice: 0.0693  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0409  decode.d6.loss_dice: 0.0730  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0408  decode.d7.loss_dice: 0.0656  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0416  decode.d8.loss_dice: 0.0682
2023/12/31 20:36:23 - mmengine - INFO - Iter(train) [19200/90000]  base_lr: 8.0578e-05 lr: 8.0578e-06  eta: 19:48:59  time: 1.0089  data_time: 0.0131  memory: 18544  grad_norm: 7.6649  loss: 1.0644  decode.loss_cls: 0.0000  decode.loss_mask: 0.0393  decode.loss_dice: 0.0678  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.0390  decode.d0.loss_dice: 0.0637  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0387  decode.d1.loss_dice: 0.0676  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0396  decode.d2.loss_dice: 0.0641  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0397  decode.d3.loss_dice: 0.0606  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0385  decode.d4.loss_dice: 0.0635  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0387  decode.d5.loss_dice: 0.0647  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0396  decode.d6.loss_dice: 0.0677  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0392  decode.d7.loss_dice: 0.0647  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0393  decode.d8.loss_dice: 0.0669
2023/12/31 20:37:14 - mmengine - INFO - Iter(train) [19250/90000]  base_lr: 8.0527e-05 lr: 8.0527e-06  eta: 19:48:09  time: 1.0080  data_time: 0.0132  memory: 18544  grad_norm: 12.5447  loss: 1.1110  decode.loss_cls: 0.0000  decode.loss_mask: 0.0400  decode.loss_dice: 0.0756  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.0371  decode.d0.loss_dice: 0.0679  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0380  decode.d1.loss_dice: 0.0690  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0383  decode.d2.loss_dice: 0.0727  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0371  decode.d3.loss_dice: 0.0688  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0396  decode.d4.loss_dice: 0.0711  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0386  decode.d5.loss_dice: 0.0696  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0381  decode.d6.loss_dice: 0.0708  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0386  decode.d7.loss_dice: 0.0679  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0387  decode.d8.loss_dice: 0.0723
2023/12/31 20:38:04 - mmengine - INFO - Iter(train) [19300/90000]  base_lr: 8.0475e-05 lr: 8.0475e-06  eta: 19:47:19  time: 1.0113  data_time: 0.0137  memory: 18544  grad_norm: 7.8214  loss: 1.0998  decode.loss_cls: 0.0000  decode.loss_mask: 0.0417  decode.loss_dice: 0.0606  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0423  decode.d0.loss_dice: 0.0617  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0426  decode.d1.loss_dice: 0.0682  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0436  decode.d2.loss_dice: 0.0669  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0427  decode.d3.loss_dice: 0.0673  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0427  decode.d4.loss_dice: 0.0654  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0421  decode.d5.loss_dice: 0.0618  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0431  decode.d6.loss_dice: 0.0684  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0417  decode.d7.loss_dice: 0.0616  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0435  decode.d8.loss_dice: 0.0655
2023/12/31 20:38:54 - mmengine - INFO - Iter(train) [19350/90000]  base_lr: 8.0424e-05 lr: 8.0424e-06  eta: 19:46:29  time: 1.0087  data_time: 0.0127  memory: 18544  grad_norm: 8.0360  loss: 1.1625  decode.loss_cls: 0.0000  decode.loss_mask: 0.0386  decode.loss_dice: 0.0776  decode.d0.loss_cls: 0.0167  decode.d0.loss_mask: 0.0396  decode.d0.loss_dice: 0.0728  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0385  decode.d1.loss_dice: 0.0786  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0393  decode.d2.loss_dice: 0.0768  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0404  decode.d3.loss_dice: 0.0796  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0386  decode.d4.loss_dice: 0.0741  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0394  decode.d5.loss_dice: 0.0727  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0386  decode.d6.loss_dice: 0.0745  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0390  decode.d7.loss_dice: 0.0742  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0388  decode.d8.loss_dice: 0.0742
2023/12/31 20:39:45 - mmengine - INFO - Iter(train) [19400/90000]  base_lr: 8.0373e-05 lr: 8.0373e-06  eta: 19:45:39  time: 1.0090  data_time: 0.0127  memory: 18544  grad_norm: 5.1152  loss: 1.0058  decode.loss_cls: 0.0000  decode.loss_mask: 0.0393  decode.loss_dice: 0.0586  decode.d0.loss_cls: 0.0217  decode.d0.loss_mask: 0.0401  decode.d0.loss_dice: 0.0601  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0386  decode.d1.loss_dice: 0.0581  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0393  decode.d2.loss_dice: 0.0604  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0387  decode.d3.loss_dice: 0.0599  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0388  decode.d4.loss_dice: 0.0604  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0385  decode.d5.loss_dice: 0.0574  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0392  decode.d6.loss_dice: 0.0590  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0397  decode.d7.loss_dice: 0.0600  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0395  decode.d8.loss_dice: 0.0582
2023/12/31 20:40:35 - mmengine - INFO - Iter(train) [19450/90000]  base_lr: 8.0322e-05 lr: 8.0322e-06  eta: 19:44:48  time: 1.0095  data_time: 0.0136  memory: 18544  grad_norm: 5.7649  loss: 0.9889  decode.loss_cls: 0.0000  decode.loss_mask: 0.0382  decode.loss_dice: 0.0594  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.0379  decode.d0.loss_dice: 0.0569  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0390  decode.d1.loss_dice: 0.0569  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0376  decode.d2.loss_dice: 0.0559  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0386  decode.d3.loss_dice: 0.0612  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.0382  decode.d4.loss_dice: 0.0595  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0380  decode.d5.loss_dice: 0.0562  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0382  decode.d6.loss_dice: 0.0576  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0386  decode.d7.loss_dice: 0.0620  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0387  decode.d8.loss_dice: 0.0572
2023/12/31 20:41:26 - mmengine - INFO - Iter(train) [19500/90000]  base_lr: 8.0271e-05 lr: 8.0271e-06  eta: 19:43:58  time: 1.0081  data_time: 0.0126  memory: 18544  grad_norm: 6.2949  loss: 1.0299  decode.loss_cls: 0.0000  decode.loss_mask: 0.0419  decode.loss_dice: 0.0580  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0412  decode.d0.loss_dice: 0.0608  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0412  decode.d1.loss_dice: 0.0614  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0422  decode.d2.loss_dice: 0.0604  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0409  decode.d3.loss_dice: 0.0587  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0412  decode.d4.loss_dice: 0.0577  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0415  decode.d5.loss_dice: 0.0586  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0412  decode.d6.loss_dice: 0.0577  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0405  decode.d7.loss_dice: 0.0559  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0419  decode.d8.loss_dice: 0.0603
2023/12/31 20:42:16 - mmengine - INFO - Iter(train) [19550/90000]  base_lr: 8.0219e-05 lr: 8.0219e-06  eta: 19:43:08  time: 1.0084  data_time: 0.0128  memory: 18544  grad_norm: 6.5973  loss: 1.0692  decode.loss_cls: 0.0000  decode.loss_mask: 0.0393  decode.loss_dice: 0.0598  decode.d0.loss_cls: 0.0211  decode.d0.loss_mask: 0.0404  decode.d0.loss_dice: 0.0628  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0381  decode.d1.loss_dice: 0.0632  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0398  decode.d2.loss_dice: 0.0667  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0399  decode.d3.loss_dice: 0.0668  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0420  decode.d4.loss_dice: 0.0708  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0396  decode.d5.loss_dice: 0.0629  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0401  decode.d6.loss_dice: 0.0675  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0401  decode.d7.loss_dice: 0.0629  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0394  decode.d8.loss_dice: 0.0659
2023/12/31 20:43:07 - mmengine - INFO - Iter(train) [19600/90000]  base_lr: 8.0168e-05 lr: 8.0168e-06  eta: 19:42:17  time: 1.0085  data_time: 0.0129  memory: 18544  grad_norm: 5.9846  loss: 1.0435  decode.loss_cls: 0.0000  decode.loss_mask: 0.0394  decode.loss_dice: 0.0611  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.0390  decode.d0.loss_dice: 0.0623  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0394  decode.d1.loss_dice: 0.0629  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0387  decode.d2.loss_dice: 0.0629  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0382  decode.d3.loss_dice: 0.0622  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0390  decode.d4.loss_dice: 0.0627  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0403  decode.d5.loss_dice: 0.0667  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0387  decode.d6.loss_dice: 0.0653  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0379  decode.d7.loss_dice: 0.0629  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0389  decode.d8.loss_dice: 0.0637
2023/12/31 20:43:57 - mmengine - INFO - Iter(train) [19650/90000]  base_lr: 8.0117e-05 lr: 8.0117e-06  eta: 19:41:27  time: 1.0066  data_time: 0.0125  memory: 18544  grad_norm: 5.7821  loss: 1.0646  decode.loss_cls: 0.0000  decode.loss_mask: 0.0396  decode.loss_dice: 0.0629  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0386  decode.d0.loss_dice: 0.0647  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0612  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0391  decode.d2.loss_dice: 0.0673  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0394  decode.d3.loss_dice: 0.0679  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0395  decode.d4.loss_dice: 0.0646  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0390  decode.d5.loss_dice: 0.0644  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0397  decode.d6.loss_dice: 0.0643  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0393  decode.d7.loss_dice: 0.0645  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0391  decode.d8.loss_dice: 0.0635
2023/12/31 20:44:47 - mmengine - INFO - Iter(train) [19700/90000]  base_lr: 8.0066e-05 lr: 8.0066e-06  eta: 19:40:37  time: 1.0058  data_time: 0.0123  memory: 18544  grad_norm: 7.6539  loss: 1.0583  decode.loss_cls: 0.0000  decode.loss_mask: 0.0379  decode.loss_dice: 0.0589  decode.d0.loss_cls: 0.0334  decode.d0.loss_mask: 0.0372  decode.d0.loss_dice: 0.0598  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0379  decode.d1.loss_dice: 0.1066  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0369  decode.d2.loss_dice: 0.0568  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0377  decode.d3.loss_dice: 0.0605  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0370  decode.d4.loss_dice: 0.0563  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0382  decode.d5.loss_dice: 0.0587  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0376  decode.d6.loss_dice: 0.0713  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0380  decode.d7.loss_dice: 0.0584  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0613
2023/12/31 20:45:38 - mmengine - INFO - Iter(train) [19750/90000]  base_lr: 8.0014e-05 lr: 8.0014e-06  eta: 19:39:46  time: 1.0074  data_time: 0.0133  memory: 18544  grad_norm: 8.2837  loss: 1.0347  decode.loss_cls: 0.0000  decode.loss_mask: 0.0385  decode.loss_dice: 0.0645  decode.d0.loss_cls: 0.0311  decode.d0.loss_mask: 0.0373  decode.d0.loss_dice: 0.0619  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0369  decode.d1.loss_dice: 0.0613  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0390  decode.d2.loss_dice: 0.0621  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0372  decode.d3.loss_dice: 0.0628  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0387  decode.d4.loss_dice: 0.0640  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0384  decode.d5.loss_dice: 0.0635  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0366  decode.d6.loss_dice: 0.0593  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0374  decode.d7.loss_dice: 0.0631  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0384  decode.d8.loss_dice: 0.0628
2023/12/31 20:46:28 - mmengine - INFO - Iter(train) [19800/90000]  base_lr: 7.9963e-05 lr: 7.9963e-06  eta: 19:38:56  time: 1.0065  data_time: 0.0122  memory: 18544  grad_norm: 5.7294  loss: 1.0769  decode.loss_cls: 0.0000  decode.loss_mask: 0.0384  decode.loss_dice: 0.0631  decode.d0.loss_cls: 0.0218  decode.d0.loss_mask: 0.0381  decode.d0.loss_dice: 0.0666  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0683  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0393  decode.d2.loss_dice: 0.0697  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0392  decode.d3.loss_dice: 0.0702  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0387  decode.d4.loss_dice: 0.0681  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0385  decode.d5.loss_dice: 0.0689  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0381  decode.d6.loss_dice: 0.0613  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0377  decode.d7.loss_dice: 0.0644  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0693
2023/12/31 20:47:18 - mmengine - INFO - Iter(train) [19850/90000]  base_lr: 7.9912e-05 lr: 7.9912e-06  eta: 19:38:05  time: 1.0066  data_time: 0.0124  memory: 18544  grad_norm: 6.9370  loss: 1.0270  decode.loss_cls: 0.0000  decode.loss_mask: 0.0384  decode.loss_dice: 0.0602  decode.d0.loss_cls: 0.0310  decode.d0.loss_mask: 0.0379  decode.d0.loss_dice: 0.0614  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0384  decode.d1.loss_dice: 0.0590  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0397  decode.d2.loss_dice: 0.0635  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0389  decode.d3.loss_dice: 0.0587  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0404  decode.d4.loss_dice: 0.0608  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0389  decode.d5.loss_dice: 0.0638  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0397  decode.d6.loss_dice: 0.0601  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0391  decode.d7.loss_dice: 0.0577  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0389  decode.d8.loss_dice: 0.0602
2023/12/31 20:48:09 - mmengine - INFO - Iter(train) [19900/90000]  base_lr: 7.9861e-05 lr: 7.9861e-06  eta: 19:37:15  time: 1.0070  data_time: 0.0125  memory: 18544  grad_norm: 5.7646  loss: 1.0203  decode.loss_cls: 0.0000  decode.loss_mask: 0.0374  decode.loss_dice: 0.0639  decode.d0.loss_cls: 0.0212  decode.d0.loss_mask: 0.0375  decode.d0.loss_dice: 0.0632  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0371  decode.d1.loss_dice: 0.0626  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0367  decode.d2.loss_dice: 0.0628  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0380  decode.d3.loss_dice: 0.0624  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0381  decode.d4.loss_dice: 0.0636  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0365  decode.d5.loss_dice: 0.0593  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0385  decode.d6.loss_dice: 0.0650  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0372  decode.d7.loss_dice: 0.0602  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0612
2023/12/31 20:48:59 - mmengine - INFO - Iter(train) [19950/90000]  base_lr: 7.9809e-05 lr: 7.9809e-06  eta: 19:36:25  time: 1.0078  data_time: 0.0123  memory: 18544  grad_norm: 5.5852  loss: 0.9883  decode.loss_cls: 0.0000  decode.loss_mask: 0.0386  decode.loss_dice: 0.0568  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.0393  decode.d0.loss_dice: 0.0565  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0591  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0383  decode.d2.loss_dice: 0.0598  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0386  decode.d3.loss_dice: 0.0576  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0385  decode.d4.loss_dice: 0.0572  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0390  decode.d5.loss_dice: 0.0583  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0382  decode.d6.loss_dice: 0.0561  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0386  decode.d7.loss_dice: 0.0582  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0382  decode.d8.loss_dice: 0.0590
2023/12/31 20:49:50 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 20:49:50 - mmengine - INFO - Iter(train) [20000/90000]  base_lr: 7.9758e-05 lr: 7.9758e-06  eta: 19:35:34  time: 1.0076  data_time: 0.0123  memory: 18544  grad_norm: 5.6753  loss: 1.0336  decode.loss_cls: 0.0000  decode.loss_mask: 0.0385  decode.loss_dice: 0.0614  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.0378  decode.d0.loss_dice: 0.0623  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0375  decode.d1.loss_dice: 0.0658  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0382  decode.d2.loss_dice: 0.0628  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0390  decode.d3.loss_dice: 0.0681  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0381  decode.d4.loss_dice: 0.0627  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0379  decode.d5.loss_dice: 0.0598  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0368  decode.d6.loss_dice: 0.0628  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0388  decode.d7.loss_dice: 0.0634  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0373  decode.d8.loss_dice: 0.0596
2023/12/31 20:49:50 - mmengine - INFO - Saving checkpoint at 20000 iterations
2023/12/31 20:49:59 - mmengine - INFO - Iter(val) [ 50/370]    eta: 0:00:50  time: 0.1539  data_time: 0.0041  memory: 3090  
2023/12/31 20:50:07 - mmengine - INFO - Iter(val) [100/370]    eta: 0:00:42  time: 0.1541  data_time: 0.0041  memory: 3090  
2023/12/31 20:50:14 - mmengine - INFO - Iter(val) [150/370]    eta: 0:00:34  time: 0.1540  data_time: 0.0040  memory: 3090  
2023/12/31 20:50:22 - mmengine - INFO - Iter(val) [200/370]    eta: 0:00:26  time: 0.1540  data_time: 0.0040  memory: 3090  
2023/12/31 20:50:30 - mmengine - INFO - Iter(val) [250/370]    eta: 0:00:18  time: 0.1540  data_time: 0.0039  memory: 3090  
2023/12/31 20:50:38 - mmengine - INFO - Iter(val) [300/370]    eta: 0:00:10  time: 0.1550  data_time: 0.0046  memory: 3090  
2023/12/31 20:50:45 - mmengine - INFO - Iter(val) [350/370]    eta: 0:00:03  time: 0.1547  data_time: 0.0045  memory: 3090  
2023/12/31 20:50:48 - mmengine - INFO - per class results:
2023/12/31 20:50:48 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.66 | 99.91 |
|     Billboard      | 91.02 | 93.84 |
|      Goal net      | 63.94 | 71.73 |
+--------------------+-------+-------+
2023/12/31 20:50:48 - mmengine - INFO - Iter(val) [370/370]    aAcc: 99.6200  mIoU: 84.8700  mAcc: 88.4900  data_time: 0.0046  time: 0.1548
2023/12/31 20:51:39 - mmengine - INFO - Iter(train) [20050/90000]  base_lr: 7.9707e-05 lr: 7.9707e-06  eta: 19:34:44  time: 1.0058  data_time: 0.0124  memory: 18544  grad_norm: 7.6483  loss: 1.0285  decode.loss_cls: 0.0000  decode.loss_mask: 0.0406  decode.loss_dice: 0.0606  decode.d0.loss_cls: 0.0308  decode.d0.loss_mask: 0.0408  decode.d0.loss_dice: 0.0586  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0400  decode.d1.loss_dice: 0.0602  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0401  decode.d2.loss_dice: 0.0556  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0404  decode.d3.loss_dice: 0.0590  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0407  decode.d4.loss_dice: 0.0659  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0409  decode.d5.loss_dice: 0.0578  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0403  decode.d6.loss_dice: 0.0684  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0396  decode.d7.loss_dice: 0.0548  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0397  decode.d8.loss_dice: 0.0537
2023/12/31 20:52:29 - mmengine - INFO - Iter(train) [20100/90000]  base_lr: 7.9655e-05 lr: 7.9655e-06  eta: 19:33:53  time: 1.0080  data_time: 0.0133  memory: 18544  grad_norm: 6.3500  loss: 1.0152  decode.loss_cls: 0.0000  decode.loss_mask: 0.0377  decode.loss_dice: 0.0604  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0366  decode.d0.loss_dice: 0.0584  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0369  decode.d1.loss_dice: 0.0733  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0380  decode.d2.loss_dice: 0.0627  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0382  decode.d3.loss_dice: 0.0601  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0379  decode.d4.loss_dice: 0.0621  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0374  decode.d5.loss_dice: 0.0652  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0375  decode.d6.loss_dice: 0.0581  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0366  decode.d7.loss_dice: 0.0586  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0370  decode.d8.loss_dice: 0.0559
2023/12/31 20:53:20 - mmengine - INFO - Iter(train) [20150/90000]  base_lr: 7.9604e-05 lr: 7.9604e-06  eta: 19:33:03  time: 1.0059  data_time: 0.0119  memory: 18544  grad_norm: 7.5299  loss: 1.0153  decode.loss_cls: 0.0000  decode.loss_mask: 0.0431  decode.loss_dice: 0.0570  decode.d0.loss_cls: 0.0323  decode.d0.loss_mask: 0.0421  decode.d0.loss_dice: 0.0551  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0427  decode.d1.loss_dice: 0.0563  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0433  decode.d2.loss_dice: 0.0560  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0435  decode.d3.loss_dice: 0.0576  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0426  decode.d4.loss_dice: 0.0563  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0430  decode.d5.loss_dice: 0.0535  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0428  decode.d6.loss_dice: 0.0544  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0415  decode.d7.loss_dice: 0.0545  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0423  decode.d8.loss_dice: 0.0553
2023/12/31 20:54:10 - mmengine - INFO - Iter(train) [20200/90000]  base_lr: 7.9553e-05 lr: 7.9553e-06  eta: 19:32:12  time: 1.0054  data_time: 0.0120  memory: 18544  grad_norm: 6.4650  loss: 1.0185  decode.loss_cls: 0.0000  decode.loss_mask: 0.0414  decode.loss_dice: 0.0547  decode.d0.loss_cls: 0.0285  decode.d0.loss_mask: 0.0419  decode.d0.loss_dice: 0.0573  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0417  decode.d1.loss_dice: 0.0574  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0414  decode.d2.loss_dice: 0.0558  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0413  decode.d3.loss_dice: 0.0609  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0416  decode.d4.loss_dice: 0.0577  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0412  decode.d5.loss_dice: 0.0578  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0420  decode.d6.loss_dice: 0.0553  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0419  decode.d7.loss_dice: 0.0607  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0405  decode.d8.loss_dice: 0.0574
2023/12/31 20:55:00 - mmengine - INFO - Iter(train) [20250/90000]  base_lr: 7.9502e-05 lr: 7.9502e-06  eta: 19:31:22  time: 1.0088  data_time: 0.0140  memory: 18544  grad_norm: 5.0640  loss: 0.9916  decode.loss_cls: 0.0000  decode.loss_mask: 0.0391  decode.loss_dice: 0.0579  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.0393  decode.d0.loss_dice: 0.0557  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0389  decode.d1.loss_dice: 0.0568  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0405  decode.d2.loss_dice: 0.0580  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0396  decode.d3.loss_dice: 0.0591  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0387  decode.d4.loss_dice: 0.0558  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0388  decode.d5.loss_dice: 0.0568  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0393  decode.d6.loss_dice: 0.0577  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0400  decode.d7.loss_dice: 0.0596  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0383  decode.d8.loss_dice: 0.0535
2023/12/31 20:55:51 - mmengine - INFO - Iter(train) [20300/90000]  base_lr: 7.9450e-05 lr: 7.9450e-06  eta: 19:30:31  time: 1.0075  data_time: 0.0135  memory: 18544  grad_norm: 11.0957  loss: 1.2152  decode.loss_cls: 0.0000  decode.loss_mask: 0.0417  decode.loss_dice: 0.0833  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.0421  decode.d0.loss_dice: 0.0664  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0429  decode.d1.loss_dice: 0.0663  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0419  decode.d2.loss_dice: 0.0958  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0422  decode.d3.loss_dice: 0.0688  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0425  decode.d4.loss_dice: 0.0693  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0422  decode.d5.loss_dice: 0.0687  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0433  decode.d6.loss_dice: 0.0930  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0417  decode.d7.loss_dice: 0.0771  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0431  decode.d8.loss_dice: 0.0749
2023/12/31 20:56:41 - mmengine - INFO - Iter(train) [20350/90000]  base_lr: 7.9399e-05 lr: 7.9399e-06  eta: 19:29:41  time: 1.0061  data_time: 0.0119  memory: 18544  grad_norm: 8.0523  loss: 1.1116  decode.loss_cls: 0.0000  decode.loss_mask: 0.0397  decode.loss_dice: 0.0805  decode.d0.loss_cls: 0.0253  decode.d0.loss_mask: 0.0407  decode.d0.loss_dice: 0.0679  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0407  decode.d1.loss_dice: 0.0786  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0404  decode.d2.loss_dice: 0.0675  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0400  decode.d3.loss_dice: 0.0640  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0408  decode.d4.loss_dice: 0.0649  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0392  decode.d5.loss_dice: 0.0631  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0405  decode.d6.loss_dice: 0.0740  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0401  decode.d7.loss_dice: 0.0643  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0397  decode.d8.loss_dice: 0.0600
2023/12/31 20:57:31 - mmengine - INFO - Iter(train) [20400/90000]  base_lr: 7.9348e-05 lr: 7.9348e-06  eta: 19:28:51  time: 1.0082  data_time: 0.0132  memory: 18544  grad_norm: 6.4640  loss: 1.0062  decode.loss_cls: 0.0000  decode.loss_mask: 0.0358  decode.loss_dice: 0.0658  decode.d0.loss_cls: 0.0314  decode.d0.loss_mask: 0.0365  decode.d0.loss_dice: 0.0637  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0356  decode.d1.loss_dice: 0.0597  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0348  decode.d2.loss_dice: 0.0594  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0356  decode.d3.loss_dice: 0.0590  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0348  decode.d4.loss_dice: 0.0613  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0360  decode.d5.loss_dice: 0.0617  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0362  decode.d6.loss_dice: 0.0673  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0367  decode.d7.loss_dice: 0.0640  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0337  decode.d8.loss_dice: 0.0574
2023/12/31 20:58:22 - mmengine - INFO - Iter(train) [20450/90000]  base_lr: 7.9296e-05 lr: 7.9296e-06  eta: 19:28:00  time: 1.0085  data_time: 0.0135  memory: 18544  grad_norm: 7.0050  loss: 1.0194  decode.loss_cls: 0.0000  decode.loss_mask: 0.0432  decode.loss_dice: 0.0551  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0432  decode.d0.loss_dice: 0.0578  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0427  decode.d1.loss_dice: 0.0567  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0429  decode.d2.loss_dice: 0.0571  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0428  decode.d3.loss_dice: 0.0582  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0435  decode.d4.loss_dice: 0.0570  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0436  decode.d5.loss_dice: 0.0585  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0427  decode.d6.loss_dice: 0.0559  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0424  decode.d7.loss_dice: 0.0534  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0425  decode.d8.loss_dice: 0.0554
2023/12/31 20:59:12 - mmengine - INFO - Iter(train) [20500/90000]  base_lr: 7.9245e-05 lr: 7.9245e-06  eta: 19:27:10  time: 1.0057  data_time: 0.0116  memory: 18544  grad_norm: 5.8318  loss: 1.1035  decode.loss_cls: 0.0000  decode.loss_mask: 0.0381  decode.loss_dice: 0.0732  decode.d0.loss_cls: 0.0211  decode.d0.loss_mask: 0.0383  decode.d0.loss_dice: 0.0736  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0370  decode.d1.loss_dice: 0.0682  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0370  decode.d2.loss_dice: 0.0691  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0380  decode.d3.loss_dice: 0.0725  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0373  decode.d4.loss_dice: 0.0689  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0373  decode.d5.loss_dice: 0.0674  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0375  decode.d6.loss_dice: 0.0710  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0382  decode.d7.loss_dice: 0.0688  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0373  decode.d8.loss_dice: 0.0736
2023/12/31 21:00:02 - mmengine - INFO - Iter(train) [20550/90000]  base_lr: 7.9194e-05 lr: 7.9194e-06  eta: 19:26:19  time: 1.0060  data_time: 0.0122  memory: 18544  grad_norm: 6.2069  loss: 1.0499  decode.loss_cls: 0.0000  decode.loss_mask: 0.0379  decode.loss_dice: 0.0609  decode.d0.loss_cls: 0.0336  decode.d0.loss_mask: 0.0392  decode.d0.loss_dice: 0.0653  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0385  decode.d1.loss_dice: 0.0659  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0382  decode.d2.loss_dice: 0.0631  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0383  decode.d3.loss_dice: 0.0650  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0371  decode.d4.loss_dice: 0.0600  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0379  decode.d5.loss_dice: 0.0593  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0388  decode.d6.loss_dice: 0.0646  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0388  decode.d7.loss_dice: 0.0657  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0382  decode.d8.loss_dice: 0.0636
2023/12/31 21:00:53 - mmengine - INFO - Iter(train) [20600/90000]  base_lr: 7.9142e-05 lr: 7.9142e-06  eta: 19:25:29  time: 1.0078  data_time: 0.0133  memory: 18544  grad_norm: 5.2908  loss: 0.9730  decode.loss_cls: 0.0000  decode.loss_mask: 0.0391  decode.loss_dice: 0.0580  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0390  decode.d0.loss_dice: 0.0573  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0385  decode.d1.loss_dice: 0.0553  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0375  decode.d2.loss_dice: 0.0520  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0385  decode.d3.loss_dice: 0.0562  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0398  decode.d4.loss_dice: 0.0609  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0393  decode.d5.loss_dice: 0.0535  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0385  decode.d6.loss_dice: 0.0538  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0382  decode.d7.loss_dice: 0.0530  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0388  decode.d8.loss_dice: 0.0595
2023/12/31 21:01:43 - mmengine - INFO - Iter(train) [20650/90000]  base_lr: 7.9091e-05 lr: 7.9091e-06  eta: 19:24:38  time: 1.0063  data_time: 0.0122  memory: 18544  grad_norm: 7.3721  loss: 1.0657  decode.loss_cls: 0.0000  decode.loss_mask: 0.0363  decode.loss_dice: 0.0620  decode.d0.loss_cls: 0.0253  decode.d0.loss_mask: 0.0381  decode.d0.loss_dice: 0.0687  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0369  decode.d1.loss_dice: 0.0647  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0377  decode.d2.loss_dice: 0.0682  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0374  decode.d3.loss_dice: 0.0716  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0378  decode.d4.loss_dice: 0.0652  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0361  decode.d5.loss_dice: 0.0646  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0371  decode.d6.loss_dice: 0.0708  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0384  decode.d7.loss_dice: 0.0644  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0381  decode.d8.loss_dice: 0.0662
2023/12/31 21:02:34 - mmengine - INFO - Iter(train) [20700/90000]  base_lr: 7.9040e-05 lr: 7.9040e-06  eta: 19:23:48  time: 1.0053  data_time: 0.0119  memory: 18544  grad_norm: 7.3931  loss: 1.0319  decode.loss_cls: 0.0000  decode.loss_mask: 0.0398  decode.loss_dice: 0.0593  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0397  decode.d0.loss_dice: 0.0635  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0405  decode.d1.loss_dice: 0.0643  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0394  decode.d2.loss_dice: 0.0604  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0398  decode.d3.loss_dice: 0.0597  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0402  decode.d4.loss_dice: 0.0589  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0394  decode.d5.loss_dice: 0.0629  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0397  decode.d6.loss_dice: 0.0597  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0397  decode.d7.loss_dice: 0.0605  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0392  decode.d8.loss_dice: 0.0622
2023/12/31 21:03:24 - mmengine - INFO - Iter(train) [20750/90000]  base_lr: 7.8989e-05 lr: 7.8989e-06  eta: 19:22:57  time: 1.0065  data_time: 0.0129  memory: 18544  grad_norm: 6.1855  loss: 1.0358  decode.loss_cls: 0.0000  decode.loss_mask: 0.0392  decode.loss_dice: 0.0594  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.0387  decode.d0.loss_dice: 0.0599  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0400  decode.d1.loss_dice: 0.0615  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0400  decode.d2.loss_dice: 0.0653  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0396  decode.d3.loss_dice: 0.0626  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0396  decode.d4.loss_dice: 0.0640  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0397  decode.d5.loss_dice: 0.0605  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0405  decode.d6.loss_dice: 0.0618  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0391  decode.d7.loss_dice: 0.0600  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0388  decode.d8.loss_dice: 0.0610
2023/12/31 21:04:14 - mmengine - INFO - Iter(train) [20800/90000]  base_lr: 7.8937e-05 lr: 7.8937e-06  eta: 19:22:07  time: 1.0066  data_time: 0.0119  memory: 18544  grad_norm: 8.8881  loss: 1.0760  decode.loss_cls: 0.0000  decode.loss_mask: 0.0383  decode.loss_dice: 0.0721  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0370  decode.d0.loss_dice: 0.0612  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0382  decode.d1.loss_dice: 0.0725  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0369  decode.d2.loss_dice: 0.0597  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0367  decode.d3.loss_dice: 0.0686  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0375  decode.d4.loss_dice: 0.0696  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0370  decode.d5.loss_dice: 0.0621  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0389  decode.d6.loss_dice: 0.0672  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0390  decode.d7.loss_dice: 0.0786  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0374  decode.d8.loss_dice: 0.0645
2023/12/31 21:05:04 - mmengine - INFO - Iter(train) [20850/90000]  base_lr: 7.8886e-05 lr: 7.8886e-06  eta: 19:21:16  time: 1.0061  data_time: 0.0120  memory: 18544  grad_norm: 6.1487  loss: 1.0479  decode.loss_cls: 0.0000  decode.loss_mask: 0.0360  decode.loss_dice: 0.0681  decode.d0.loss_cls: 0.0211  decode.d0.loss_mask: 0.0354  decode.d0.loss_dice: 0.0622  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0352  decode.d1.loss_dice: 0.0667  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0360  decode.d2.loss_dice: 0.0658  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0364  decode.d3.loss_dice: 0.0684  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0348  decode.d4.loss_dice: 0.0618  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0370  decode.d5.loss_dice: 0.0716  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0362  decode.d6.loss_dice: 0.0664  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0373  decode.d7.loss_dice: 0.0673  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0358  decode.d8.loss_dice: 0.0683
2023/12/31 21:05:55 - mmengine - INFO - Iter(train) [20900/90000]  base_lr: 7.8835e-05 lr: 7.8835e-06  eta: 19:20:26  time: 1.0080  data_time: 0.0134  memory: 18544  grad_norm: 6.0749  loss: 0.9547  decode.loss_cls: 0.0000  decode.loss_mask: 0.0372  decode.loss_dice: 0.0575  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.0361  decode.d0.loss_dice: 0.0592  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0357  decode.d1.loss_dice: 0.0539  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0360  decode.d2.loss_dice: 0.0603  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0353  decode.d3.loss_dice: 0.0584  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0355  decode.d4.loss_dice: 0.0580  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0351  decode.d5.loss_dice: 0.0555  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0361  decode.d6.loss_dice: 0.0556  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0365  decode.d7.loss_dice: 0.0593  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0355  decode.d8.loss_dice: 0.0535
2023/12/31 21:06:45 - mmengine - INFO - Iter(train) [20950/90000]  base_lr: 7.8783e-05 lr: 7.8783e-06  eta: 19:19:35  time: 1.0062  data_time: 0.0123  memory: 18544  grad_norm: 7.7080  loss: 1.1263  decode.loss_cls: 0.0000  decode.loss_mask: 0.0388  decode.loss_dice: 0.0679  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0397  decode.d0.loss_dice: 0.0739  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0389  decode.d1.loss_dice: 0.0687  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0406  decode.d2.loss_dice: 0.0726  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0387  decode.d3.loss_dice: 0.0682  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0394  decode.d4.loss_dice: 0.0597  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0391  decode.d5.loss_dice: 0.0617  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0397  decode.d6.loss_dice: 0.0957  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0390  decode.d7.loss_dice: 0.0758  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0391  decode.d8.loss_dice: 0.0624
2023/12/31 21:07:36 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 21:07:36 - mmengine - INFO - Iter(train) [21000/90000]  base_lr: 7.8732e-05 lr: 7.8732e-06  eta: 19:18:45  time: 1.0069  data_time: 0.0121  memory: 18544  grad_norm: 7.5518  loss: 0.9881  decode.loss_cls: 0.0000  decode.loss_mask: 0.0387  decode.loss_dice: 0.0566  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.0407  decode.d0.loss_dice: 0.0615  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0393  decode.d1.loss_dice: 0.0557  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0392  decode.d2.loss_dice: 0.0582  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0395  decode.d3.loss_dice: 0.0545  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0396  decode.d4.loss_dice: 0.0554  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0394  decode.d5.loss_dice: 0.0589  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0381  decode.d6.loss_dice: 0.0553  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0398  decode.d7.loss_dice: 0.0564  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0395  decode.d8.loss_dice: 0.0571
2023/12/31 21:08:26 - mmengine - INFO - Iter(train) [21050/90000]  base_lr: 7.8680e-05 lr: 7.8680e-06  eta: 19:17:54  time: 1.0068  data_time: 0.0128  memory: 18544  grad_norm: 6.8048  loss: 0.9925  decode.loss_cls: 0.0000  decode.loss_mask: 0.0419  decode.loss_dice: 0.0561  decode.d0.loss_cls: 0.0296  decode.d0.loss_mask: 0.0427  decode.d0.loss_dice: 0.0562  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0417  decode.d1.loss_dice: 0.0567  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0402  decode.d2.loss_dice: 0.0543  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0418  decode.d3.loss_dice: 0.0543  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0422  decode.d4.loss_dice: 0.0538  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0416  decode.d5.loss_dice: 0.0524  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0413  decode.d6.loss_dice: 0.0565  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0406  decode.d7.loss_dice: 0.0550  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0408  decode.d8.loss_dice: 0.0528
2023/12/31 21:09:16 - mmengine - INFO - Iter(train) [21100/90000]  base_lr: 7.8629e-05 lr: 7.8629e-06  eta: 19:17:04  time: 1.0067  data_time: 0.0117  memory: 18544  grad_norm: 6.0044  loss: 0.9782  decode.loss_cls: 0.0000  decode.loss_mask: 0.0373  decode.loss_dice: 0.0615  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.0365  decode.d0.loss_dice: 0.0589  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0360  decode.d1.loss_dice: 0.0635  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0370  decode.d2.loss_dice: 0.0564  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0358  decode.d3.loss_dice: 0.0557  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0371  decode.d4.loss_dice: 0.0586  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.0353  decode.d5.loss_dice: 0.0557  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0360  decode.d6.loss_dice: 0.0573  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0377  decode.d7.loss_dice: 0.0621  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0371  decode.d8.loss_dice: 0.0592
2023/12/31 21:10:07 - mmengine - INFO - Iter(train) [21150/90000]  base_lr: 7.8578e-05 lr: 7.8578e-06  eta: 19:16:13  time: 1.0066  data_time: 0.0117  memory: 18544  grad_norm: 6.9531  loss: 1.0559  decode.loss_cls: 0.0000  decode.loss_mask: 0.0417  decode.loss_dice: 0.0597  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0405  decode.d0.loss_dice: 0.0634  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0396  decode.d1.loss_dice: 0.0598  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0415  decode.d2.loss_dice: 0.0635  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0420  decode.d3.loss_dice: 0.0647  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0407  decode.d4.loss_dice: 0.0620  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0411  decode.d5.loss_dice: 0.0612  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0402  decode.d6.loss_dice: 0.0610  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0406  decode.d7.loss_dice: 0.0632  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0408  decode.d8.loss_dice: 0.0623
2023/12/31 21:10:57 - mmengine - INFO - Iter(train) [21200/90000]  base_lr: 7.8526e-05 lr: 7.8526e-06  eta: 19:15:23  time: 1.0058  data_time: 0.0124  memory: 18544  grad_norm: 6.5706  loss: 1.0719  decode.loss_cls: 0.0000  decode.loss_mask: 0.0374  decode.loss_dice: 0.0652  decode.d0.loss_cls: 0.0212  decode.d0.loss_mask: 0.0369  decode.d0.loss_dice: 0.0659  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0377  decode.d1.loss_dice: 0.0706  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0381  decode.d2.loss_dice: 0.0689  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0368  decode.d3.loss_dice: 0.0630  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0383  decode.d4.loss_dice: 0.0697  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0375  decode.d5.loss_dice: 0.0700  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0385  decode.d6.loss_dice: 0.0696  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0373  decode.d7.loss_dice: 0.0624  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0387  decode.d8.loss_dice: 0.0681
2023/12/31 21:11:47 - mmengine - INFO - Iter(train) [21250/90000]  base_lr: 7.8475e-05 lr: 7.8475e-06  eta: 19:14:32  time: 1.0054  data_time: 0.0119  memory: 18544  grad_norm: 9.7244  loss: 1.1366  decode.loss_cls: 0.0000  decode.loss_mask: 0.0413  decode.loss_dice: 0.0719  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.0392  decode.d0.loss_dice: 0.0683  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0404  decode.d1.loss_dice: 0.0738  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0408  decode.d2.loss_dice: 0.0702  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0391  decode.d3.loss_dice: 0.0715  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0399  decode.d4.loss_dice: 0.0708  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0397  decode.d5.loss_dice: 0.0699  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0413  decode.d6.loss_dice: 0.0726  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0405  decode.d7.loss_dice: 0.0715  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0396  decode.d8.loss_dice: 0.0708
2023/12/31 21:12:37 - mmengine - INFO - Iter(train) [21300/90000]  base_lr: 7.8424e-05 lr: 7.8424e-06  eta: 19:13:41  time: 1.0051  data_time: 0.0115  memory: 18544  grad_norm: 6.2711  loss: 1.0537  decode.loss_cls: 0.0000  decode.loss_mask: 0.0394  decode.loss_dice: 0.0647  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0392  decode.d0.loss_dice: 0.0619  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0394  decode.d1.loss_dice: 0.0665  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0398  decode.d2.loss_dice: 0.0671  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0406  decode.d3.loss_dice: 0.0672  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0385  decode.d4.loss_dice: 0.0644  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0389  decode.d5.loss_dice: 0.0615  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0388  decode.d6.loss_dice: 0.0592  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0401  decode.d7.loss_dice: 0.0621  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0383  decode.d8.loss_dice: 0.0614
2023/12/31 21:13:28 - mmengine - INFO - Iter(train) [21350/90000]  base_lr: 7.8372e-05 lr: 7.8372e-06  eta: 19:12:50  time: 1.0062  data_time: 0.0125  memory: 18544  grad_norm: 6.9286  loss: 1.0190  decode.loss_cls: 0.0000  decode.loss_mask: 0.0370  decode.loss_dice: 0.0620  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0361  decode.d0.loss_dice: 0.0636  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0355  decode.d1.loss_dice: 0.0601  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0364  decode.d2.loss_dice: 0.0597  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0369  decode.d3.loss_dice: 0.0656  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0372  decode.d4.loss_dice: 0.0651  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0370  decode.d5.loss_dice: 0.0645  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0364  decode.d6.loss_dice: 0.0598  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0371  decode.d7.loss_dice: 0.0638  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0363  decode.d8.loss_dice: 0.0637
2023/12/31 21:14:18 - mmengine - INFO - Iter(train) [21400/90000]  base_lr: 7.8321e-05 lr: 7.8321e-06  eta: 19:12:00  time: 1.0063  data_time: 0.0123  memory: 18544  grad_norm: 6.4030  loss: 0.9976  decode.loss_cls: 0.0000  decode.loss_mask: 0.0369  decode.loss_dice: 0.0622  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0367  decode.d0.loss_dice: 0.0593  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0368  decode.d1.loss_dice: 0.0601  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0386  decode.d2.loss_dice: 0.0608  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0378  decode.d3.loss_dice: 0.0632  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0369  decode.d4.loss_dice: 0.0618  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0372  decode.d5.loss_dice: 0.0612  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0371  decode.d6.loss_dice: 0.0566  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0360  decode.d7.loss_dice: 0.0584  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0373  decode.d8.loss_dice: 0.0597
2023/12/31 21:15:08 - mmengine - INFO - Iter(train) [21450/90000]  base_lr: 7.8270e-05 lr: 7.8270e-06  eta: 19:11:09  time: 1.0058  data_time: 0.0116  memory: 18544  grad_norm: 7.4933  loss: 1.0510  decode.loss_cls: 0.0000  decode.loss_mask: 0.0393  decode.loss_dice: 0.0613  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.0413  decode.d0.loss_dice: 0.0640  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0401  decode.d1.loss_dice: 0.0606  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0408  decode.d2.loss_dice: 0.0612  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0395  decode.d3.loss_dice: 0.0614  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0404  decode.d4.loss_dice: 0.0620  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0402  decode.d5.loss_dice: 0.0636  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0407  decode.d6.loss_dice: 0.0639  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0415  decode.d7.loss_dice: 0.0620  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0404  decode.d8.loss_dice: 0.0620
2023/12/31 21:15:59 - mmengine - INFO - Iter(train) [21500/90000]  base_lr: 7.8218e-05 lr: 7.8218e-06  eta: 19:10:19  time: 1.0059  data_time: 0.0125  memory: 18544  grad_norm: 10.6088  loss: 1.1101  decode.loss_cls: 0.0000  decode.loss_mask: 0.0386  decode.loss_dice: 0.0761  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0377  decode.d0.loss_dice: 0.0649  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0376  decode.d1.loss_dice: 0.0751  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0373  decode.d2.loss_dice: 0.0664  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0382  decode.d3.loss_dice: 0.0716  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0373  decode.d4.loss_dice: 0.0875  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0379  decode.d5.loss_dice: 0.0619  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0374  decode.d6.loss_dice: 0.0582  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0382  decode.d7.loss_dice: 0.0803  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0379  decode.d8.loss_dice: 0.0634
2023/12/31 21:16:49 - mmengine - INFO - Iter(train) [21550/90000]  base_lr: 7.8167e-05 lr: 7.8167e-06  eta: 19:09:28  time: 1.0056  data_time: 0.0119  memory: 18544  grad_norm: 6.8617  loss: 1.0631  decode.loss_cls: 0.0000  decode.loss_mask: 0.0400  decode.loss_dice: 0.0602  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.0400  decode.d0.loss_dice: 0.0649  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0397  decode.d1.loss_dice: 0.0660  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0389  decode.d2.loss_dice: 0.0636  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0408  decode.d3.loss_dice: 0.0666  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0391  decode.d4.loss_dice: 0.0627  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0399  decode.d5.loss_dice: 0.0677  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0407  decode.d6.loss_dice: 0.0649  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0396  decode.d7.loss_dice: 0.0646  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0394  decode.d8.loss_dice: 0.0604
2023/12/31 21:17:39 - mmengine - INFO - Iter(train) [21600/90000]  base_lr: 7.8115e-05 lr: 7.8115e-06  eta: 19:08:37  time: 1.0071  data_time: 0.0122  memory: 18544  grad_norm: 7.3254  loss: 1.1627  decode.loss_cls: 0.0000  decode.loss_mask: 0.0382  decode.loss_dice: 0.0603  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0391  decode.d0.loss_dice: 0.0623  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0377  decode.d1.loss_dice: 0.0932  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0373  decode.d2.loss_dice: 0.1028  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0369  decode.d3.loss_dice: 0.0570  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0382  decode.d4.loss_dice: 0.0941  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0372  decode.d5.loss_dice: 0.0762  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0392  decode.d6.loss_dice: 0.0828  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0386  decode.d7.loss_dice: 0.0568  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0376  decode.d8.loss_dice: 0.0745
2023/12/31 21:18:30 - mmengine - INFO - Iter(train) [21650/90000]  base_lr: 7.8064e-05 lr: 7.8064e-06  eta: 19:07:48  time: 1.0078  data_time: 0.0126  memory: 18544  grad_norm: 7.5773  loss: 1.1141  decode.loss_cls: 0.0000  decode.loss_mask: 0.0363  decode.loss_dice: 0.0736  decode.d0.loss_cls: 0.0220  decode.d0.loss_mask: 0.0366  decode.d0.loss_dice: 0.0702  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0358  decode.d1.loss_dice: 0.0724  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0363  decode.d2.loss_dice: 0.0755  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0353  decode.d3.loss_dice: 0.0722  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0358  decode.d4.loss_dice: 0.0685  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0372  decode.d5.loss_dice: 0.0744  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0359  decode.d6.loss_dice: 0.0736  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0362  decode.d7.loss_dice: 0.0707  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0368  decode.d8.loss_dice: 0.0788
2023/12/31 21:19:20 - mmengine - INFO - Iter(train) [21700/90000]  base_lr: 7.8013e-05 lr: 7.8013e-06  eta: 19:06:57  time: 1.0072  data_time: 0.0123  memory: 18544  grad_norm: 7.1096  loss: 1.0146  decode.loss_cls: 0.0000  decode.loss_mask: 0.0390  decode.loss_dice: 0.0622  decode.d0.loss_cls: 0.0196  decode.d0.loss_mask: 0.0375  decode.d0.loss_dice: 0.0576  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0374  decode.d1.loss_dice: 0.0607  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0384  decode.d2.loss_dice: 0.0633  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0374  decode.d3.loss_dice: 0.0641  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0381  decode.d4.loss_dice: 0.0597  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0374  decode.d5.loss_dice: 0.0614  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0361  decode.d6.loss_dice: 0.0575  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0398  decode.d7.loss_dice: 0.0673  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0373  decode.d8.loss_dice: 0.0628
2023/12/31 21:20:11 - mmengine - INFO - Iter(train) [21750/90000]  base_lr: 7.7961e-05 lr: 7.7961e-06  eta: 19:06:07  time: 1.0068  data_time: 0.0122  memory: 18544  grad_norm: 5.2449  loss: 0.9840  decode.loss_cls: 0.0000  decode.loss_mask: 0.0376  decode.loss_dice: 0.0540  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.0369  decode.d0.loss_dice: 0.0571  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0381  decode.d1.loss_dice: 0.0578  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0400  decode.d2.loss_dice: 0.0603  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0390  decode.d3.loss_dice: 0.0573  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0375  decode.d4.loss_dice: 0.0553  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0382  decode.d5.loss_dice: 0.0570  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0381  decode.d6.loss_dice: 0.0565  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0401  decode.d7.loss_dice: 0.0585  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0388  decode.d8.loss_dice: 0.0575
2023/12/31 21:21:01 - mmengine - INFO - Iter(train) [21800/90000]  base_lr: 7.7910e-05 lr: 7.7910e-06  eta: 19:05:16  time: 1.0068  data_time: 0.0131  memory: 18544  grad_norm: 8.2212  loss: 1.0931  decode.loss_cls: 0.0000  decode.loss_mask: 0.0374  decode.loss_dice: 0.0701  decode.d0.loss_cls: 0.0215  decode.d0.loss_mask: 0.0378  decode.d0.loss_dice: 0.0733  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0364  decode.d1.loss_dice: 0.0711  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.0375  decode.d2.loss_dice: 0.0704  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.0384  decode.d3.loss_dice: 0.0708  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.0371  decode.d4.loss_dice: 0.0661  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.0385  decode.d5.loss_dice: 0.0645  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0377  decode.d6.loss_dice: 0.0675  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0374  decode.d7.loss_dice: 0.0678  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0700
2023/12/31 21:21:51 - mmengine - INFO - Iter(train) [21850/90000]  base_lr: 7.7858e-05 lr: 7.7858e-06  eta: 19:04:26  time: 1.0069  data_time: 0.0122  memory: 18544  grad_norm: 4.8827  loss: 0.9729  decode.loss_cls: 0.0000  decode.loss_mask: 0.0354  decode.loss_dice: 0.0597  decode.d0.loss_cls: 0.0211  decode.d0.loss_mask: 0.0355  decode.d0.loss_dice: 0.0574  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0362  decode.d1.loss_dice: 0.0617  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0346  decode.d2.loss_dice: 0.0562  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0367  decode.d3.loss_dice: 0.0638  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0354  decode.d4.loss_dice: 0.0607  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0355  decode.d5.loss_dice: 0.0569  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0350  decode.d6.loss_dice: 0.0581  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0361  decode.d7.loss_dice: 0.0602  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0362  decode.d8.loss_dice: 0.0605
2023/12/31 21:22:42 - mmengine - INFO - Iter(train) [21900/90000]  base_lr: 7.7807e-05 lr: 7.7807e-06  eta: 19:03:35  time: 1.0058  data_time: 0.0121  memory: 18544  grad_norm: 10.1312  loss: 1.1978  decode.loss_cls: 0.0000  decode.loss_mask: 0.0435  decode.loss_dice: 0.0758  decode.d0.loss_cls: 0.0298  decode.d0.loss_mask: 0.0421  decode.d0.loss_dice: 0.0833  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0421  decode.d1.loss_dice: 0.0718  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0444  decode.d2.loss_dice: 0.0733  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0433  decode.d3.loss_dice: 0.0772  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0418  decode.d4.loss_dice: 0.0710  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0418  decode.d5.loss_dice: 0.0746  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0433  decode.d6.loss_dice: 0.0717  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0424  decode.d7.loss_dice: 0.0746  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0414  decode.d8.loss_dice: 0.0685
2023/12/31 21:23:32 - mmengine - INFO - Iter(train) [21950/90000]  base_lr: 7.7756e-05 lr: 7.7756e-06  eta: 19:02:45  time: 1.0074  data_time: 0.0125  memory: 18544  grad_norm: 8.9361  loss: 0.9993  decode.loss_cls: 0.0000  decode.loss_mask: 0.0383  decode.loss_dice: 0.0606  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.0382  decode.d0.loss_dice: 0.0670  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0375  decode.d1.loss_dice: 0.0583  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0377  decode.d2.loss_dice: 0.0628  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0375  decode.d3.loss_dice: 0.0580  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0393  decode.d4.loss_dice: 0.0623  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0371  decode.d5.loss_dice: 0.0588  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0365  decode.d6.loss_dice: 0.0557  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0367  decode.d7.loss_dice: 0.0565  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0381  decode.d8.loss_dice: 0.0589
2023/12/31 21:24:22 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 21:24:22 - mmengine - INFO - Iter(train) [22000/90000]  base_lr: 7.7704e-05 lr: 7.7704e-06  eta: 19:01:54  time: 1.0065  data_time: 0.0122  memory: 18544  grad_norm: 5.9387  loss: 1.0222  decode.loss_cls: 0.0000  decode.loss_mask: 0.0389  decode.loss_dice: 0.0631  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.0380  decode.d0.loss_dice: 0.0600  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0375  decode.d1.loss_dice: 0.0631  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0372  decode.d2.loss_dice: 0.0603  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0378  decode.d3.loss_dice: 0.0623  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0375  decode.d4.loss_dice: 0.0602  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0383  decode.d5.loss_dice: 0.0643  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0381  decode.d6.loss_dice: 0.0640  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0380  decode.d7.loss_dice: 0.0606  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0601
2023/12/31 21:25:13 - mmengine - INFO - Iter(train) [22050/90000]  base_lr: 7.7653e-05 lr: 7.7653e-06  eta: 19:01:04  time: 1.0063  data_time: 0.0118  memory: 18544  grad_norm: 6.7312  loss: 1.0389  decode.loss_cls: 0.0000  decode.loss_mask: 0.0379  decode.loss_dice: 0.0628  decode.d0.loss_cls: 0.0227  decode.d0.loss_mask: 0.0374  decode.d0.loss_dice: 0.0628  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0379  decode.d1.loss_dice: 0.0622  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0367  decode.d2.loss_dice: 0.0618  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0384  decode.d3.loss_dice: 0.0675  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0380  decode.d4.loss_dice: 0.0650  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0373  decode.d5.loss_dice: 0.0637  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0384  decode.d6.loss_dice: 0.0622  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0386  decode.d7.loss_dice: 0.0689  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0609
2023/12/31 21:26:03 - mmengine - INFO - Iter(train) [22100/90000]  base_lr: 7.7601e-05 lr: 7.7601e-06  eta: 19:00:13  time: 1.0063  data_time: 0.0122  memory: 18544  grad_norm: 8.2464  loss: 1.0628  decode.loss_cls: 0.0000  decode.loss_mask: 0.0357  decode.loss_dice: 0.0655  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.0376  decode.d0.loss_dice: 0.0630  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0358  decode.d1.loss_dice: 0.0664  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0370  decode.d2.loss_dice: 0.0661  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0372  decode.d3.loss_dice: 0.0775  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0370  decode.d4.loss_dice: 0.0696  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0375  decode.d5.loss_dice: 0.0636  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0380  decode.d6.loss_dice: 0.0696  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0370  decode.d7.loss_dice: 0.0614  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0372  decode.d8.loss_dice: 0.0652
2023/12/31 21:26:53 - mmengine - INFO - Iter(train) [22150/90000]  base_lr: 7.7550e-05 lr: 7.7550e-06  eta: 18:59:22  time: 1.0050  data_time: 0.0117  memory: 18544  grad_norm: 13.0836  loss: 1.0844  decode.loss_cls: 0.0000  decode.loss_mask: 0.0399  decode.loss_dice: 0.0619  decode.d0.loss_cls: 0.0321  decode.d0.loss_mask: 0.0413  decode.d0.loss_dice: 0.0690  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0408  decode.d1.loss_dice: 0.0640  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0415  decode.d2.loss_dice: 0.0669  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0403  decode.d3.loss_dice: 0.0676  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0401  decode.d4.loss_dice: 0.0639  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0401  decode.d5.loss_dice: 0.0616  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0408  decode.d6.loss_dice: 0.0615  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0409  decode.d7.loss_dice: 0.0632  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0405  decode.d8.loss_dice: 0.0665
2023/12/31 21:27:43 - mmengine - INFO - Iter(train) [22200/90000]  base_lr: 7.7498e-05 lr: 7.7498e-06  eta: 18:58:32  time: 1.0047  data_time: 0.0116  memory: 18544  grad_norm: 7.9500  loss: 1.0941  decode.loss_cls: 0.0000  decode.loss_mask: 0.0381  decode.loss_dice: 0.0693  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0377  decode.d0.loss_dice: 0.0671  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0378  decode.d1.loss_dice: 0.0694  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0376  decode.d2.loss_dice: 0.0684  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0370  decode.d3.loss_dice: 0.0721  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0374  decode.d4.loss_dice: 0.0667  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0382  decode.d5.loss_dice: 0.0680  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0381  decode.d6.loss_dice: 0.0674  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0385  decode.d7.loss_dice: 0.0736  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0375  decode.d8.loss_dice: 0.0679
2023/12/31 21:28:34 - mmengine - INFO - Iter(train) [22250/90000]  base_lr: 7.7447e-05 lr: 7.7447e-06  eta: 18:57:41  time: 1.0075  data_time: 0.0119  memory: 18544  grad_norm: 6.7104  loss: 1.0070  decode.loss_cls: 0.0000  decode.loss_mask: 0.0382  decode.loss_dice: 0.0650  decode.d0.loss_cls: 0.0180  decode.d0.loss_mask: 0.0374  decode.d0.loss_dice: 0.0613  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0367  decode.d1.loss_dice: 0.0600  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0377  decode.d2.loss_dice: 0.0611  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0382  decode.d3.loss_dice: 0.0616  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0375  decode.d4.loss_dice: 0.0618  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0383  decode.d5.loss_dice: 0.0621  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0380  decode.d6.loss_dice: 0.0599  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0375  decode.d7.loss_dice: 0.0619  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0366  decode.d8.loss_dice: 0.0584
2023/12/31 21:29:24 - mmengine - INFO - Iter(train) [22300/90000]  base_lr: 7.7396e-05 lr: 7.7396e-06  eta: 18:56:51  time: 1.0069  data_time: 0.0122  memory: 18544  grad_norm: 10.9346  loss: 1.0269  decode.loss_cls: 0.0000  decode.loss_mask: 0.0383  decode.loss_dice: 0.0524  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.0382  decode.d0.loss_dice: 0.0549  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0393  decode.d1.loss_dice: 0.0646  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0384  decode.d2.loss_dice: 0.0613  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0386  decode.d3.loss_dice: 0.0511  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0388  decode.d4.loss_dice: 0.0533  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0392  decode.d5.loss_dice: 0.0597  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0377  decode.d6.loss_dice: 0.0665  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0394  decode.d7.loss_dice: 0.0953  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0385  decode.d8.loss_dice: 0.0533
2023/12/31 21:30:15 - mmengine - INFO - Iter(train) [22350/90000]  base_lr: 7.7344e-05 lr: 7.7344e-06  eta: 18:56:01  time: 1.0085  data_time: 0.0121  memory: 18544  grad_norm: 6.5806  loss: 1.0078  decode.loss_cls: 0.0000  decode.loss_mask: 0.0364  decode.loss_dice: 0.0609  decode.d0.loss_cls: 0.0192  decode.d0.loss_mask: 0.0388  decode.d0.loss_dice: 0.0617  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0389  decode.d1.loss_dice: 0.0650  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0376  decode.d2.loss_dice: 0.0624  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0382  decode.d3.loss_dice: 0.0601  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0373  decode.d4.loss_dice: 0.0629  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0382  decode.d5.loss_dice: 0.0609  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0375  decode.d6.loss_dice: 0.0610  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0373  decode.d7.loss_dice: 0.0569  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0373  decode.d8.loss_dice: 0.0592
2023/12/31 21:31:05 - mmengine - INFO - Iter(train) [22400/90000]  base_lr: 7.7293e-05 lr: 7.7293e-06  eta: 18:55:10  time: 1.0056  data_time: 0.0121  memory: 18544  grad_norm: 6.4982  loss: 0.9983  decode.loss_cls: 0.0000  decode.loss_mask: 0.0387  decode.loss_dice: 0.0556  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0401  decode.d0.loss_dice: 0.0567  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0401  decode.d1.loss_dice: 0.0566  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0388  decode.d2.loss_dice: 0.0573  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0384  decode.d3.loss_dice: 0.0539  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0404  decode.d4.loss_dice: 0.0570  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0402  decode.d5.loss_dice: 0.0576  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0403  decode.d6.loss_dice: 0.0587  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0405  decode.d7.loss_dice: 0.0602  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0401  decode.d8.loss_dice: 0.0605
2023/12/31 21:31:55 - mmengine - INFO - Iter(train) [22450/90000]  base_lr: 7.7241e-05 lr: 7.7241e-06  eta: 18:54:20  time: 1.0061  data_time: 0.0124  memory: 18544  grad_norm: 5.3630  loss: 0.9856  decode.loss_cls: 0.0000  decode.loss_mask: 0.0370  decode.loss_dice: 0.0525  decode.d0.loss_cls: 0.0291  decode.d0.loss_mask: 0.0363  decode.d0.loss_dice: 0.0539  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0360  decode.d1.loss_dice: 0.0513  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0368  decode.d2.loss_dice: 0.0517  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0357  decode.d3.loss_dice: 0.0491  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0380  decode.d4.loss_dice: 0.0633  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0366  decode.d5.loss_dice: 0.0830  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0360  decode.d6.loss_dice: 0.0513  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0362  decode.d7.loss_dice: 0.0619  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0371  decode.d8.loss_dice: 0.0725
2023/12/31 21:32:46 - mmengine - INFO - Iter(train) [22500/90000]  base_lr: 7.7190e-05 lr: 7.7190e-06  eta: 18:53:29  time: 1.0071  data_time: 0.0124  memory: 18544  grad_norm: 7.7679  loss: 1.1460  decode.loss_cls: 0.0000  decode.loss_mask: 0.0427  decode.loss_dice: 0.0688  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.0437  decode.d0.loss_dice: 0.0698  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0418  decode.d1.loss_dice: 0.0687  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0438  decode.d2.loss_dice: 0.0731  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0413  decode.d3.loss_dice: 0.0699  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0425  decode.d4.loss_dice: 0.0692  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0429  decode.d5.loss_dice: 0.0698  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0431  decode.d6.loss_dice: 0.0707  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0425  decode.d7.loss_dice: 0.0680  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0416  decode.d8.loss_dice: 0.0689
2023/12/31 21:33:36 - mmengine - INFO - Iter(train) [22550/90000]  base_lr: 7.7138e-05 lr: 7.7138e-06  eta: 18:52:39  time: 1.0064  data_time: 0.0124  memory: 18544  grad_norm: 6.0593  loss: 1.0328  decode.loss_cls: 0.0000  decode.loss_mask: 0.0401  decode.loss_dice: 0.0612  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0397  decode.d0.loss_dice: 0.0588  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0396  decode.d1.loss_dice: 0.0582  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0398  decode.d2.loss_dice: 0.0584  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0401  decode.d3.loss_dice: 0.0616  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0398  decode.d4.loss_dice: 0.0643  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0388  decode.d5.loss_dice: 0.0613  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0397  decode.d6.loss_dice: 0.0623  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0404  decode.d7.loss_dice: 0.0604  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0387  decode.d8.loss_dice: 0.0613
2023/12/31 21:34:26 - mmengine - INFO - Iter(train) [22600/90000]  base_lr: 7.7087e-05 lr: 7.7087e-06  eta: 18:51:49  time: 1.0082  data_time: 0.0135  memory: 18544  grad_norm: 33.4471  loss: 1.4925  decode.loss_cls: 0.0101  decode.loss_mask: 0.0618  decode.loss_dice: 0.0729  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.0630  decode.d0.loss_dice: 0.0718  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.0623  decode.d1.loss_dice: 0.0714  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.0641  decode.d2.loss_dice: 0.0706  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.0643  decode.d3.loss_dice: 0.0756  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.0618  decode.d4.loss_dice: 0.0753  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.0634  decode.d5.loss_dice: 0.0734  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.0638  decode.d6.loss_dice: 0.0728  decode.d7.loss_cls: 0.0109  decode.d7.loss_mask: 0.0638  decode.d7.loss_dice: 0.0746  decode.d8.loss_cls: 0.0129  decode.d8.loss_mask: 0.0652  decode.d8.loss_dice: 0.0731
2023/12/31 21:35:17 - mmengine - INFO - Iter(train) [22650/90000]  base_lr: 7.7035e-05 lr: 7.7035e-06  eta: 18:50:58  time: 1.0069  data_time: 0.0127  memory: 18544  grad_norm: 12.6720  loss: 1.0886  decode.loss_cls: 0.0000  decode.loss_mask: 0.0420  decode.loss_dice: 0.0610  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0431  decode.d0.loss_dice: 0.0757  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0436  decode.d1.loss_dice: 0.0696  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0429  decode.d2.loss_dice: 0.0612  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0432  decode.d3.loss_dice: 0.0631  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0427  decode.d4.loss_dice: 0.0579  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0427  decode.d5.loss_dice: 0.0600  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0421  decode.d6.loss_dice: 0.0654  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0449  decode.d7.loss_dice: 0.0620  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0424  decode.d8.loss_dice: 0.0600
2023/12/31 21:36:07 - mmengine - INFO - Iter(train) [22700/90000]  base_lr: 7.6984e-05 lr: 7.6984e-06  eta: 18:50:08  time: 1.0077  data_time: 0.0124  memory: 18544  grad_norm: 5.8368  loss: 1.0046  decode.loss_cls: 0.0000  decode.loss_mask: 0.0375  decode.loss_dice: 0.0610  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.0366  decode.d0.loss_dice: 0.0607  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0373  decode.d1.loss_dice: 0.0607  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0379  decode.d2.loss_dice: 0.0605  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0379  decode.d3.loss_dice: 0.0593  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0381  decode.d4.loss_dice: 0.0636  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0374  decode.d5.loss_dice: 0.0621  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0373  decode.d6.loss_dice: 0.0607  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0379  decode.d7.loss_dice: 0.0590  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0375  decode.d8.loss_dice: 0.0585
2023/12/31 21:36:58 - mmengine - INFO - Iter(train) [22750/90000]  base_lr: 7.6932e-05 lr: 7.6932e-06  eta: 18:49:18  time: 1.0056  data_time: 0.0118  memory: 18544  grad_norm: 7.2753  loss: 1.0567  decode.loss_cls: 0.0000  decode.loss_mask: 0.0411  decode.loss_dice: 0.0631  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.0402  decode.d0.loss_dice: 0.0623  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0414  decode.d1.loss_dice: 0.0699  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0408  decode.d2.loss_dice: 0.0580  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0403  decode.d3.loss_dice: 0.0657  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0413  decode.d4.loss_dice: 0.0585  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0416  decode.d5.loss_dice: 0.0673  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0404  decode.d6.loss_dice: 0.0608  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0404  decode.d7.loss_dice: 0.0594  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0404  decode.d8.loss_dice: 0.0560
2023/12/31 21:37:48 - mmengine - INFO - Iter(train) [22800/90000]  base_lr: 7.6881e-05 lr: 7.6881e-06  eta: 18:48:27  time: 1.0058  data_time: 0.0116  memory: 18544  grad_norm: 7.3746  loss: 1.0245  decode.loss_cls: 0.0000  decode.loss_mask: 0.0364  decode.loss_dice: 0.0695  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.0359  decode.d0.loss_dice: 0.0640  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0356  decode.d1.loss_dice: 0.0660  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0352  decode.d2.loss_dice: 0.0639  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0352  decode.d3.loss_dice: 0.0647  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0360  decode.d4.loss_dice: 0.0685  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0350  decode.d5.loss_dice: 0.0619  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0355  decode.d6.loss_dice: 0.0621  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0354  decode.d7.loss_dice: 0.0654  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0356  decode.d8.loss_dice: 0.0632
2023/12/31 21:38:38 - mmengine - INFO - Iter(train) [22850/90000]  base_lr: 7.6829e-05 lr: 7.6829e-06  eta: 18:47:37  time: 1.0077  data_time: 0.0128  memory: 18544  grad_norm: 5.5641  loss: 0.9978  decode.loss_cls: 0.0000  decode.loss_mask: 0.0390  decode.loss_dice: 0.0627  decode.d0.loss_cls: 0.0172  decode.d0.loss_mask: 0.0382  decode.d0.loss_dice: 0.0631  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0610  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0371  decode.d2.loss_dice: 0.0569  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0377  decode.d3.loss_dice: 0.0562  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0369  decode.d4.loss_dice: 0.0577  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0389  decode.d5.loss_dice: 0.0609  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0387  decode.d6.loss_dice: 0.0614  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0381  decode.d7.loss_dice: 0.0602  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0588
2023/12/31 21:39:29 - mmengine - INFO - Iter(train) [22900/90000]  base_lr: 7.6778e-05 lr: 7.6778e-06  eta: 18:46:46  time: 1.0095  data_time: 0.0136  memory: 18544  grad_norm: 5.5530  loss: 1.0414  decode.loss_cls: 0.0000  decode.loss_mask: 0.0356  decode.loss_dice: 0.0701  decode.d0.loss_cls: 0.0199  decode.d0.loss_mask: 0.0353  decode.d0.loss_dice: 0.0700  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0343  decode.d1.loss_dice: 0.0636  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0349  decode.d2.loss_dice: 0.0670  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0347  decode.d3.loss_dice: 0.0683  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0351  decode.d4.loss_dice: 0.0680  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0350  decode.d5.loss_dice: 0.0667  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0346  decode.d6.loss_dice: 0.0654  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0349  decode.d7.loss_dice: 0.0665  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0351  decode.d8.loss_dice: 0.0664
2023/12/31 21:40:19 - mmengine - INFO - Iter(train) [22950/90000]  base_lr: 7.6726e-05 lr: 7.6726e-06  eta: 18:45:56  time: 1.0057  data_time: 0.0119  memory: 18544  grad_norm: 5.8985  loss: 0.9322  decode.loss_cls: 0.0000  decode.loss_mask: 0.0391  decode.loss_dice: 0.0489  decode.d0.loss_cls: 0.0337  decode.d0.loss_mask: 0.0403  decode.d0.loss_dice: 0.0504  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0399  decode.d1.loss_dice: 0.0512  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0398  decode.d2.loss_dice: 0.0492  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0395  decode.d3.loss_dice: 0.0490  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0392  decode.d4.loss_dice: 0.0511  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0389  decode.d5.loss_dice: 0.0491  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0394  decode.d6.loss_dice: 0.0510  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0400  decode.d7.loss_dice: 0.0514  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0403  decode.d8.loss_dice: 0.0507
2023/12/31 21:41:10 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 21:41:10 - mmengine - INFO - Iter(train) [23000/90000]  base_lr: 7.6675e-05 lr: 7.6675e-06  eta: 18:45:06  time: 1.0071  data_time: 0.0121  memory: 18544  grad_norm: 5.4732  loss: 1.0069  decode.loss_cls: 0.0000  decode.loss_mask: 0.0392  decode.loss_dice: 0.0604  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0398  decode.d0.loss_dice: 0.0613  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0391  decode.d1.loss_dice: 0.0567  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0398  decode.d2.loss_dice: 0.0601  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0394  decode.d3.loss_dice: 0.0601  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0393  decode.d4.loss_dice: 0.0588  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0386  decode.d5.loss_dice: 0.0566  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0400  decode.d6.loss_dice: 0.0585  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0376  decode.d7.loss_dice: 0.0562  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0390  decode.d8.loss_dice: 0.0595
2023/12/31 21:42:00 - mmengine - INFO - Iter(train) [23050/90000]  base_lr: 7.6623e-05 lr: 7.6623e-06  eta: 18:44:15  time: 1.0085  data_time: 0.0132  memory: 18544  grad_norm: 6.6342  loss: 1.0008  decode.loss_cls: 0.0000  decode.loss_mask: 0.0376  decode.loss_dice: 0.0592  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.0374  decode.d0.loss_dice: 0.0593  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0362  decode.d1.loss_dice: 0.0598  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0370  decode.d2.loss_dice: 0.0607  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0378  decode.d3.loss_dice: 0.0607  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0376  decode.d4.loss_dice: 0.0596  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0381  decode.d5.loss_dice: 0.0601  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0373  decode.d6.loss_dice: 0.0597  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0372  decode.d7.loss_dice: 0.0618  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0608
2023/12/31 21:42:50 - mmengine - INFO - Iter(train) [23100/90000]  base_lr: 7.6572e-05 lr: 7.6572e-06  eta: 18:43:25  time: 1.0072  data_time: 0.0125  memory: 18544  grad_norm: 6.8573  loss: 1.0234  decode.loss_cls: 0.0000  decode.loss_mask: 0.0390  decode.loss_dice: 0.0619  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0376  decode.d0.loss_dice: 0.0590  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0379  decode.d1.loss_dice: 0.0625  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0379  decode.d2.loss_dice: 0.0644  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0379  decode.d3.loss_dice: 0.0623  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0372  decode.d4.loss_dice: 0.0598  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0376  decode.d5.loss_dice: 0.0604  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0380  decode.d6.loss_dice: 0.0641  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0384  decode.d7.loss_dice: 0.0647  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0380  decode.d8.loss_dice: 0.0617
2023/12/31 21:43:41 - mmengine - INFO - Iter(train) [23150/90000]  base_lr: 7.6520e-05 lr: 7.6520e-06  eta: 18:42:35  time: 1.0071  data_time: 0.0125  memory: 18544  grad_norm: 9.6290  loss: 1.0443  decode.loss_cls: 0.0000  decode.loss_mask: 0.0391  decode.loss_dice: 0.0570  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.0392  decode.d0.loss_dice: 0.0662  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0390  decode.d1.loss_dice: 0.0612  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0379  decode.d2.loss_dice: 0.0522  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0383  decode.d3.loss_dice: 0.0544  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0378  decode.d4.loss_dice: 0.0715  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0385  decode.d5.loss_dice: 0.0663  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0375  decode.d6.loss_dice: 0.0663  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0390  decode.d7.loss_dice: 0.0567  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0394  decode.d8.loss_dice: 0.0818
2023/12/31 21:44:31 - mmengine - INFO - Iter(train) [23200/90000]  base_lr: 7.6469e-05 lr: 7.6469e-06  eta: 18:41:44  time: 1.0044  data_time: 0.0122  memory: 18544  grad_norm: 9.4393  loss: 1.0784  decode.loss_cls: 0.0000  decode.loss_mask: 0.0391  decode.loss_dice: 0.0823  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0389  decode.d0.loss_dice: 0.0596  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0405  decode.d1.loss_dice: 0.0624  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0395  decode.d2.loss_dice: 0.0641  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0392  decode.d3.loss_dice: 0.0603  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0394  decode.d4.loss_dice: 0.0651  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0397  decode.d5.loss_dice: 0.0676  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0388  decode.d6.loss_dice: 0.0710  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0399  decode.d7.loss_dice: 0.0630  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0394  decode.d8.loss_dice: 0.0622
2023/12/31 21:45:21 - mmengine - INFO - Iter(train) [23250/90000]  base_lr: 7.6417e-05 lr: 7.6417e-06  eta: 18:40:54  time: 1.0078  data_time: 0.0126  memory: 18544  grad_norm: 6.4355  loss: 1.0214  decode.loss_cls: 0.0000  decode.loss_mask: 0.0372  decode.loss_dice: 0.0627  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0377  decode.d0.loss_dice: 0.0654  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0382  decode.d1.loss_dice: 0.0637  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0368  decode.d2.loss_dice: 0.0620  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0384  decode.d3.loss_dice: 0.0595  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0378  decode.d4.loss_dice: 0.0635  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0382  decode.d5.loss_dice: 0.0610  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0367  decode.d6.loss_dice: 0.0608  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0373  decode.d7.loss_dice: 0.0591  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0383  decode.d8.loss_dice: 0.0605
2023/12/31 21:46:12 - mmengine - INFO - Iter(train) [23300/90000]  base_lr: 7.6366e-05 lr: 7.6366e-06  eta: 18:40:03  time: 1.0074  data_time: 0.0130  memory: 18544  grad_norm: 6.0880  loss: 0.9700  decode.loss_cls: 0.0000  decode.loss_mask: 0.0405  decode.loss_dice: 0.0586  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.0393  decode.d0.loss_dice: 0.0545  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0397  decode.d1.loss_dice: 0.0525  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0389  decode.d2.loss_dice: 0.0548  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0374  decode.d3.loss_dice: 0.0524  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0404  decode.d4.loss_dice: 0.0561  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0388  decode.d5.loss_dice: 0.0551  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0387  decode.d6.loss_dice: 0.0556  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0397  decode.d7.loss_dice: 0.0536  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0401  decode.d8.loss_dice: 0.0551
2023/12/31 21:47:02 - mmengine - INFO - Iter(train) [23350/90000]  base_lr: 7.6314e-05 lr: 7.6314e-06  eta: 18:39:13  time: 1.0082  data_time: 0.0134  memory: 18544  grad_norm: 6.1054  loss: 0.9494  decode.loss_cls: 0.0000  decode.loss_mask: 0.0382  decode.loss_dice: 0.0498  decode.d0.loss_cls: 0.0350  decode.d0.loss_mask: 0.0388  decode.d0.loss_dice: 0.0525  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0370  decode.d1.loss_dice: 0.0507  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0385  decode.d2.loss_dice: 0.0529  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0384  decode.d3.loss_dice: 0.0528  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0373  decode.d4.loss_dice: 0.0533  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0392  decode.d5.loss_dice: 0.0580  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0390  decode.d6.loss_dice: 0.0543  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0392  decode.d7.loss_dice: 0.0540  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0382  decode.d8.loss_dice: 0.0522
2023/12/31 21:47:53 - mmengine - INFO - Iter(train) [23400/90000]  base_lr: 7.6263e-05 lr: 7.6263e-06  eta: 18:38:23  time: 1.0067  data_time: 0.0125  memory: 18544  grad_norm: 6.3360  loss: 0.9602  decode.loss_cls: 0.0000  decode.loss_mask: 0.0377  decode.loss_dice: 0.0557  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.0381  decode.d0.loss_dice: 0.0520  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0380  decode.d1.loss_dice: 0.0546  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0385  decode.d2.loss_dice: 0.0525  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0382  decode.d3.loss_dice: 0.0525  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0394  decode.d4.loss_dice: 0.0549  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0385  decode.d5.loss_dice: 0.0563  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0398  decode.d6.loss_dice: 0.0578  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0395  decode.d7.loss_dice: 0.0550  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0386  decode.d8.loss_dice: 0.0563
2023/12/31 21:48:43 - mmengine - INFO - Iter(train) [23450/90000]  base_lr: 7.6211e-05 lr: 7.6211e-06  eta: 18:37:32  time: 1.0065  data_time: 0.0130  memory: 18544  grad_norm: 6.3890  loss: 1.0711  decode.loss_cls: 0.0000  decode.loss_mask: 0.0368  decode.loss_dice: 0.0641  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0380  decode.d0.loss_dice: 0.0654  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0389  decode.d1.loss_dice: 0.0720  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0378  decode.d2.loss_dice: 0.0676  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0379  decode.d3.loss_dice: 0.0704  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0364  decode.d4.loss_dice: 0.0637  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0383  decode.d5.loss_dice: 0.0662  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0369  decode.d6.loss_dice: 0.0645  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0369  decode.d7.loss_dice: 0.0677  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0373  decode.d8.loss_dice: 0.0661
2023/12/31 21:49:33 - mmengine - INFO - Iter(train) [23500/90000]  base_lr: 7.6160e-05 lr: 7.6160e-06  eta: 18:36:42  time: 1.0069  data_time: 0.0135  memory: 18544  grad_norm: 16.4369  loss: 1.3090  decode.loss_cls: 0.0016  decode.loss_mask: 0.0390  decode.loss_dice: 0.0813  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.0388  decode.d0.loss_dice: 0.0923  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0396  decode.d1.loss_dice: 0.0930  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0392  decode.d2.loss_dice: 0.1042  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0386  decode.d3.loss_dice: 0.0765  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0378  decode.d4.loss_dice: 0.0915  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0392  decode.d5.loss_dice: 0.0955  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0378  decode.d6.loss_dice: 0.0904  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0373  decode.d7.loss_dice: 0.0668  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0377  decode.d8.loss_dice: 0.1024
2023/12/31 21:50:24 - mmengine - INFO - Iter(train) [23550/90000]  base_lr: 7.6108e-05 lr: 7.6108e-06  eta: 18:35:51  time: 1.0068  data_time: 0.0123  memory: 18544  grad_norm: 6.6090  loss: 1.0347  decode.loss_cls: 0.0000  decode.loss_mask: 0.0391  decode.loss_dice: 0.0666  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0396  decode.d0.loss_dice: 0.0605  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0384  decode.d1.loss_dice: 0.0562  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0392  decode.d2.loss_dice: 0.0640  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0384  decode.d3.loss_dice: 0.0644  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0385  decode.d4.loss_dice: 0.0564  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0388  decode.d5.loss_dice: 0.0641  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0387  decode.d6.loss_dice: 0.0582  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0386  decode.d7.loss_dice: 0.0741  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0375  decode.d8.loss_dice: 0.0585
2023/12/31 21:51:14 - mmengine - INFO - Iter(train) [23600/90000]  base_lr: 7.6057e-05 lr: 7.6057e-06  eta: 18:35:01  time: 1.0057  data_time: 0.0130  memory: 18544  grad_norm: 5.4456  loss: 0.9571  decode.loss_cls: 0.0000  decode.loss_mask: 0.0373  decode.loss_dice: 0.0524  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0385  decode.d0.loss_dice: 0.0591  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0368  decode.d1.loss_dice: 0.0530  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0378  decode.d2.loss_dice: 0.0531  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0379  decode.d3.loss_dice: 0.0548  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0380  decode.d4.loss_dice: 0.0560  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0382  decode.d5.loss_dice: 0.0539  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0386  decode.d6.loss_dice: 0.0604  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0365  decode.d7.loss_dice: 0.0597  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0378  decode.d8.loss_dice: 0.0527
2023/12/31 21:52:04 - mmengine - INFO - Iter(train) [23650/90000]  base_lr: 7.6005e-05 lr: 7.6005e-06  eta: 18:34:10  time: 1.0078  data_time: 0.0135  memory: 18544  grad_norm: 7.3721  loss: 1.0558  decode.loss_cls: 0.0000  decode.loss_mask: 0.0387  decode.loss_dice: 0.0628  decode.d0.loss_cls: 0.0262  decode.d0.loss_mask: 0.0388  decode.d0.loss_dice: 0.0612  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0392  decode.d1.loss_dice: 0.0639  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0399  decode.d2.loss_dice: 0.0623  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0394  decode.d3.loss_dice: 0.0651  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0391  decode.d4.loss_dice: 0.0642  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0384  decode.d5.loss_dice: 0.0639  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0394  decode.d6.loss_dice: 0.0666  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0393  decode.d7.loss_dice: 0.0619  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0396  decode.d8.loss_dice: 0.0658
2023/12/31 21:52:55 - mmengine - INFO - Iter(train) [23700/90000]  base_lr: 7.5954e-05 lr: 7.5954e-06  eta: 18:33:20  time: 1.0074  data_time: 0.0125  memory: 18544  grad_norm: 11.1543  loss: 1.2538  decode.loss_cls: 0.0000  decode.loss_mask: 0.0433  decode.loss_dice: 0.0799  decode.d0.loss_cls: 0.0210  decode.d0.loss_mask: 0.0445  decode.d0.loss_dice: 0.0768  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0427  decode.d1.loss_dice: 0.0790  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0441  decode.d2.loss_dice: 0.0802  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0430  decode.d3.loss_dice: 0.0812  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0452  decode.d4.loss_dice: 0.0794  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0440  decode.d5.loss_dice: 0.0851  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0436  decode.d6.loss_dice: 0.0798  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0434  decode.d7.loss_dice: 0.0753  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0439  decode.d8.loss_dice: 0.0784
2023/12/31 21:53:45 - mmengine - INFO - Iter(train) [23750/90000]  base_lr: 7.5902e-05 lr: 7.5902e-06  eta: 18:32:29  time: 1.0079  data_time: 0.0134  memory: 18544  grad_norm: 6.0105  loss: 1.0418  decode.loss_cls: 0.0000  decode.loss_mask: 0.0420  decode.loss_dice: 0.0601  decode.d0.loss_cls: 0.0304  decode.d0.loss_mask: 0.0393  decode.d0.loss_dice: 0.0566  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0422  decode.d1.loss_dice: 0.0621  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0413  decode.d2.loss_dice: 0.0620  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0407  decode.d3.loss_dice: 0.0564  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0422  decode.d4.loss_dice: 0.0631  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0413  decode.d5.loss_dice: 0.0613  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0414  decode.d6.loss_dice: 0.0602  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0410  decode.d7.loss_dice: 0.0580  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0417  decode.d8.loss_dice: 0.0586
2023/12/31 21:54:35 - mmengine - INFO - Iter(train) [23800/90000]  base_lr: 7.5850e-05 lr: 7.5850e-06  eta: 18:31:39  time: 1.0092  data_time: 0.0135  memory: 18544  grad_norm: 5.9127  loss: 0.9550  decode.loss_cls: 0.0000  decode.loss_mask: 0.0355  decode.loss_dice: 0.0554  decode.d0.loss_cls: 0.0225  decode.d0.loss_mask: 0.0363  decode.d0.loss_dice: 0.0544  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0369  decode.d1.loss_dice: 0.0566  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0378  decode.d2.loss_dice: 0.0590  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0359  decode.d3.loss_dice: 0.0560  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0362  decode.d4.loss_dice: 0.0552  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0360  decode.d5.loss_dice: 0.0554  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0378  decode.d6.loss_dice: 0.0591  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0370  decode.d7.loss_dice: 0.0594  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0371  decode.d8.loss_dice: 0.0554
2023/12/31 21:55:26 - mmengine - INFO - Iter(train) [23850/90000]  base_lr: 7.5799e-05 lr: 7.5799e-06  eta: 18:30:48  time: 1.0067  data_time: 0.0123  memory: 18544  grad_norm: 13.3972  loss: 1.4670  decode.loss_cls: 0.0000  decode.loss_mask: 0.0380  decode.loss_dice: 0.1177  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0373  decode.d0.loss_dice: 0.1646  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0379  decode.d1.loss_dice: 0.0700  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0378  decode.d2.loss_dice: 0.0649  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0369  decode.d3.loss_dice: 0.1108  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0379  decode.d4.loss_dice: 0.0753  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0379  decode.d5.loss_dice: 0.1033  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0376  decode.d6.loss_dice: 0.0868  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0376  decode.d7.loss_dice: 0.1408  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0386  decode.d8.loss_dice: 0.1291
2023/12/31 21:56:16 - mmengine - INFO - Iter(train) [23900/90000]  base_lr: 7.5747e-05 lr: 7.5747e-06  eta: 18:29:58  time: 1.0073  data_time: 0.0134  memory: 18544  grad_norm: 7.4444  loss: 0.9663  decode.loss_cls: 0.0000  decode.loss_mask: 0.0406  decode.loss_dice: 0.0559  decode.d0.loss_cls: 0.0298  decode.d0.loss_mask: 0.0408  decode.d0.loss_dice: 0.0539  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0408  decode.d1.loss_dice: 0.0527  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0394  decode.d2.loss_dice: 0.0501  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0394  decode.d3.loss_dice: 0.0530  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0409  decode.d4.loss_dice: 0.0540  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0402  decode.d5.loss_dice: 0.0533  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0407  decode.d6.loss_dice: 0.0541  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0403  decode.d7.loss_dice: 0.0521  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0406  decode.d8.loss_dice: 0.0540
2023/12/31 21:57:06 - mmengine - INFO - Iter(train) [23950/90000]  base_lr: 7.5696e-05 lr: 7.5696e-06  eta: 18:29:08  time: 1.0089  data_time: 0.0137  memory: 18544  grad_norm: 5.1131  loss: 0.9988  decode.loss_cls: 0.0000  decode.loss_mask: 0.0364  decode.loss_dice: 0.0590  decode.d0.loss_cls: 0.0277  decode.d0.loss_mask: 0.0359  decode.d0.loss_dice: 0.0566  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0378  decode.d1.loss_dice: 0.0649  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0374  decode.d2.loss_dice: 0.0563  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0371  decode.d3.loss_dice: 0.0577  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0377  decode.d4.loss_dice: 0.0639  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0365  decode.d5.loss_dice: 0.0571  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0369  decode.d6.loss_dice: 0.0659  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0369  decode.d7.loss_dice: 0.0601  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0374  decode.d8.loss_dice: 0.0597
2023/12/31 21:57:57 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 21:57:57 - mmengine - INFO - Iter(train) [24000/90000]  base_lr: 7.5644e-05 lr: 7.5644e-06  eta: 18:28:17  time: 1.0075  data_time: 0.0122  memory: 18544  grad_norm: 5.6777  loss: 1.0495  decode.loss_cls: 0.0000  decode.loss_mask: 0.0374  decode.loss_dice: 0.0672  decode.d0.loss_cls: 0.0196  decode.d0.loss_mask: 0.0372  decode.d0.loss_dice: 0.0637  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0368  decode.d1.loss_dice: 0.0669  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0366  decode.d2.loss_dice: 0.0676  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0363  decode.d3.loss_dice: 0.0673  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0363  decode.d4.loss_dice: 0.0645  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0384  decode.d5.loss_dice: 0.0671  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0371  decode.d6.loss_dice: 0.0655  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0366  decode.d7.loss_dice: 0.0627  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0372  decode.d8.loss_dice: 0.0677
2023/12/31 21:58:47 - mmengine - INFO - Iter(train) [24050/90000]  base_lr: 7.5593e-05 lr: 7.5593e-06  eta: 18:27:27  time: 1.0083  data_time: 0.0132  memory: 18544  grad_norm: 6.2497  loss: 1.0131  decode.loss_cls: 0.0000  decode.loss_mask: 0.0374  decode.loss_dice: 0.0615  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0380  decode.d0.loss_dice: 0.0595  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0368  decode.d1.loss_dice: 0.0586  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0373  decode.d2.loss_dice: 0.0620  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0381  decode.d3.loss_dice: 0.0622  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0383  decode.d4.loss_dice: 0.0605  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0381  decode.d5.loss_dice: 0.0604  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0377  decode.d6.loss_dice: 0.0622  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0378  decode.d7.loss_dice: 0.0629  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0385  decode.d8.loss_dice: 0.0625
2023/12/31 21:59:38 - mmengine - INFO - Iter(train) [24100/90000]  base_lr: 7.5541e-05 lr: 7.5541e-06  eta: 18:26:36  time: 1.0073  data_time: 0.0136  memory: 18544  grad_norm: 8.0395  loss: 1.0400  decode.loss_cls: 0.0000  decode.loss_mask: 0.0402  decode.loss_dice: 0.0612  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0394  decode.d0.loss_dice: 0.0599  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0397  decode.d1.loss_dice: 0.0580  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0403  decode.d2.loss_dice: 0.0620  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0417  decode.d3.loss_dice: 0.0615  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0408  decode.d4.loss_dice: 0.0644  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0410  decode.d5.loss_dice: 0.0642  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0399  decode.d6.loss_dice: 0.0614  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0390  decode.d7.loss_dice: 0.0593  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0403  decode.d8.loss_dice: 0.0594
2023/12/31 22:00:28 - mmengine - INFO - Iter(train) [24150/90000]  base_lr: 7.5489e-05 lr: 7.5489e-06  eta: 18:25:46  time: 1.0051  data_time: 0.0121  memory: 18544  grad_norm: 4.9800  loss: 0.8694  decode.loss_cls: 0.0000  decode.loss_mask: 0.0369  decode.loss_dice: 0.0510  decode.d0.loss_cls: 0.0315  decode.d0.loss_mask: 0.0365  decode.d0.loss_dice: 0.0475  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0358  decode.d1.loss_dice: 0.0478  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0356  decode.d2.loss_dice: 0.0478  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0366  decode.d3.loss_dice: 0.0482  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0346  decode.d4.loss_dice: 0.0448  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0367  decode.d5.loss_dice: 0.0509  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0358  decode.d6.loss_dice: 0.0476  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0356  decode.d7.loss_dice: 0.0448  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0356  decode.d8.loss_dice: 0.0478
2023/12/31 22:01:18 - mmengine - INFO - Iter(train) [24200/90000]  base_lr: 7.5438e-05 lr: 7.5438e-06  eta: 18:24:55  time: 1.0072  data_time: 0.0129  memory: 18544  grad_norm: 16.5409  loss: 1.1076  decode.loss_cls: 0.0000  decode.loss_mask: 0.0477  decode.loss_dice: 0.0637  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.0471  decode.d0.loss_dice: 0.0651  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0463  decode.d1.loss_dice: 0.0607  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0459  decode.d2.loss_dice: 0.0637  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0459  decode.d3.loss_dice: 0.0647  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0463  decode.d4.loss_dice: 0.0623  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0453  decode.d5.loss_dice: 0.0596  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0457  decode.d6.loss_dice: 0.0636  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0460  decode.d7.loss_dice: 0.0574  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0456  decode.d8.loss_dice: 0.0621
2023/12/31 22:02:09 - mmengine - INFO - Iter(train) [24250/90000]  base_lr: 7.5386e-05 lr: 7.5386e-06  eta: 18:24:05  time: 1.0076  data_time: 0.0131  memory: 18544  grad_norm: 6.6365  loss: 1.0202  decode.loss_cls: 0.0000  decode.loss_mask: 0.0409  decode.loss_dice: 0.0591  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.0409  decode.d0.loss_dice: 0.0587  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0400  decode.d1.loss_dice: 0.0614  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0397  decode.d2.loss_dice: 0.0596  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0405  decode.d3.loss_dice: 0.0643  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0406  decode.d4.loss_dice: 0.0574  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0398  decode.d5.loss_dice: 0.0566  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0397  decode.d6.loss_dice: 0.0598  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0409  decode.d7.loss_dice: 0.0626  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0395  decode.d8.loss_dice: 0.0513
2023/12/31 22:02:59 - mmengine - INFO - Iter(train) [24300/90000]  base_lr: 7.5335e-05 lr: 7.5335e-06  eta: 18:23:15  time: 1.0051  data_time: 0.0117  memory: 18544  grad_norm: 7.0663  loss: 1.0532  decode.loss_cls: 0.0000  decode.loss_mask: 0.0370  decode.loss_dice: 0.0823  decode.d0.loss_cls: 0.0169  decode.d0.loss_mask: 0.0364  decode.d0.loss_dice: 0.0592  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0366  decode.d1.loss_dice: 0.0848  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0372  decode.d2.loss_dice: 0.0651  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0362  decode.d3.loss_dice: 0.0609  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0360  decode.d4.loss_dice: 0.0595  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0356  decode.d5.loss_dice: 0.0642  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0357  decode.d6.loss_dice: 0.0585  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0375  decode.d7.loss_dice: 0.0665  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0374  decode.d8.loss_dice: 0.0697
2023/12/31 22:03:49 - mmengine - INFO - Iter(train) [24350/90000]  base_lr: 7.5283e-05 lr: 7.5283e-06  eta: 18:22:24  time: 1.0071  data_time: 0.0131  memory: 18544  grad_norm: 6.1930  loss: 0.9492  decode.loss_cls: 0.0000  decode.loss_mask: 0.0382  decode.loss_dice: 0.0555  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.0365  decode.d0.loss_dice: 0.0533  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0371  decode.d1.loss_dice: 0.0524  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0365  decode.d2.loss_dice: 0.0546  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0371  decode.d3.loss_dice: 0.0569  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0382  decode.d4.loss_dice: 0.0573  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0370  decode.d5.loss_dice: 0.0533  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0372  decode.d6.loss_dice: 0.0566  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0378  decode.d7.loss_dice: 0.0557  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0374  decode.d8.loss_dice: 0.0559
2023/12/31 22:04:40 - mmengine - INFO - Iter(train) [24400/90000]  base_lr: 7.5231e-05 lr: 7.5231e-06  eta: 18:21:34  time: 1.0084  data_time: 0.0135  memory: 18544  grad_norm: 5.5168  loss: 1.0024  decode.loss_cls: 0.0000  decode.loss_mask: 0.0364  decode.loss_dice: 0.0639  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.0370  decode.d0.loss_dice: 0.0620  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0355  decode.d1.loss_dice: 0.0650  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0370  decode.d2.loss_dice: 0.0630  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0361  decode.d3.loss_dice: 0.0594  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0368  decode.d4.loss_dice: 0.0595  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0358  decode.d5.loss_dice: 0.0598  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0367  decode.d6.loss_dice: 0.0634  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0356  decode.d7.loss_dice: 0.0627  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0355  decode.d8.loss_dice: 0.0619
2023/12/31 22:05:30 - mmengine - INFO - Iter(train) [24450/90000]  base_lr: 7.5180e-05 lr: 7.5180e-06  eta: 18:20:43  time: 1.0066  data_time: 0.0120  memory: 18544  grad_norm: 5.3805  loss: 0.9322  decode.loss_cls: 0.0000  decode.loss_mask: 0.0390  decode.loss_dice: 0.0520  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.0403  decode.d0.loss_dice: 0.0537  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0396  decode.d1.loss_dice: 0.0519  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0377  decode.d2.loss_dice: 0.0514  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0378  decode.d3.loss_dice: 0.0498  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0395  decode.d4.loss_dice: 0.0515  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0387  decode.d5.loss_dice: 0.0508  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0389  decode.d6.loss_dice: 0.0506  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0390  decode.d7.loss_dice: 0.0536  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0381  decode.d8.loss_dice: 0.0534
2023/12/31 22:06:20 - mmengine - INFO - Iter(train) [24500/90000]  base_lr: 7.5128e-05 lr: 7.5128e-06  eta: 18:19:53  time: 1.0087  data_time: 0.0139  memory: 18544  grad_norm: 6.3936  loss: 0.9844  decode.loss_cls: 0.0000  decode.loss_mask: 0.0399  decode.loss_dice: 0.0558  decode.d0.loss_cls: 0.0299  decode.d0.loss_mask: 0.0394  decode.d0.loss_dice: 0.0557  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0394  decode.d1.loss_dice: 0.0560  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0396  decode.d2.loss_dice: 0.0573  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0392  decode.d3.loss_dice: 0.0542  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0400  decode.d4.loss_dice: 0.0568  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0413  decode.d5.loss_dice: 0.0554  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0414  decode.d6.loss_dice: 0.0589  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0391  decode.d7.loss_dice: 0.0536  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0393  decode.d8.loss_dice: 0.0524
2023/12/31 22:07:11 - mmengine - INFO - Iter(train) [24550/90000]  base_lr: 7.5077e-05 lr: 7.5077e-06  eta: 18:19:03  time: 1.0055  data_time: 0.0123  memory: 18544  grad_norm: 6.1826  loss: 1.0263  decode.loss_cls: 0.0000  decode.loss_mask: 0.0377  decode.loss_dice: 0.0604  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.0373  decode.d0.loss_dice: 0.0634  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0378  decode.d1.loss_dice: 0.0636  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0375  decode.d2.loss_dice: 0.0620  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0365  decode.d3.loss_dice: 0.0604  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0383  decode.d4.loss_dice: 0.0616  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0376  decode.d5.loss_dice: 0.0621  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0389  decode.d6.loss_dice: 0.0610  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0378  decode.d7.loss_dice: 0.0617  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0385  decode.d8.loss_dice: 0.0642
2023/12/31 22:08:01 - mmengine - INFO - Iter(train) [24600/90000]  base_lr: 7.5025e-05 lr: 7.5025e-06  eta: 18:18:12  time: 1.0054  data_time: 0.0126  memory: 18544  grad_norm: 5.3282  loss: 0.9285  decode.loss_cls: 0.0000  decode.loss_mask: 0.0384  decode.loss_dice: 0.0525  decode.d0.loss_cls: 0.0297  decode.d0.loss_mask: 0.0398  decode.d0.loss_dice: 0.0503  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0398  decode.d1.loss_dice: 0.0521  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0409  decode.d2.loss_dice: 0.0557  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0399  decode.d3.loss_dice: 0.0500  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0391  decode.d4.loss_dice: 0.0476  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0398  decode.d5.loss_dice: 0.0490  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0399  decode.d6.loss_dice: 0.0496  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0384  decode.d7.loss_dice: 0.0484  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0389  decode.d8.loss_dice: 0.0487
2023/12/31 22:08:51 - mmengine - INFO - Iter(train) [24650/90000]  base_lr: 7.4973e-05 lr: 7.4973e-06  eta: 18:17:22  time: 1.0089  data_time: 0.0138  memory: 18544  grad_norm: 5.7363  loss: 1.0018  decode.loss_cls: 0.0000  decode.loss_mask: 0.0372  decode.loss_dice: 0.0591  decode.d0.loss_cls: 0.0237  decode.d0.loss_mask: 0.0378  decode.d0.loss_dice: 0.0628  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0366  decode.d1.loss_dice: 0.0615  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0368  decode.d2.loss_dice: 0.0617  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0361  decode.d3.loss_dice: 0.0631  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0373  decode.d4.loss_dice: 0.0604  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0365  decode.d5.loss_dice: 0.0628  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0366  decode.d6.loss_dice: 0.0586  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0364  decode.d7.loss_dice: 0.0581  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0366  decode.d8.loss_dice: 0.0619
2023/12/31 22:09:42 - mmengine - INFO - Iter(train) [24700/90000]  base_lr: 7.4922e-05 lr: 7.4922e-06  eta: 18:16:31  time: 1.0068  data_time: 0.0130  memory: 18544  grad_norm: 6.5911  loss: 0.9935  decode.loss_cls: 0.0000  decode.loss_mask: 0.0395  decode.loss_dice: 0.0518  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.0407  decode.d0.loss_dice: 0.0560  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0405  decode.d1.loss_dice: 0.0539  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0398  decode.d2.loss_dice: 0.0567  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0418  decode.d3.loss_dice: 0.0607  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0407  decode.d4.loss_dice: 0.0571  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0412  decode.d5.loss_dice: 0.0574  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0408  decode.d6.loss_dice: 0.0517  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0414  decode.d7.loss_dice: 0.0577  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0404  decode.d8.loss_dice: 0.0574
2023/12/31 22:10:32 - mmengine - INFO - Iter(train) [24750/90000]  base_lr: 7.4870e-05 lr: 7.4870e-06  eta: 18:15:41  time: 1.0072  data_time: 0.0128  memory: 18544  grad_norm: 8.1791  loss: 0.9793  decode.loss_cls: 0.0000  decode.loss_mask: 0.0382  decode.loss_dice: 0.0559  decode.d0.loss_cls: 0.0215  decode.d0.loss_mask: 0.0388  decode.d0.loss_dice: 0.0585  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0382  decode.d1.loss_dice: 0.0588  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0390  decode.d2.loss_dice: 0.0598  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0390  decode.d3.loss_dice: 0.0569  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0397  decode.d4.loss_dice: 0.0585  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0386  decode.d5.loss_dice: 0.0578  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0383  decode.d6.loss_dice: 0.0568  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0381  decode.d7.loss_dice: 0.0539  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0387  decode.d8.loss_dice: 0.0545
2023/12/31 22:11:23 - mmengine - INFO - Iter(train) [24800/90000]  base_lr: 7.4818e-05 lr: 7.4818e-06  eta: 18:14:50  time: 1.0086  data_time: 0.0138  memory: 18544  grad_norm: 5.7180  loss: 1.0027  decode.loss_cls: 0.0000  decode.loss_mask: 0.0375  decode.loss_dice: 0.0589  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.0385  decode.d0.loss_dice: 0.0602  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0369  decode.d1.loss_dice: 0.0584  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0379  decode.d2.loss_dice: 0.0572  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0386  decode.d3.loss_dice: 0.0601  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0373  decode.d4.loss_dice: 0.0614  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0384  decode.d5.loss_dice: 0.0600  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0382  decode.d6.loss_dice: 0.0587  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0374  decode.d7.loss_dice: 0.0621  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0375  decode.d8.loss_dice: 0.0629
2023/12/31 22:12:13 - mmengine - INFO - Iter(train) [24850/90000]  base_lr: 7.4767e-05 lr: 7.4767e-06  eta: 18:14:00  time: 1.0070  data_time: 0.0136  memory: 18544  grad_norm: 13.5462  loss: 1.0054  decode.loss_cls: 0.0000  decode.loss_mask: 0.0427  decode.loss_dice: 0.0577  decode.d0.loss_cls: 0.0298  decode.d0.loss_mask: 0.0423  decode.d0.loss_dice: 0.0538  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0422  decode.d1.loss_dice: 0.0549  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0424  decode.d2.loss_dice: 0.0548  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0410  decode.d3.loss_dice: 0.0547  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0430  decode.d4.loss_dice: 0.0578  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0418  decode.d5.loss_dice: 0.0537  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0423  decode.d6.loss_dice: 0.0551  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0427  decode.d7.loss_dice: 0.0548  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0429  decode.d8.loss_dice: 0.0550
2023/12/31 22:13:03 - mmengine - INFO - Iter(train) [24900/90000]  base_lr: 7.4715e-05 lr: 7.4715e-06  eta: 18:13:10  time: 1.0074  data_time: 0.0127  memory: 18544  grad_norm: 7.0630  loss: 1.0175  decode.loss_cls: 0.0000  decode.loss_mask: 0.0380  decode.loss_dice: 0.0583  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.0395  decode.d0.loss_dice: 0.0577  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0403  decode.d1.loss_dice: 0.0576  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0388  decode.d2.loss_dice: 0.0587  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0405  decode.d3.loss_dice: 0.0600  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0396  decode.d4.loss_dice: 0.0612  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0405  decode.d5.loss_dice: 0.0594  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0401  decode.d6.loss_dice: 0.0632  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0405  decode.d7.loss_dice: 0.0589  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0393  decode.d8.loss_dice: 0.0588
2023/12/31 22:13:54 - mmengine - INFO - Iter(train) [24950/90000]  base_lr: 7.4664e-05 lr: 7.4664e-06  eta: 18:12:19  time: 1.0085  data_time: 0.0136  memory: 18544  grad_norm: 4.3988  loss: 0.9822  decode.loss_cls: 0.0000  decode.loss_mask: 0.0346  decode.loss_dice: 0.0603  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.0354  decode.d0.loss_dice: 0.0594  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0360  decode.d1.loss_dice: 0.0620  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0355  decode.d2.loss_dice: 0.0613  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0352  decode.d3.loss_dice: 0.0623  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0358  decode.d4.loss_dice: 0.0610  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0356  decode.d5.loss_dice: 0.0593  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0341  decode.d6.loss_dice: 0.0608  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0354  decode.d7.loss_dice: 0.0606  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0355  decode.d8.loss_dice: 0.0609
2023/12/31 22:14:44 - mmengine - INFO - Exp name: mask2former_r50_4xb2-90k_soccernet-1080x1920_20231231_151050
2023/12/31 22:14:44 - mmengine - INFO - Iter(train) [25000/90000]  base_lr: 7.4612e-05 lr: 7.4612e-06  eta: 18:11:29  time: 1.0084  data_time: 0.0133  memory: 18544  grad_norm: 5.2849  loss: 0.9611  decode.loss_cls: 0.0000  decode.loss_mask: 0.0331  decode.loss_dice: 0.0603  decode.d0.loss_cls: 0.0176  decode.d0.loss_mask: 0.0336  decode.d0.loss_dice: 0.0669  decode.d1.loss_cls: 0.0000  decode.d1.loss_mask: 0.0321  decode.d1.loss_dice: 0.0614  decode.d2.loss_cls: 0.0000  decode.d2.loss_mask: 0.0334  decode.d2.loss_dice: 0.0631  decode.d3.loss_cls: 0.0000  decode.d3.loss_mask: 0.0335  decode.d3.loss_dice: 0.0583  decode.d4.loss_cls: 0.0000  decode.d4.loss_mask: 0.0332  decode.d4.loss_dice: 0.0604  decode.d5.loss_cls: 0.0000  decode.d5.loss_mask: 0.0328  decode.d5.loss_dice: 0.0590  decode.d6.loss_cls: 0.0000  decode.d6.loss_mask: 0.0334  decode.d6.loss_dice: 0.0618  decode.d7.loss_cls: 0.0000  decode.d7.loss_mask: 0.0333  decode.d7.loss_dice: 0.0574  decode.d8.loss_cls: 0.0000  decode.d8.loss_mask: 0.0339  decode.d8.loss_dice: 0.0624
2023/12/31 22:14:44 - mmengine - INFO - Saving checkpoint at 25000 iterations
