{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.tensor([1, 2, 3, 4, 5,2,2,2,2,2,2,2,2,2,2,2,2,])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (label != 0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0., 13.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.histc(label[mask].float(), bins=6, min=0, max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Morphology(nn.Module):\n",
    "    '''\n",
    "    Base class for morpholigical operators \n",
    "    For now, only supports stride=1, dilation=1, kernel_size H==W, and padding='same'.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, soft_max=True, beta=15, type=None):\n",
    "        '''\n",
    "        in_channels: scalar\n",
    "        out_channels: scalar, the number of the morphological neure. \n",
    "        kernel_size: scalar, the spatial size of the morphological neure.\n",
    "        soft_max: bool, using the soft max rather the torch.max(), ref: Dense Morphological Networks: An Universal Function Approximator (Mondal et al. (2019)).\n",
    "        beta: scalar, used by soft_max.\n",
    "        type: str, dilation2d or erosion2d.\n",
    "        '''\n",
    "        super(Morphology, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.soft_max = soft_max\n",
    "        self.beta = beta\n",
    "        self.type = type\n",
    "\n",
    "        self.weight = nn.Parameter(torch.zeros(out_channels, in_channels, kernel_size, kernel_size), requires_grad=True)\n",
    "        self.unfold = nn.Unfold(kernel_size, dilation=0, padding=0, stride=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: tensor of shape (B,C,H,W)\n",
    "        '''\n",
    "        # padding\n",
    "        x = fixed_padding(x, self.kernel_size, dilation=1)\n",
    "        \n",
    "        # unfold\n",
    "        x = self.unfold(x)  # (B, Cin*kH*kW, L), where L is the numbers of patches\n",
    "        x = x.unsqueeze(1)  # (B, 1, Cin*kH*kW, L)\n",
    "        L = x.size(-1)\n",
    "        L_sqrt = int(math.sqrt(L))\n",
    "\n",
    "        # erosion\n",
    "        weight = self.weight.view(self.out_channels, -1) # (Cout, Cin*kH*kW)\n",
    "        weight = weight.unsqueeze(0).unsqueeze(-1)  # (1, Cout, Cin*kH*kW, 1)\n",
    "\n",
    "        if self.type == 'erosion2d':\n",
    "            x = weight - x # (B, Cout, Cin*kH*kW, L)\n",
    "        elif self.type == 'dilation2d':\n",
    "            x = weight + x # (B, Cout, Cin*kH*kW, L)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "        if not self.soft_max:\n",
    "            x, _ = torch.max(x, dim=2, keepdim=False) # (B, Cout, L)\n",
    "        else:\n",
    "            x = torch.logsumexp(x*self.beta, dim=2, keepdim=False) / self.beta # (B, Cout, L)\n",
    "\n",
    "        if self.type == 'erosion2d':\n",
    "            x = -1 * x\n",
    "\n",
    "        # instead of fold, we use view to avoid copy\n",
    "        x = x.view(-1, self.out_channels, L_sqrt, L_sqrt)  # (B, Cout, L/2, L/2)\n",
    "\n",
    "        return x \n",
    "\n",
    "class Dilation2d(Morphology):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, soft_max=True, beta=20):\n",
    "        super(Dilation2d, self).__init__(in_channels, out_channels, kernel_size, soft_max, beta, 'dilation2d')\n",
    "\n",
    "class Erosion2d(Morphology):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, soft_max=True, beta=20):\n",
    "        super(Erosion2d, self).__init__(in_channels, out_channels, kernel_size, soft_max, beta, 'erosion2d')\n",
    "\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pytorch, implement a morphological dilation operator with a 3x3 kernel and a dilation rate of 2\n",
    "# The input image is a 1x1x10x10 tensor of integers between 0 and 255\n",
    "# The output image should be a 1x1x10x10 tensor of integers between 0 and 255\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def dilate(image, kernel_size, dilation_rate):\n",
    "    # Check if input is a 4D tensor (batched image)\n",
    "    if len(image.shape) != 4:\n",
    "        raise ValueError(\"Input image should be a 4D tensor\")\n",
    "\n",
    "    # Expand the input tensor using unfold\n",
    "    unfolded_image = F.unfold(image, kernel_size, padding=dilation_rate * (kernel_size[0] - 1), stride=1)\n",
    "\n",
    "    # Create a tensor to store the dilated image\n",
    "    dilated_image = torch.zeros_like(image)\n",
    "\n",
    "    # Apply pointwise maximum operations to combine the expanded elements with the original ones\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            dilated_image[i, j] = torch.max(unfolded_image[i, j, :, :], image[i, j])\n",
    "\n",
    "    return dilated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to : https://stackoverflow.com/questions/56235733/is-there-a-tensor-operation-or-function-in-pytorch-that-works-like-cv2-dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.array([ [0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0],\n",
    "                [0, 1, 1, 0, 0],\n",
    "                [0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0] ], dtype=np.int8)\n",
    "kernel_el = np.array([ [0, 1, 0],\n",
    "                    [1, 1, 1],\n",
    "                    [0, 1, 0] ], dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [1., 0., 1., 0., 0.],\n",
      "          [1., 1., 1., 1., 0.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [0., 0., 0., 1., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "im = np.array([ [0, -10, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0],\n",
    "                [0, 1, 1, 0, 0],\n",
    "                [0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0] ], dtype=np.int8)\n",
    "kernel_el = np.array([ [0, 1, 0],\n",
    "                    [1, 1, 1],\n",
    "                    [0, 1, 0] ], dtype=np.int8)\n",
    "im_tensor = torch.Tensor(np.expand_dims(np.expand_dims(im, 0), 0)) # size:(1, 1, 5, 5)\n",
    "kernel_tensor = torch.Tensor(np.expand_dims(np.expand_dims(kernel_el, 0), 0)) # size: (1, 1, 3, 3)\n",
    "torch_result = torch.clamp(torch.nn.functional.conv2d(im_tensor, kernel_tensor, padding=(1, 1)), 0, 1)\n",
    "print(torch_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 5, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.expand_dims(im, 0), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-10.,  -9., -10.,   0.,   0.],\n",
       "          [  1.,  -8.,   2.,   0.,   0.],\n",
       "          [  1.,   3.,   2.,   2.,   0.],\n",
       "          [  0.,   1.,   2.,   1.,   1.],\n",
       "          [  0.,   0.,   0.,   1.,   0.]]]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.conv2d(im_tensor, kernel_tensor, padding=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tensor = torch.tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "mask = torch.tensor([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.bool)\n",
    "\n",
    "masked_tensor = torch.masked_fill(tensor, mask, 0)\n",
    "# masked_tensor = torch.masked_fill(tensor, ~mask, 0)\n",
    "\n",
    "print(masked_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 1, 1], [0, 7, 0], [3, 4, 5]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [1, 0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "one_hot = torch.nn.functional.one_hot(tensor)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0],\n",
      "         [1, 0, 1],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [1, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 1, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 1, 0],\n",
      "         [0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "# Change one_hot shape from (H, W, C) to (C, H, W)\n",
    "one_hot = one_hot.permute(2, 0, 1)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [0, 7, 0],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from one-hot encoding to label index\n",
    "torch.argmax(one_hot, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, -6)\n",
      "(-6, 5)\n",
      "tensor :\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "torch.Size([20, 20])\n",
      "one_hot_tensor :\n",
      "tensor([[[1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0],\n",
      "         [1, 0, 0, 0]]])\n",
      "torch.Size([20, 20, 4])\n",
      "one_hot_tensor :\n",
      "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]])\n",
      "torch.Size([4, 20, 20])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# tensor = torch.tensor([[0,0,0,0,0],[0,0,0,3,0],[0,0,0,0,0],[0,2,0,0,0],[0,0,0,0,0]]).to(torch.long)\n",
    "i = 20\n",
    "tensor = torch.zeros((i,i)).to(torch.long)\n",
    "shift = 5\n",
    "tensor[shift+1, -1 - shift+1] = 3\n",
    "print((shift + 10, -1 - shift))\n",
    "tensor[-1 - shift, shift] = 2\n",
    "print((-1 - shift, shift))\n",
    "# tensor = torch.tensor([[1,1,1,1,1],[1,0,2,0,1],[1,2,2,2,1],[1,0,2,0,1],[1,1,1,1,1]]).to(torch.long)\n",
    "# tensor = torch.tensor([[0,0,0,0,0],[0,0,2,0,0],[0,2,2,2,0],[0,0,2,0,0],[0,0,0,0,0]]).to(torch.long)\n",
    "print('tensor :')\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "\n",
    "one_hot_tensor = torch.nn.functional.one_hot(tensor)\n",
    "print('one_hot_tensor :')\n",
    "print(one_hot_tensor)\n",
    "print(one_hot_tensor.shape)\n",
    "\n",
    "one_hot_tensor = one_hot_tensor.permute(2, 0, 1)\n",
    "print('one_hot_tensor :')\n",
    "print(one_hot_tensor)\n",
    "print(one_hot_tensor.shape)\n",
    "print(one_hot_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel element :\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 0]])\n",
      "torch.Size([3, 3])\n",
      "kernel :\n",
      "tensor([[[[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0],\n",
      "          [0, 0, 0],\n",
      "          [0, 0, 0]]]])\n",
      "torch.Size([4, 4, 3, 3])\n",
      "kernel :\n",
      "tensor([[[[  0,   0,   0],\n",
      "          [  0,   1,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "        [[[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   1,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]]],\n",
      "\n",
      "\n",
      "        [[[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0, -10,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   1,   0],\n",
      "          [  1, 100,   1],\n",
      "          [  0,   1,   0]],\n",
      "\n",
      "         [[  0, -10,   0],\n",
      "          [-10, -10, -10],\n",
      "          [  0, -10,   0]]],\n",
      "\n",
      "\n",
      "        [[[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0, -10,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0, -10,   0],\n",
      "          [-10, -10, -10],\n",
      "          [  0, -10,   0]],\n",
      "\n",
      "         [[  0,   1,   0],\n",
      "          [  1, 100,   1],\n",
      "          [  0,   1,   0]]]])\n",
      "torch.Size([4, 4, 3, 3])\n",
      "torch.int64\n",
      "cond dtype :\n",
      "torch.int64\n",
      "one_hot_tensor after convolution :\n",
      "tensor([[[  1,   1,   1,  ...,   1,   1,   1],\n",
      "         [  1,   1,   1,  ...,   1,   1,   1],\n",
      "         [  1,   1,   1,  ...,   1,   1,   1],\n",
      "         ...,\n",
      "         [  1,   1,   1,  ...,   1,   1,   1],\n",
      "         [  1,   1,   1,  ...,   1,   1,   1],\n",
      "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[  2, 102, 103,  ..., -40, -40, -30],\n",
      "         [102, 104, 104,  ..., -50, -50, -40],\n",
      "         [103, 104, 104,  ..., -50, -50, -40],\n",
      "         ...,\n",
      "         [103, 104, 104,  ..., -50, -50, -40],\n",
      "         [103, 104, 104,  ..., -50, -50, -40],\n",
      "         [102, 103, 103,  ..., -40, -40, -30]],\n",
      "\n",
      "        [[-20, -30, -40,  ..., 103, 103, 102],\n",
      "         [-30, -50, -50,  ..., 104, 104, 103],\n",
      "         [-40, -50, -50,  ..., 104, 104, 103],\n",
      "         ...,\n",
      "         [-40, -50, -50,  ..., 104, 104, 103],\n",
      "         [-40, -50, -50,  ..., 104, 104, 103],\n",
      "         [-30, -40, -40,  ..., 103, 103, 102]]])\n",
      "torch.Size([4, 20, 20])\n",
      "one_hot_tensor after clamping :\n",
      "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1]]])\n",
      "torch.Size([4, 20, 20])\n",
      "tensor (one_hot_tensor after argmax) :\n",
      "tensor([[2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3]])\n",
      "torch.Size([20, 20])\n",
      "[[2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efc8e6483d0>"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# one_hot_tensor = one_hot_tensor.unsqueeze(0)\n",
    "\n",
    "# Create a kernel such that the output of the convolution is the same as the input one_hot_tensor\n",
    "kernel_el = torch.tensor([[0,0,0],[0,1,0],[0,0,0]]).to(torch.long)\n",
    "print('kernel element :')\n",
    "print(kernel_el)\n",
    "print(kernel_el.shape)\n",
    "\n",
    "# Create a kernel with size (C, C, H, W) where C is the number of classes, H, W are the kernel size and each element of [C,C,:] is the kernel_el\n",
    "kernel = torch.zeros((one_hot_tensor.shape[0], one_hot_tensor.shape[0], kernel_el.shape[0], kernel_el.shape[1])).to(torch.long)\n",
    "print('kernel :')\n",
    "print(kernel)\n",
    "print(kernel.shape)\n",
    "\n",
    "# Fill the kernel with the kernel_el\n",
    "for i in range(kernel.shape[0]):\n",
    "    for j in range(kernel.shape[1]):\n",
    "        if i == j:\n",
    "            kernel[i, j] = kernel_el\n",
    "        else:\n",
    "            kernel[i, j] = torch.zeros_like(kernel_el)\n",
    "\n",
    "kernel[2,2] = torch.tensor([[0,1,0],[1,100,1],[0,1,0]]).to(torch.long) # kernel for class 2, its the kernel for dilation\n",
    "kernel[2,1] = torch.tensor([[0,0,0],[0,-10,0],[0,0,0]]).to(torch.long) # kernel for class 2, its a negative dilation such that if class 1 is in the neighborhood, the result will be 0 and not 1, thus class 1 act as an obstacle\n",
    "kernel[2,3] = torch.tensor([[0,-10,0],[-10,-10,-10],[0,-10,0]]).to(torch.long) # kernel for class 2, its a negative dilation such that if class 3 is in the neighborhood, the result will be 0 and not 1, thus class 3 act as an obstacle\n",
    "\n",
    "kernel[3,3] = torch.tensor([[0,1,0],[1,100,1],[0,1,0]]).to(torch.long) # kernel for class 3, its the kernel for dilation\n",
    "kernel[3,1] = torch.tensor([[0,0,0],[0,-10,0],[0,0,0]]).to(torch.long) # kernel for class 3, its a negative dilation such that if class 1 is in the neighborhood, the result will be 0 and not 1, thus class 1 act as an obstacle\n",
    "kernel[3,2] = torch.tensor([[0,-10,0],[-10,-10,-10],[0,-10,0]]).to(torch.long) # kernel for class 3, its a negative dilation such that if class 2 is in the neighborhood, the result will be 0 and not 1, thus class 2 act as an obstacle\n",
    "\n",
    "print('kernel :')\n",
    "print(kernel)\n",
    "print(kernel.shape)\n",
    "print(kernel.dtype)\n",
    "\n",
    "# Convolve the one_hot_tensor with the kernel\n",
    "print('cond dtype :')\n",
    "print(torch.nn.functional.conv2d(one_hot_tensor, kernel, padding='same').dtype)\n",
    "one_hot_tensor = torch.nn.functional.conv2d(one_hot_tensor, kernel, padding='same')\n",
    "print('one_hot_tensor after convolution :')\n",
    "print(one_hot_tensor)\n",
    "print(one_hot_tensor.shape)\n",
    "\n",
    "print('one_hot_tensor after clamping :')\n",
    "one_hot_tensor = torch.clamp(one_hot_tensor, 0, 1)\n",
    "print(one_hot_tensor)\n",
    "print(one_hot_tensor.shape)\n",
    "\n",
    "one_hot_tensor_copy = one_hot_tensor.clone()\n",
    "\n",
    "# Set first channel to zero to not be taken into account by the argmax\n",
    "one_hot_tensor_copy[0] = torch.zeros_like(one_hot_tensor_copy[0])\n",
    "\n",
    "# from one-hot encoding to label index\n",
    "tensor = torch.argmax(one_hot_tensor_copy, dim=0)\n",
    "print('tensor (one_hot_tensor after argmax) :')\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "\n",
    "palette = [[0, 0, 0], [255, 255, 255], [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0], [255, 0, 255], [0, 255, 255], [128, 0, 0], [0, 128, 0], [0, 0, 128], [64, 64, 64], [128, 128, 0], [128, 0, 128], [0, 128, 128], [255, 128, 0], [192, 192, 192], [128, 128, 128]]\n",
    "\n",
    "tensor = tensor.squeeze()\n",
    "\n",
    "# Assert the tensor shape is 2D\n",
    "assert tensor.dim() == 2\n",
    "\n",
    "# from tensor to numpy array uint8\n",
    "img = tensor.cpu().numpy()\n",
    "img = np.uint8(img)\n",
    "print(img)\n",
    "img = Image.fromarray(img).convert('P')\n",
    "img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "\n",
    "plt.imshow(np.array(img.convert('RGB')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 3 3 3]\n",
      " [0 0 0 ... 0 3 0]\n",
      " ...\n",
      " [0 2 0 ... 0 0 0]\n",
      " [2 2 2 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efcad8a46d0>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "palette = [[0, 0, 0], [255, 255, 255], [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0], [255, 0, 255], [0, 255, 255], [128, 0, 0], [0, 128, 0], [0, 0, 128], [64, 64, 64], [128, 128, 0], [128, 0, 128], [0, 128, 128], [255, 128, 0], [192, 192, 192], [128, 128, 128]]\n",
    "\n",
    "tensor = tensor.squeeze()\n",
    "\n",
    "# Assert the tensor shape is 2D\n",
    "assert tensor.dim() == 2\n",
    "\n",
    "# from tensor to numpy array uint8\n",
    "img = tensor.cpu().numpy()\n",
    "img = np.uint8(img)\n",
    "print(img)\n",
    "img = Image.fromarray(img).convert('P')\n",
    "img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "\n",
    "plt.imshow(np.array(img.convert('RGB')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsegTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
