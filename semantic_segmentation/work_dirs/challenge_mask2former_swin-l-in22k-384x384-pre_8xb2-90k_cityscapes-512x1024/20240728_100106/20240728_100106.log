2024/07/28 10:01:07 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1568644196
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: None
    GCC: gcc (GCC) 8.3.1 20191121 (Red Hat 8.3.1-5)
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.10.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1568644196
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2024/07/28 10:01:07 - mmengine - INFO - Config:
ann_dir = 'Labels'
auto_scale_lr = dict(base_batch_size=2, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    1080,
    1920,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.10.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.11.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.12.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.13.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.14.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.15.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.16.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.17.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.6.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.7.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.8.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.9.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        1080,
        1920,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '../Dataset'
dataset_type = 'SoccerNet'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=10935,
        max_keep_ckpts=2,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=135, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(draw=True, interval=100, type='SegVisualizationHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    18,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_dir = 'Images'
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
    2.0,
]
iters = 10935
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            18,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=192,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_large_patch4_window12_384_22k_20220412-6580f57d.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            6,
            12,
            24,
            48,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        pretrain_img_size=384,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=12,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            1080,
            1920,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            192,
            384,
            768,
            1536,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=4,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 4
optim_wrapper = dict(
    accumulative_counts=2,
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.10.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.11.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.12.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.13.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.14.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.15.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.16.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.17.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.6.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.7.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.8.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.9.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=10935,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_large_patch4_window12_384_22k_20220412-6580f57d.pth'
resume = False
scale = (
    1920,
    1080,
)
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='splits/challenge.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='../Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1920,
                1080,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
train_cfg = dict(
    max_iters=10935, type='IterBasedTrainLoop', val_interval=10935)
train_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='splits/challengeTrain.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='../Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                keep_ratio=True,
                ratio_range=(
                    0.5,
                    2.0,
                ),
                scale=(
                    1920,
                    1080,
                ),
                type='RandomResize'),
            dict(
                cat_max_ratio=0.75,
                crop_size=(
                    1080,
                    1920,
                ),
                type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            1920,
            1080,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        1080,
        1920,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=2.0, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file='splits/challenge.txt',
        data_prefix=dict(img_path='Images', seg_map_path='Labels'),
        data_root='../Dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1920,
                1080,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='SoccerNet'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
val_interval = 10935
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1920,
        1080,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024'

2024/07/28 10:01:11 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2024/07/28 10:01:11 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
2024/07/28 10:01:11 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:12 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr=1e-05
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:weight_decay=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr_mult=0.1
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:decay_mult=0.0
2024/07/28 10:01:13 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2024/07/28 10:01:14 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2024/07/28 10:01:15 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2024/07/28 10:01:15 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([192, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table - torch.Size([529, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([1536, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([529, 48]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([4608, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([4608]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([1536, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([6144, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([6144]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([1536, 6144]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([529, 48]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([4608, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([4608]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([1536, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([6144, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([6144]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([1536, 6144]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 1536, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 768, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 192, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([5, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2024/07/28 10:01:17 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/07/28 10:01:17 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/07/28 10:01:17 - mmengine - INFO - Checkpoints will be saved to /scratch/users/vgaspar/semantic_segmentation/work_dirs/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.
2024/07/28 10:04:22 - mmengine - INFO - Iter(train) [  135/10935]  base_lr: 9.8896e-05 lr: 9.8896e-06  eta: 4:05:43  time: 1.3422  data_time: 0.0099  memory: 30260  loss: 39.5300  decode.loss_cls: 0.2660  decode.loss_mask: 0.9314  decode.loss_dice: 2.6900  decode.d0.loss_cls: 2.8383  decode.d0.loss_mask: 0.8218  decode.d0.loss_dice: 2.7206  decode.d1.loss_cls: 0.1268  decode.d1.loss_mask: 0.8771  decode.d1.loss_dice: 2.5873  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.9198  decode.d2.loss_dice: 2.5859  decode.d3.loss_cls: 0.0817  decode.d3.loss_mask: 0.9297  decode.d3.loss_dice: 2.5953  decode.d4.loss_cls: 0.0994  decode.d4.loss_mask: 0.9094  decode.d4.loss_dice: 2.5724  decode.d5.loss_cls: 0.1202  decode.d5.loss_mask: 0.9189  decode.d5.loss_dice: 2.6088  decode.d6.loss_cls: 0.1379  decode.d6.loss_mask: 0.9180  decode.d6.loss_dice: 2.6071  decode.d7.loss_cls: 0.1708  decode.d7.loss_mask: 0.9574  decode.d7.loss_dice: 2.6287  decode.d8.loss_cls: 0.2099  decode.d8.loss_mask: 0.9661  decode.d8.loss_dice: 2.6643  grad_norm: 455.6848
2024/07/28 10:07:23 - mmengine - INFO - Iter(train) [  270/10935]  base_lr: 9.7783e-05 lr: 9.7783e-06  eta: 4:00:51  time: 1.3440  data_time: 0.0104  memory: 25124  loss: 23.5614  decode.loss_cls: 0.0531  decode.loss_mask: 0.5179  decode.loss_dice: 1.5307  decode.d0.loss_cls: 2.6609  decode.d0.loss_mask: 0.4277  decode.d0.loss_dice: 1.6322  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.4762  decode.d1.loss_dice: 1.5378  decode.d2.loss_cls: 0.0587  decode.d2.loss_mask: 0.5342  decode.d2.loss_dice: 1.5382  decode.d3.loss_cls: 0.0669  decode.d3.loss_mask: 0.5118  decode.d3.loss_dice: 1.5449  decode.d4.loss_cls: 0.0355  decode.d4.loss_mask: 0.5187  decode.d4.loss_dice: 1.5248  decode.d5.loss_cls: 0.0343  decode.d5.loss_mask: 0.5102  decode.d5.loss_dice: 1.5324  decode.d6.loss_cls: 0.0386  decode.d6.loss_mask: 0.5017  decode.d6.loss_dice: 1.5337  decode.d7.loss_cls: 0.0415  decode.d7.loss_mask: 0.5110  decode.d7.loss_dice: 1.5021  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.5159  decode.d8.loss_dice: 1.5469  grad_norm: 184.1386
2024/07/28 10:10:25 - mmengine - INFO - Iter(train) [  405/10935]  base_lr: 9.6668e-05 lr: 9.6668e-06  eta: 3:57:09  time: 1.3424  data_time: 0.0098  memory: 25124  loss: 20.4354  decode.loss_cls: 0.0536  decode.loss_mask: 0.4133  decode.loss_dice: 1.3855  decode.d0.loss_cls: 2.4430  decode.d0.loss_mask: 0.4174  decode.d0.loss_dice: 1.2795  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.4609  decode.d1.loss_dice: 1.2686  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.4883  decode.d2.loss_dice: 1.2547  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.4886  decode.d3.loss_dice: 1.2254  decode.d4.loss_cls: 0.0611  decode.d4.loss_mask: 0.4909  decode.d4.loss_dice: 1.2565  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.4839  decode.d5.loss_dice: 1.2735  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.4781  decode.d6.loss_dice: 1.2662  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.4712  decode.d7.loss_dice: 1.2946  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.4526  decode.d8.loss_dice: 1.3026  grad_norm: 324.5830
2024/07/28 10:13:26 - mmengine - INFO - Iter(train) [  540/10935]  base_lr: 9.5552e-05 lr: 9.5552e-06  eta: 3:53:50  time: 1.3449  data_time: 0.0099  memory: 25124  loss: 13.7980  decode.loss_cls: 0.0195  decode.loss_mask: 0.1998  decode.loss_dice: 0.9559  decode.d0.loss_cls: 2.1925  decode.d0.loss_mask: 0.1858  decode.d0.loss_dice: 1.0020  decode.d1.loss_cls: 0.0374  decode.d1.loss_mask: 0.1952  decode.d1.loss_dice: 0.8893  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.1985  decode.d2.loss_dice: 0.9633  decode.d3.loss_cls: 0.0204  decode.d3.loss_mask: 0.1996  decode.d3.loss_dice: 0.8522  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.1987  decode.d4.loss_dice: 1.0046  decode.d5.loss_cls: 0.0161  decode.d5.loss_mask: 0.1917  decode.d5.loss_dice: 0.9297  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.1964  decode.d6.loss_dice: 0.9126  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.2025  decode.d7.loss_dice: 0.9892  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.1969  decode.d8.loss_dice: 0.9564  grad_norm: 172.8824
2024/07/28 10:16:28 - mmengine - INFO - Iter(train) [  675/10935]  base_lr: 9.4435e-05 lr: 9.4435e-06  eta: 3:50:35  time: 1.3432  data_time: 0.0103  memory: 25124  loss: 16.5780  decode.loss_cls: 0.0365  decode.loss_mask: 0.4006  decode.loss_dice: 1.0414  decode.d0.loss_cls: 1.9394  decode.d0.loss_mask: 0.3746  decode.d0.loss_dice: 1.0541  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.3975  decode.d1.loss_dice: 1.0200  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.4087  decode.d2.loss_dice: 1.0073  decode.d3.loss_cls: 0.0351  decode.d3.loss_mask: 0.4153  decode.d3.loss_dice: 1.0207  decode.d4.loss_cls: 0.0270  decode.d4.loss_mask: 0.4160  decode.d4.loss_dice: 1.0020  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.4195  decode.d5.loss_dice: 1.0276  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.4158  decode.d6.loss_dice: 1.0378  decode.d7.loss_cls: 0.0262  decode.d7.loss_mask: 0.4316  decode.d7.loss_dice: 0.9971  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.4186  decode.d8.loss_dice: 1.0335  grad_norm: 189.1700
2024/07/28 10:19:29 - mmengine - INFO - Iter(train) [  810/10935]  base_lr: 9.3316e-05 lr: 9.3316e-06  eta: 3:47:25  time: 1.3460  data_time: 0.0102  memory: 25124  loss: 11.4599  decode.loss_cls: 0.0171  decode.loss_mask: 0.1521  decode.loss_dice: 0.7977  decode.d0.loss_cls: 1.6955  decode.d0.loss_mask: 0.1304  decode.d0.loss_dice: 0.7895  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.1408  decode.d1.loss_dice: 0.7933  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.1365  decode.d2.loss_dice: 0.7761  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.1442  decode.d3.loss_dice: 0.8974  decode.d4.loss_cls: 0.0143  decode.d4.loss_mask: 0.1474  decode.d4.loss_dice: 0.8354  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.1421  decode.d5.loss_dice: 0.7958  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.1535  decode.d6.loss_dice: 0.8397  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.1553  decode.d7.loss_dice: 0.8335  decode.d8.loss_cls: 0.0147  decode.d8.loss_mask: 0.1595  decode.d8.loss_dice: 0.7808  grad_norm: 101.8278
2024/07/28 10:22:30 - mmengine - INFO - Iter(train) [  945/10935]  base_lr: 9.2195e-05 lr: 9.2195e-06  eta: 3:44:16  time: 1.3456  data_time: 0.0105  memory: 25124  loss: 11.5884  decode.loss_cls: 0.0144  decode.loss_mask: 0.1634  decode.loss_dice: 0.8430  decode.d0.loss_cls: 1.3859  decode.d0.loss_mask: 0.1463  decode.d0.loss_dice: 0.9230  decode.d1.loss_cls: 0.0453  decode.d1.loss_mask: 0.1562  decode.d1.loss_dice: 0.9126  decode.d2.loss_cls: 0.0262  decode.d2.loss_mask: 0.1666  decode.d2.loss_dice: 0.8638  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.1628  decode.d3.loss_dice: 0.7842  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.1667  decode.d4.loss_dice: 0.8283  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.1650  decode.d5.loss_dice: 0.8070  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.1694  decode.d6.loss_dice: 0.8698  decode.d7.loss_cls: 0.0132  decode.d7.loss_mask: 0.1698  decode.d7.loss_dice: 0.8515  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.1597  decode.d8.loss_dice: 0.7353  grad_norm: 66.1824
2024/07/28 10:23:44 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 10:25:32 - mmengine - INFO - Iter(train) [ 1080/10935]  base_lr: 9.1073e-05 lr: 9.1073e-06  eta: 3:41:12  time: 1.3451  data_time: 0.0101  memory: 25124  loss: 10.7582  decode.loss_cls: 0.0215  decode.loss_mask: 0.1478  decode.loss_dice: 0.8289  decode.d0.loss_cls: 1.2338  decode.d0.loss_mask: 0.1302  decode.d0.loss_dice: 0.8039  decode.d1.loss_cls: 0.0400  decode.d1.loss_mask: 0.1362  decode.d1.loss_dice: 0.7701  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.1360  decode.d2.loss_dice: 0.8169  decode.d3.loss_cls: 0.0291  decode.d3.loss_mask: 0.1299  decode.d3.loss_dice: 0.6913  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.1348  decode.d4.loss_dice: 0.7643  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.1411  decode.d5.loss_dice: 0.8232  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.1448  decode.d6.loss_dice: 0.8055  decode.d7.loss_cls: 0.0236  decode.d7.loss_mask: 0.1469  decode.d7.loss_dice: 0.8004  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.1535  decode.d8.loss_dice: 0.7643  grad_norm: 101.9824
2024/07/28 10:28:33 - mmengine - INFO - Iter(train) [ 1215/10935]  base_lr: 8.9949e-05 lr: 8.9949e-06  eta: 3:38:07  time: 1.3435  data_time: 0.0100  memory: 25124  loss: 9.8421  decode.loss_cls: 0.0069  decode.loss_mask: 0.1460  decode.loss_dice: 0.7344  decode.d0.loss_cls: 1.1245  decode.d0.loss_mask: 0.1427  decode.d0.loss_dice: 0.7733  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.1468  decode.d1.loss_dice: 0.7353  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.1480  decode.d2.loss_dice: 0.6411  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.1476  decode.d3.loss_dice: 0.7502  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.1510  decode.d4.loss_dice: 0.6253  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.1483  decode.d5.loss_dice: 0.7621  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.1396  decode.d6.loss_dice: 0.7175  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.1529  decode.d7.loss_dice: 0.6829  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.1465  decode.d8.loss_dice: 0.7556  grad_norm: 119.2626
2024/07/28 10:31:35 - mmengine - INFO - Iter(train) [ 1350/10935]  base_lr: 8.8824e-05 lr: 8.8824e-06  eta: 3:35:03  time: 1.3449  data_time: 0.0104  memory: 25124  loss: 12.2573  decode.loss_cls: 0.1700  decode.loss_mask: 0.1562  decode.loss_dice: 0.8408  decode.d0.loss_cls: 0.9260  decode.d0.loss_mask: 0.1474  decode.d0.loss_dice: 0.8086  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.1488  decode.d1.loss_dice: 0.7553  decode.d2.loss_cls: 0.1499  decode.d2.loss_mask: 0.1439  decode.d2.loss_dice: 0.7655  decode.d3.loss_cls: 0.2193  decode.d3.loss_mask: 0.1522  decode.d3.loss_dice: 0.9091  decode.d4.loss_cls: 0.2787  decode.d4.loss_mask: 0.1450  decode.d4.loss_dice: 0.7959  decode.d5.loss_cls: 0.2671  decode.d5.loss_mask: 0.1506  decode.d5.loss_dice: 0.8172  decode.d6.loss_cls: 0.1826  decode.d6.loss_mask: 0.1546  decode.d6.loss_dice: 0.7870  decode.d7.loss_cls: 0.1854  decode.d7.loss_mask: 0.1679  decode.d7.loss_dice: 0.7945  decode.d8.loss_cls: 0.1592  decode.d8.loss_mask: 0.1619  decode.d8.loss_dice: 0.7897  grad_norm: 93.7888
2024/07/28 10:34:36 - mmengine - INFO - Iter(train) [ 1485/10935]  base_lr: 8.7698e-05 lr: 8.7698e-06  eta: 3:31:59  time: 1.3463  data_time: 0.0101  memory: 25124  loss: 10.8722  decode.loss_cls: 0.0258  decode.loss_mask: 0.1727  decode.loss_dice: 0.7926  decode.d0.loss_cls: 0.7826  decode.d0.loss_mask: 0.1679  decode.d0.loss_dice: 0.8637  decode.d1.loss_cls: 0.0288  decode.d1.loss_mask: 0.1828  decode.d1.loss_dice: 0.8226  decode.d2.loss_cls: 0.0282  decode.d2.loss_mask: 0.1757  decode.d2.loss_dice: 0.8216  decode.d3.loss_cls: 0.0327  decode.d3.loss_mask: 0.1747  decode.d3.loss_dice: 0.7645  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 0.1718  decode.d4.loss_dice: 0.8705  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.1726  decode.d5.loss_dice: 0.7409  decode.d6.loss_cls: 0.0332  decode.d6.loss_mask: 0.1706  decode.d6.loss_dice: 0.7705  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.1743  decode.d7.loss_dice: 0.8477  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.1727  decode.d8.loss_dice: 0.7828  grad_norm: 119.6311
2024/07/28 10:37:38 - mmengine - INFO - Iter(train) [ 1620/10935]  base_lr: 8.6569e-05 lr: 8.6569e-06  eta: 3:28:56  time: 1.3444  data_time: 0.0102  memory: 25124  loss: 11.0941  decode.loss_cls: 0.0034  decode.loss_mask: 0.1672  decode.loss_dice: 0.8547  decode.d0.loss_cls: 0.6460  decode.d0.loss_mask: 0.1547  decode.d0.loss_dice: 0.8853  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.1686  decode.d1.loss_dice: 0.8803  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.1689  decode.d2.loss_dice: 0.8693  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.1735  decode.d3.loss_dice: 0.8732  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.1728  decode.d4.loss_dice: 0.8900  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.1731  decode.d5.loss_dice: 0.8698  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.1721  decode.d6.loss_dice: 0.8636  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.1675  decode.d7.loss_dice: 0.8725  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.1743  decode.d8.loss_dice: 0.8663  grad_norm: 217.7396
2024/07/28 10:40:39 - mmengine - INFO - Iter(train) [ 1755/10935]  base_lr: 8.5439e-05 lr: 8.5439e-06  eta: 3:25:53  time: 1.3429  data_time: 0.0098  memory: 25124  loss: 10.6811  decode.loss_cls: 0.0025  decode.loss_mask: 0.1190  decode.loss_dice: 0.8997  decode.d0.loss_cls: 0.5356  decode.d0.loss_mask: 0.1072  decode.d0.loss_dice: 0.8839  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.1162  decode.d1.loss_dice: 0.9261  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.1215  decode.d2.loss_dice: 0.8582  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.1129  decode.d3.loss_dice: 0.8592  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1130  decode.d4.loss_dice: 0.9322  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.1103  decode.d5.loss_dice: 0.8622  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.1111  decode.d6.loss_dice: 0.9542  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.1127  decode.d7.loss_dice: 0.9261  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.1194  decode.d8.loss_dice: 0.8757  grad_norm: 80.9731
2024/07/28 10:43:41 - mmengine - INFO - Iter(train) [ 1890/10935]  base_lr: 8.4308e-05 lr: 8.4308e-06  eta: 3:22:50  time: 1.3409  data_time: 0.0098  memory: 25124  loss: 10.0495  decode.loss_cls: 0.0062  decode.loss_mask: 0.0874  decode.loss_dice: 0.8248  decode.d0.loss_cls: 0.4621  decode.d0.loss_mask: 0.0867  decode.d0.loss_dice: 0.8286  decode.d1.loss_cls: 0.0088  decode.d1.loss_mask: 0.0936  decode.d1.loss_dice: 0.8889  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.0895  decode.d2.loss_dice: 0.8029  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.0894  decode.d3.loss_dice: 0.7635  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.0896  decode.d4.loss_dice: 0.8642  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.0843  decode.d5.loss_dice: 0.7223  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.0890  decode.d6.loss_dice: 0.9197  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.0909  decode.d7.loss_dice: 0.8421  decode.d8.loss_cls: 0.1567  decode.d8.loss_mask: 0.0914  decode.d8.loss_dice: 0.8994  grad_norm: 89.7692
2024/07/28 10:46:02 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 10:46:09 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 10:46:42 - mmengine - INFO - Iter(train) [ 2025/10935]  base_lr: 8.3174e-05 lr: 8.3174e-06  eta: 3:19:48  time: 1.3422  data_time: 0.0104  memory: 25124  loss: 6.3814  decode.loss_cls: 0.1150  decode.loss_mask: 0.0923  decode.loss_dice: 0.5866  decode.d0.loss_cls: 0.4088  decode.d0.loss_mask: 0.0864  decode.d0.loss_dice: 0.4644  decode.d1.loss_cls: 0.0118  decode.d1.loss_mask: 0.0852  decode.d1.loss_dice: 0.4856  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.0873  decode.d2.loss_dice: 0.4711  decode.d3.loss_cls: 0.0107  decode.d3.loss_mask: 0.0868  decode.d3.loss_dice: 0.5051  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.0892  decode.d4.loss_dice: 0.4998  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.0893  decode.d5.loss_dice: 0.4844  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.0866  decode.d6.loss_dice: 0.4638  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.0857  decode.d7.loss_dice: 0.4719  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.0879  decode.d8.loss_dice: 0.4757  grad_norm: 133.9848
2024/07/28 10:49:44 - mmengine - INFO - Iter(train) [ 2160/10935]  base_lr: 8.2039e-05 lr: 8.2039e-06  eta: 3:16:46  time: 1.3423  data_time: 0.0101  memory: 25124  loss: 7.2464  decode.loss_cls: 0.0030  decode.loss_mask: 0.0873  decode.loss_dice: 0.5403  decode.d0.loss_cls: 0.3533  decode.d0.loss_mask: 0.0850  decode.d0.loss_dice: 0.5974  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.0853  decode.d1.loss_dice: 0.6426  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.0921  decode.d2.loss_dice: 0.7036  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.0910  decode.d3.loss_dice: 0.6144  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.0909  decode.d4.loss_dice: 0.5912  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.0934  decode.d5.loss_dice: 0.6393  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.0907  decode.d6.loss_dice: 0.5644  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.0898  decode.d7.loss_dice: 0.5358  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.0906  decode.d8.loss_dice: 0.5428  grad_norm: 100.2110
2024/07/28 10:52:45 - mmengine - INFO - Iter(train) [ 2295/10935]  base_lr: 8.0902e-05 lr: 8.0902e-06  eta: 3:13:43  time: 1.3410  data_time: 0.0097  memory: 25124  loss: 5.2263  decode.loss_cls: 0.0045  decode.loss_mask: 0.0671  decode.loss_dice: 0.4322  decode.d0.loss_cls: 0.3210  decode.d0.loss_mask: 0.0630  decode.d0.loss_dice: 0.4120  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.0667  decode.d1.loss_dice: 0.4136  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.0623  decode.d2.loss_dice: 0.4105  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.0656  decode.d3.loss_dice: 0.4217  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.0644  decode.d4.loss_dice: 0.4410  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.0673  decode.d5.loss_dice: 0.4337  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.0644  decode.d6.loss_dice: 0.4206  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.0647  decode.d7.loss_dice: 0.3838  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.0632  decode.d8.loss_dice: 0.4643  grad_norm: 73.3652
2024/07/28 10:55:46 - mmengine - INFO - Iter(train) [ 2430/10935]  base_lr: 7.9764e-05 lr: 7.9764e-06  eta: 3:10:41  time: 1.3407  data_time: 0.0098  memory: 25124  loss: 8.6952  decode.loss_cls: 0.0136  decode.loss_mask: 0.0995  decode.loss_dice: 0.6839  decode.d0.loss_cls: 0.2680  decode.d0.loss_mask: 0.0955  decode.d0.loss_dice: 0.7106  decode.d1.loss_cls: 0.0910  decode.d1.loss_mask: 0.0979  decode.d1.loss_dice: 0.7601  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.1011  decode.d2.loss_dice: 0.6981  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.1042  decode.d3.loss_dice: 0.8046  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.1069  decode.d4.loss_dice: 0.7123  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.1004  decode.d5.loss_dice: 0.6611  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.1057  decode.d6.loss_dice: 0.7033  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.1034  decode.d7.loss_dice: 0.6837  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.1046  decode.d8.loss_dice: 0.7221  grad_norm: 91.4179
2024/07/28 10:58:48 - mmengine - INFO - Iter(train) [ 2565/10935]  base_lr: 7.8623e-05 lr: 7.8623e-06  eta: 3:07:39  time: 1.3444  data_time: 0.0101  memory: 25124  loss: 9.5463  decode.loss_cls: 0.0013  decode.loss_mask: 0.1161  decode.loss_dice: 0.8720  decode.d0.loss_cls: 0.2226  decode.d0.loss_mask: 0.1078  decode.d0.loss_dice: 0.9062  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.1107  decode.d1.loss_dice: 0.7848  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.1097  decode.d2.loss_dice: 0.7944  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.1098  decode.d3.loss_dice: 0.7949  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.1032  decode.d4.loss_dice: 0.8142  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.1061  decode.d5.loss_dice: 0.7707  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.1072  decode.d6.loss_dice: 0.7990  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.1141  decode.d7.loss_dice: 0.8141  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.1136  decode.d8.loss_dice: 0.8588  grad_norm: 169.0293
2024/07/28 11:01:50 - mmengine - INFO - Iter(train) [ 2700/10935]  base_lr: 7.7481e-05 lr: 7.7481e-06  eta: 3:04:37  time: 1.3445  data_time: 0.0104  memory: 25124  loss: 8.2748  decode.loss_cls: 0.0214  decode.loss_mask: 0.1597  decode.loss_dice: 0.6634  decode.d0.loss_cls: 0.2043  decode.d0.loss_mask: 0.1457  decode.d0.loss_dice: 0.6386  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.1513  decode.d1.loss_dice: 0.6086  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.1561  decode.d2.loss_dice: 0.6580  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.1616  decode.d3.loss_dice: 0.6513  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.1603  decode.d4.loss_dice: 0.6525  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.1581  decode.d5.loss_dice: 0.6438  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.1589  decode.d6.loss_dice: 0.6358  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.1659  decode.d7.loss_dice: 0.6373  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.1656  decode.d8.loss_dice: 0.6123  grad_norm: 79.6650
2024/07/28 11:04:51 - mmengine - INFO - Iter(train) [ 2835/10935]  base_lr: 7.6337e-05 lr: 7.6337e-06  eta: 3:01:35  time: 1.3460  data_time: 0.0101  memory: 25124  loss: 7.9240  decode.loss_cls: 0.0006  decode.loss_mask: 0.1773  decode.loss_dice: 0.5759  decode.d0.loss_cls: 0.1832  decode.d0.loss_mask: 0.1758  decode.d0.loss_dice: 0.6255  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.1820  decode.d1.loss_dice: 0.6252  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.1768  decode.d2.loss_dice: 0.5688  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.1731  decode.d3.loss_dice: 0.5937  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.1795  decode.d4.loss_dice: 0.6464  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.1795  decode.d5.loss_dice: 0.5812  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.1832  decode.d6.loss_dice: 0.5819  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.1805  decode.d7.loss_dice: 0.5825  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.1841  decode.d8.loss_dice: 0.5435  grad_norm: 190.8392
2024/07/28 11:07:53 - mmengine - INFO - Iter(train) [ 2970/10935]  base_lr: 7.5191e-05 lr: 7.5191e-06  eta: 2:58:34  time: 1.3451  data_time: 0.0104  memory: 25124  loss: 10.8465  decode.loss_cls: 0.0015  decode.loss_mask: 0.1327  decode.loss_dice: 0.8726  decode.d0.loss_cls: 0.1670  decode.d0.loss_mask: 0.1338  decode.d0.loss_dice: 0.9032  decode.d1.loss_cls: 0.1094  decode.d1.loss_mask: 0.1325  decode.d1.loss_dice: 0.8369  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 0.1313  decode.d2.loss_dice: 0.8682  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.1342  decode.d3.loss_dice: 0.9544  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.1305  decode.d4.loss_dice: 0.9179  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.1307  decode.d5.loss_dice: 0.9463  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.1376  decode.d6.loss_dice: 0.8716  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.1349  decode.d7.loss_dice: 0.9202  decode.d8.loss_cls: 0.0239  decode.d8.loss_mask: 0.1346  decode.d8.loss_dice: 0.9266  grad_norm: 141.2435
2024/07/28 11:08:33 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 11:10:54 - mmengine - INFO - Iter(train) [ 3105/10935]  base_lr: 7.4043e-05 lr: 7.4043e-06  eta: 2:55:32  time: 1.3437  data_time: 0.0103  memory: 25124  loss: 7.8805  decode.loss_cls: 0.0034  decode.loss_mask: 0.1043  decode.loss_dice: 0.6269  decode.d0.loss_cls: 0.1658  decode.d0.loss_mask: 0.1053  decode.d0.loss_dice: 0.6106  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.1024  decode.d1.loss_dice: 0.6353  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.1051  decode.d2.loss_dice: 0.6238  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.1020  decode.d3.loss_dice: 0.6667  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.1028  decode.d4.loss_dice: 0.6452  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.1022  decode.d5.loss_dice: 0.6955  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.1008  decode.d6.loss_dice: 0.6662  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.1000  decode.d7.loss_dice: 0.6228  decode.d8.loss_cls: 0.1959  decode.d8.loss_mask: 0.1003  decode.d8.loss_dice: 0.6461  grad_norm: 97.5931
2024/07/28 11:13:55 - mmengine - INFO - Iter(train) [ 3240/10935]  base_lr: 7.2893e-05 lr: 7.2893e-06  eta: 2:52:30  time: 1.3418  data_time: 0.0101  memory: 25124  loss: 5.1715  decode.loss_cls: 0.0007  decode.loss_mask: 0.0644  decode.loss_dice: 0.4071  decode.d0.loss_cls: 0.1441  decode.d0.loss_mask: 0.0686  decode.d0.loss_dice: 0.4822  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.0702  decode.d1.loss_dice: 0.4541  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.0693  decode.d2.loss_dice: 0.4157  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.0653  decode.d3.loss_dice: 0.4509  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.0676  decode.d4.loss_dice: 0.4279  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.0646  decode.d5.loss_dice: 0.4424  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.0656  decode.d6.loss_dice: 0.3921  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0712  decode.d7.loss_dice: 0.4340  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0675  decode.d8.loss_dice: 0.4393  grad_norm: 46.5861
2024/07/28 11:16:57 - mmengine - INFO - Iter(train) [ 3375/10935]  base_lr: 7.1741e-05 lr: 7.1741e-06  eta: 2:49:28  time: 1.3438  data_time: 0.0101  memory: 25124  loss: 7.2316  decode.loss_cls: 0.0006  decode.loss_mask: 0.0909  decode.loss_dice: 0.5569  decode.d0.loss_cls: 0.1359  decode.d0.loss_mask: 0.0851  decode.d0.loss_dice: 0.6175  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.0881  decode.d1.loss_dice: 0.6255  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.0921  decode.d2.loss_dice: 0.6297  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.0920  decode.d3.loss_dice: 0.6624  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.0923  decode.d4.loss_dice: 0.6384  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.0869  decode.d5.loss_dice: 0.5673  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.0899  decode.d6.loss_dice: 0.6359  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0886  decode.d7.loss_dice: 0.6119  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.0932  decode.d8.loss_dice: 0.6391  grad_norm: 61.6326
2024/07/28 11:19:58 - mmengine - INFO - Iter(train) [ 3510/10935]  base_lr: 7.0587e-05 lr: 7.0587e-06  eta: 2:46:26  time: 1.3472  data_time: 0.0105  memory: 25124  loss: 6.1984  decode.loss_cls: 0.0095  decode.loss_mask: 0.0944  decode.loss_dice: 0.5258  decode.d0.loss_cls: 0.1321  decode.d0.loss_mask: 0.0926  decode.d0.loss_dice: 0.5063  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.0945  decode.d1.loss_dice: 0.5081  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.0943  decode.d2.loss_dice: 0.5002  decode.d3.loss_cls: 0.0485  decode.d3.loss_mask: 0.0927  decode.d3.loss_dice: 0.4390  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.0967  decode.d4.loss_dice: 0.4831  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.0929  decode.d5.loss_dice: 0.4850  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.0962  decode.d6.loss_dice: 0.5049  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.0887  decode.d7.loss_dice: 0.4862  decode.d8.loss_cls: 0.1063  decode.d8.loss_mask: 0.0942  decode.d8.loss_dice: 0.4183  grad_norm: 62.4751
2024/07/28 11:23:00 - mmengine - INFO - Iter(train) [ 3645/10935]  base_lr: 6.9431e-05 lr: 6.9431e-06  eta: 2:43:24  time: 1.3428  data_time: 0.0102  memory: 25124  loss: 7.6544  decode.loss_cls: 0.0010  decode.loss_mask: 0.0877  decode.loss_dice: 0.6529  decode.d0.loss_cls: 0.1363  decode.d0.loss_mask: 0.0874  decode.d0.loss_dice: 0.6427  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.0864  decode.d1.loss_dice: 0.6378  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.0869  decode.d2.loss_dice: 0.6408  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.0841  decode.d3.loss_dice: 0.6443  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.0853  decode.d4.loss_dice: 0.6732  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.0900  decode.d5.loss_dice: 0.7397  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.0876  decode.d6.loss_dice: 0.6742  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.0841  decode.d7.loss_dice: 0.6549  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.0851  decode.d8.loss_dice: 0.6753  grad_norm: 35.3323
2024/07/28 11:26:01 - mmengine - INFO - Iter(train) [ 3780/10935]  base_lr: 6.8273e-05 lr: 6.8273e-06  eta: 2:40:22  time: 1.3446  data_time: 0.0100  memory: 25124  loss: 5.8919  decode.loss_cls: 0.0032  decode.loss_mask: 0.1091  decode.loss_dice: 0.4585  decode.d0.loss_cls: 0.1303  decode.d0.loss_mask: 0.1145  decode.d0.loss_dice: 0.4299  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.1107  decode.d1.loss_dice: 0.4790  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.1111  decode.d2.loss_dice: 0.4586  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.1168  decode.d3.loss_dice: 0.4310  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.1106  decode.d4.loss_dice: 0.4608  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.1122  decode.d5.loss_dice: 0.4842  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.1106  decode.d6.loss_dice: 0.5008  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.1159  decode.d7.loss_dice: 0.4661  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.1122  decode.d8.loss_dice: 0.4537  grad_norm: 58.9542
2024/07/28 11:29:02 - mmengine - INFO - Iter(train) [ 3915/10935]  base_lr: 6.7112e-05 lr: 6.7112e-06  eta: 2:37:20  time: 1.3453  data_time: 0.0101  memory: 25124  loss: 7.5046  decode.loss_cls: 0.0036  decode.loss_mask: 0.0898  decode.loss_dice: 0.6084  decode.d0.loss_cls: 0.1228  decode.d0.loss_mask: 0.0860  decode.d0.loss_dice: 0.6019  decode.d1.loss_cls: 0.2259  decode.d1.loss_mask: 0.0876  decode.d1.loss_dice: 0.5963  decode.d2.loss_cls: 0.0895  decode.d2.loss_mask: 0.0939  decode.d2.loss_dice: 0.6087  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.0888  decode.d3.loss_dice: 0.5705  decode.d4.loss_cls: 0.0630  decode.d4.loss_mask: 0.0900  decode.d4.loss_dice: 0.5923  decode.d5.loss_cls: 0.0806  decode.d5.loss_mask: 0.0924  decode.d5.loss_dice: 0.6024  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.0920  decode.d6.loss_dice: 0.5807  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.0914  decode.d7.loss_dice: 0.5967  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.0883  decode.d8.loss_dice: 0.5607  grad_norm: 71.6908
2024/07/28 11:30:57 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 11:32:04 - mmengine - INFO - Iter(train) [ 4050/10935]  base_lr: 6.5950e-05 lr: 6.5950e-06  eta: 2:34:18  time: 1.3432  data_time: 0.0099  memory: 25124  loss: 5.3368  decode.loss_cls: 0.0004  decode.loss_mask: 0.0862  decode.loss_dice: 0.4495  decode.d0.loss_cls: 0.1194  decode.d0.loss_mask: 0.0812  decode.d0.loss_dice: 0.4091  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.0887  decode.d1.loss_dice: 0.4544  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.0844  decode.d2.loss_dice: 0.4349  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0879  decode.d3.loss_dice: 0.4486  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.0810  decode.d4.loss_dice: 0.4018  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0885  decode.d5.loss_dice: 0.4398  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.0845  decode.d6.loss_dice: 0.4319  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.0847  decode.d7.loss_dice: 0.4453  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.0869  decode.d8.loss_dice: 0.4427  grad_norm: 45.2115
2024/07/28 11:35:05 - mmengine - INFO - Iter(train) [ 4185/10935]  base_lr: 6.4785e-05 lr: 6.4785e-06  eta: 2:31:17  time: 1.3462  data_time: 0.0101  memory: 25124  loss: 5.6495  decode.loss_cls: 0.0009  decode.loss_mask: 0.0799  decode.loss_dice: 0.4988  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.0695  decode.d0.loss_dice: 0.4588  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.0784  decode.d1.loss_dice: 0.4821  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.0808  decode.d2.loss_dice: 0.5097  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.0796  decode.d3.loss_dice: 0.4775  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.0778  decode.d4.loss_dice: 0.4759  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.0779  decode.d5.loss_dice: 0.4659  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.0777  decode.d6.loss_dice: 0.4796  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.0748  decode.d7.loss_dice: 0.4498  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.0785  decode.d8.loss_dice: 0.4670  grad_norm: 80.7884
2024/07/28 11:38:07 - mmengine - INFO - Iter(train) [ 4320/10935]  base_lr: 6.3617e-05 lr: 6.3617e-06  eta: 2:28:15  time: 1.3447  data_time: 0.0102  memory: 25124  loss: 6.5802  decode.loss_cls: 0.0015  decode.loss_mask: 0.1010  decode.loss_dice: 0.6099  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.0982  decode.d0.loss_dice: 0.5011  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.1013  decode.d1.loss_dice: 0.5580  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.0984  decode.d2.loss_dice: 0.5432  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.1040  decode.d3.loss_dice: 0.5275  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.1026  decode.d4.loss_dice: 0.5439  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.0995  decode.d5.loss_dice: 0.4495  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.1050  decode.d6.loss_dice: 0.5351  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.1015  decode.d7.loss_dice: 0.4997  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.1033  decode.d8.loss_dice: 0.6556  grad_norm: 72.9732
2024/07/28 11:41:09 - mmengine - INFO - Iter(train) [ 4455/10935]  base_lr: 6.2448e-05 lr: 6.2448e-06  eta: 2:25:14  time: 1.3449  data_time: 0.0102  memory: 25124  loss: 8.0625  decode.loss_cls: 0.0009  decode.loss_mask: 0.0967  decode.loss_dice: 0.7297  decode.d0.loss_cls: 0.1087  decode.d0.loss_mask: 0.0966  decode.d0.loss_dice: 0.6975  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.0961  decode.d1.loss_dice: 0.6772  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.0929  decode.d2.loss_dice: 0.6548  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.0963  decode.d3.loss_dice: 0.7070  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.0980  decode.d4.loss_dice: 0.7290  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.0981  decode.d5.loss_dice: 0.7014  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.0980  decode.d6.loss_dice: 0.7199  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.0980  decode.d7.loss_dice: 0.6684  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.0960  decode.d8.loss_dice: 0.6935  grad_norm: 55.3640
2024/07/28 11:44:10 - mmengine - INFO - Iter(train) [ 4590/10935]  base_lr: 6.1276e-05 lr: 6.1276e-06  eta: 2:22:12  time: 1.3439  data_time: 0.0099  memory: 25124  loss: 8.7390  decode.loss_cls: 0.1624  decode.loss_mask: 0.1966  decode.loss_dice: 0.6049  decode.d0.loss_cls: 0.0891  decode.d0.loss_mask: 0.2039  decode.d0.loss_dice: 0.6833  decode.d1.loss_cls: 0.1089  decode.d1.loss_mask: 0.1861  decode.d1.loss_dice: 0.6182  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.1892  decode.d2.loss_dice: 0.5855  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.1975  decode.d3.loss_dice: 0.6096  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.1873  decode.d4.loss_dice: 0.6543  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.1964  decode.d5.loss_dice: 0.6283  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.6672  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.6420  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.1987  decode.d8.loss_dice: 0.6136  grad_norm: 66.2743
2024/07/28 11:47:11 - mmengine - INFO - Iter(train) [ 4725/10935]  base_lr: 6.0101e-05 lr: 6.0101e-06  eta: 2:19:10  time: 1.3448  data_time: 0.0102  memory: 25124  loss: 3.1232  decode.loss_cls: 0.0003  decode.loss_mask: 0.0512  decode.loss_dice: 0.2595  decode.d0.loss_cls: 0.1321  decode.d0.loss_mask: 0.0487  decode.d0.loss_dice: 0.2591  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.0539  decode.d1.loss_dice: 0.2620  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.0506  decode.d2.loss_dice: 0.2461  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0541  decode.d3.loss_dice: 0.2391  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0517  decode.d4.loss_dice: 0.2664  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.0498  decode.d5.loss_dice: 0.2260  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0511  decode.d6.loss_dice: 0.2378  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0489  decode.d7.loss_dice: 0.2213  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.0482  decode.d8.loss_dice: 0.2604  grad_norm: 38.0588
2024/07/28 11:50:13 - mmengine - INFO - Iter(train) [ 4860/10935]  base_lr: 5.8924e-05 lr: 5.8924e-06  eta: 2:16:09  time: 1.3454  data_time: 0.0103  memory: 25124  loss: 5.8756  decode.loss_cls: 0.0002  decode.loss_mask: 0.0891  decode.loss_dice: 0.5063  decode.d0.loss_cls: 0.0979  decode.d0.loss_mask: 0.0860  decode.d0.loss_dice: 0.4509  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.0887  decode.d1.loss_dice: 0.4545  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.0856  decode.d2.loss_dice: 0.4621  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0895  decode.d3.loss_dice: 0.5148  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.0912  decode.d4.loss_dice: 0.5108  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0862  decode.d5.loss_dice: 0.4857  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0917  decode.d6.loss_dice: 0.4836  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0900  decode.d7.loss_dice: 0.5314  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.0881  decode.d8.loss_dice: 0.4863  grad_norm: 35.7048
2024/07/28 11:53:14 - mmengine - INFO - Iter(train) [ 4995/10935]  base_lr: 5.7744e-05 lr: 5.7744e-06  eta: 2:13:07  time: 1.3452  data_time: 0.0101  memory: 25124  loss: 8.4817  decode.loss_cls: 0.0004  decode.loss_mask: 0.0949  decode.loss_dice: 0.6532  decode.d0.loss_cls: 0.0943  decode.d0.loss_mask: 0.0953  decode.d0.loss_dice: 0.5960  decode.d1.loss_cls: 0.1333  decode.d1.loss_mask: 0.0928  decode.d1.loss_dice: 0.6361  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.0909  decode.d2.loss_dice: 0.7038  decode.d3.loss_cls: 0.1332  decode.d3.loss_mask: 0.0943  decode.d3.loss_dice: 0.6670  decode.d4.loss_cls: 0.1071  decode.d4.loss_mask: 0.0955  decode.d4.loss_dice: 0.6828  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.0964  decode.d5.loss_dice: 0.6098  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.0932  decode.d6.loss_dice: 0.7642  decode.d7.loss_cls: 0.2625  decode.d7.loss_mask: 0.0979  decode.d7.loss_dice: 0.7242  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.0953  decode.d8.loss_dice: 0.6277  grad_norm: 143.0659
2024/07/28 11:53:21 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 11:56:16 - mmengine - INFO - Iter(train) [ 5130/10935]  base_lr: 5.6561e-05 lr: 5.6561e-06  eta: 2:10:06  time: 1.3437  data_time: 0.0100  memory: 25124  loss: 6.7444  decode.loss_cls: 0.0005  decode.loss_mask: 0.0808  decode.loss_dice: 0.6010  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.0787  decode.d0.loss_dice: 0.5543  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.0790  decode.d1.loss_dice: 0.5098  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.0790  decode.d2.loss_dice: 0.6248  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.0792  decode.d3.loss_dice: 0.6191  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.0832  decode.d4.loss_dice: 0.5890  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.0819  decode.d5.loss_dice: 0.5497  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0798  decode.d6.loss_dice: 0.5973  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.0821  decode.d7.loss_dice: 0.5859  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.0794  decode.d8.loss_dice: 0.6051  grad_norm: 94.1325
2024/07/28 11:59:17 - mmengine - INFO - Iter(train) [ 5265/10935]  base_lr: 5.5376e-05 lr: 5.5376e-06  eta: 2:07:04  time: 1.3432  data_time: 0.0099  memory: 25124  loss: 7.9072  decode.loss_cls: 0.0003  decode.loss_mask: 0.0958  decode.loss_dice: 0.6796  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.0930  decode.d0.loss_dice: 0.6668  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.0950  decode.d1.loss_dice: 0.6881  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.0949  decode.d2.loss_dice: 0.6810  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0960  decode.d3.loss_dice: 0.6732  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.0912  decode.d4.loss_dice: 0.6754  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.0959  decode.d5.loss_dice: 0.7050  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0975  decode.d6.loss_dice: 0.6987  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0948  decode.d7.loss_dice: 0.6903  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0949  decode.d8.loss_dice: 0.7186  grad_norm: 153.8252
2024/07/28 12:02:19 - mmengine - INFO - Iter(train) [ 5400/10935]  base_lr: 5.4188e-05 lr: 5.4188e-06  eta: 2:04:02  time: 1.3447  data_time: 0.0099  memory: 25124  loss: 4.6678  decode.loss_cls: 0.0012  decode.loss_mask: 0.0805  decode.loss_dice: 0.3831  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.0884  decode.d0.loss_dice: 0.3308  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.0858  decode.d1.loss_dice: 0.3917  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.0854  decode.d2.loss_dice: 0.3894  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0797  decode.d3.loss_dice: 0.3663  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.0860  decode.d4.loss_dice: 0.3817  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.0836  decode.d5.loss_dice: 0.3831  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.0822  decode.d6.loss_dice: 0.3649  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.0837  decode.d7.loss_dice: 0.3801  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.0839  decode.d8.loss_dice: 0.3641  grad_norm: 56.1790
2024/07/28 12:05:20 - mmengine - INFO - Iter(train) [ 5535/10935]  base_lr: 5.2997e-05 lr: 5.2997e-06  eta: 2:01:00  time: 1.3442  data_time: 0.0102  memory: 25124  loss: 6.3674  decode.loss_cls: 0.0081  decode.loss_mask: 0.0832  decode.loss_dice: 0.5264  decode.d0.loss_cls: 0.0780  decode.d0.loss_mask: 0.0869  decode.d0.loss_dice: 0.5376  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.0886  decode.d1.loss_dice: 0.5359  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.0846  decode.d2.loss_dice: 0.5432  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.0818  decode.d3.loss_dice: 0.5441  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.0825  decode.d4.loss_dice: 0.5720  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.0849  decode.d5.loss_dice: 0.5793  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.0827  decode.d6.loss_dice: 0.5391  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.0810  decode.d7.loss_dice: 0.4902  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.0811  decode.d8.loss_dice: 0.5217  grad_norm: 36.5994
2024/07/28 12:08:21 - mmengine - INFO - Iter(train) [ 5670/10935]  base_lr: 5.1803e-05 lr: 5.1803e-06  eta: 1:57:59  time: 1.3415  data_time: 0.0100  memory: 25124  loss: 5.3096  decode.loss_cls: 0.0004  decode.loss_mask: 0.0649  decode.loss_dice: 0.4202  decode.d0.loss_cls: 0.0839  decode.d0.loss_mask: 0.0645  decode.d0.loss_dice: 0.4610  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.0673  decode.d1.loss_dice: 0.4521  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.0697  decode.d2.loss_dice: 0.4276  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0687  decode.d3.loss_dice: 0.4676  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0708  decode.d4.loss_dice: 0.4637  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0681  decode.d5.loss_dice: 0.4547  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0679  decode.d6.loss_dice: 0.4737  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0679  decode.d7.loss_dice: 0.4547  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0662  decode.d8.loss_dice: 0.4628  grad_norm: 55.8963
2024/07/28 12:11:23 - mmengine - INFO - Iter(train) [ 5805/10935]  base_lr: 5.0606e-05 lr: 5.0606e-06  eta: 1:54:57  time: 1.3445  data_time: 0.0102  memory: 25124  loss: 5.6365  decode.loss_cls: 0.0002  decode.loss_mask: 0.1019  decode.loss_dice: 0.4683  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.1030  decode.d0.loss_dice: 0.4449  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.1014  decode.d1.loss_dice: 0.4334  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.1036  decode.d2.loss_dice: 0.4768  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.1012  decode.d3.loss_dice: 0.4600  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0992  decode.d4.loss_dice: 0.4662  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.1009  decode.d5.loss_dice: 0.4405  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.1054  decode.d6.loss_dice: 0.4501  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.1039  decode.d7.loss_dice: 0.4736  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.1005  decode.d8.loss_dice: 0.4289  grad_norm: 39.9537
2024/07/28 12:14:24 - mmengine - INFO - Iter(train) [ 5940/10935]  base_lr: 4.9406e-05 lr: 4.9406e-06  eta: 1:51:56  time: 1.3457  data_time: 0.0102  memory: 25124  loss: 4.4297  decode.loss_cls: 0.0011  decode.loss_mask: 0.0749  decode.loss_dice: 0.3579  decode.d0.loss_cls: 0.1104  decode.d0.loss_mask: 0.0729  decode.d0.loss_dice: 0.3540  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.0718  decode.d1.loss_dice: 0.3736  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.0702  decode.d2.loss_dice: 0.3639  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.0692  decode.d3.loss_dice: 0.3423  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.0686  decode.d4.loss_dice: 0.3486  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.0698  decode.d5.loss_dice: 0.3685  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0700  decode.d6.loss_dice: 0.3526  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.0695  decode.d7.loss_dice: 0.3804  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.0690  decode.d8.loss_dice: 0.3582  grad_norm: 71.0652
2024/07/28 12:15:45 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 12:17:25 - mmengine - INFO - Iter(train) [ 6075/10935]  base_lr: 4.8203e-05 lr: 4.8203e-06  eta: 1:48:54  time: 1.3424  data_time: 0.0104  memory: 25124  loss: 7.2209  decode.loss_cls: 0.0004  decode.loss_mask: 0.0921  decode.loss_dice: 0.5583  decode.d0.loss_cls: 0.1670  decode.d0.loss_mask: 0.0987  decode.d0.loss_dice: 0.6721  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.1007  decode.d1.loss_dice: 0.6625  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.0917  decode.d2.loss_dice: 0.6264  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.0954  decode.d3.loss_dice: 0.5943  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.0903  decode.d4.loss_dice: 0.5876  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0921  decode.d5.loss_dice: 0.5661  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0945  decode.d6.loss_dice: 0.6073  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.0961  decode.d7.loss_dice: 0.6306  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0924  decode.d8.loss_dice: 0.5553  grad_norm: 61.6489
2024/07/28 12:20:27 - mmengine - INFO - Iter(train) [ 6210/10935]  base_lr: 4.6996e-05 lr: 4.6996e-06  eta: 1:45:52  time: 1.3438  data_time: 0.0101  memory: 25124  loss: 5.5514  decode.loss_cls: 0.0006  decode.loss_mask: 0.0601  decode.loss_dice: 0.4628  decode.d0.loss_cls: 0.1527  decode.d0.loss_mask: 0.0654  decode.d0.loss_dice: 0.5867  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.0648  decode.d1.loss_dice: 0.5309  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.0642  decode.d2.loss_dice: 0.4950  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0623  decode.d3.loss_dice: 0.4694  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0620  decode.d4.loss_dice: 0.4237  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0611  decode.d5.loss_dice: 0.4410  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.0608  decode.d6.loss_dice: 0.4355  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.0629  decode.d7.loss_dice: 0.4352  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0644  decode.d8.loss_dice: 0.4829  grad_norm: 37.5727
2024/07/28 12:23:28 - mmengine - INFO - Iter(train) [ 6345/10935]  base_lr: 4.5786e-05 lr: 4.5786e-06  eta: 1:42:51  time: 1.3400  data_time: 0.0094  memory: 25124  loss: 5.0918  decode.loss_cls: 0.0005  decode.loss_mask: 0.0632  decode.loss_dice: 0.4433  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.0671  decode.d0.loss_dice: 0.4374  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.0688  decode.d1.loss_dice: 0.4381  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.0639  decode.d2.loss_dice: 0.4195  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.0653  decode.d3.loss_dice: 0.4298  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.0650  decode.d4.loss_dice: 0.4526  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.0695  decode.d5.loss_dice: 0.4439  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.0678  decode.d6.loss_dice: 0.4751  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.0669  decode.d7.loss_dice: 0.4035  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.0667  decode.d8.loss_dice: 0.3194  grad_norm: 65.7948
2024/07/28 12:26:30 - mmengine - INFO - Iter(train) [ 6480/10935]  base_lr: 4.4572e-05 lr: 4.4572e-06  eta: 1:39:49  time: 1.3402  data_time: 0.0096  memory: 25124  loss: 6.8124  decode.loss_cls: 0.0083  decode.loss_mask: 0.0667  decode.loss_dice: 0.6259  decode.d0.loss_cls: 0.0704  decode.d0.loss_mask: 0.0649  decode.d0.loss_dice: 0.5980  decode.d1.loss_cls: 0.0180  decode.d1.loss_mask: 0.0672  decode.d1.loss_dice: 0.6601  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.0643  decode.d2.loss_dice: 0.5600  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.0684  decode.d3.loss_dice: 0.6070  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.0644  decode.d4.loss_dice: 0.5558  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.0670  decode.d5.loss_dice: 0.6276  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.0671  decode.d6.loss_dice: 0.5842  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.0669  decode.d7.loss_dice: 0.5226  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.0667  decode.d8.loss_dice: 0.6444  grad_norm: 40.8538
2024/07/28 12:29:31 - mmengine - INFO - Iter(train) [ 6615/10935]  base_lr: 4.3355e-05 lr: 4.3355e-06  eta: 1:36:47  time: 1.3419  data_time: 0.0102  memory: 25124  loss: 5.7573  decode.loss_cls: 0.0029  decode.loss_mask: 0.0569  decode.loss_dice: 0.4711  decode.d0.loss_cls: 0.0767  decode.d0.loss_mask: 0.0568  decode.d0.loss_dice: 0.5242  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.0537  decode.d1.loss_dice: 0.4342  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.0580  decode.d2.loss_dice: 0.4896  decode.d3.loss_cls: 0.0959  decode.d3.loss_mask: 0.0573  decode.d3.loss_dice: 0.5965  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.0573  decode.d4.loss_dice: 0.4275  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.0532  decode.d5.loss_dice: 0.4695  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.0561  decode.d6.loss_dice: 0.5104  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.0557  decode.d7.loss_dice: 0.4975  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.0569  decode.d8.loss_dice: 0.5777  grad_norm: 51.5930
2024/07/28 12:32:32 - mmengine - INFO - Iter(train) [ 6750/10935]  base_lr: 4.2133e-05 lr: 4.2133e-06  eta: 1:33:46  time: 1.3402  data_time: 0.0098  memory: 25124  loss: 7.8741  decode.loss_cls: 0.0023  decode.loss_mask: 0.0721  decode.loss_dice: 0.6669  decode.d0.loss_cls: 0.0637  decode.d0.loss_mask: 0.0697  decode.d0.loss_dice: 0.7654  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.0703  decode.d1.loss_dice: 0.6622  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.0758  decode.d2.loss_dice: 0.6574  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.0718  decode.d3.loss_dice: 0.7494  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.0748  decode.d4.loss_dice: 0.7718  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.0735  decode.d5.loss_dice: 0.6665  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.0744  decode.d6.loss_dice: 0.6786  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.0714  decode.d7.loss_dice: 0.7151  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.0732  decode.d8.loss_dice: 0.7010  grad_norm: 42.6088
2024/07/28 12:35:34 - mmengine - INFO - Iter(train) [ 6885/10935]  base_lr: 4.0908e-05 lr: 4.0908e-06  eta: 1:30:44  time: 1.3454  data_time: 0.0103  memory: 25124  loss: 4.8580  decode.loss_cls: 0.0002  decode.loss_mask: 0.0813  decode.loss_dice: 0.4170  decode.d0.loss_cls: 0.0754  decode.d0.loss_mask: 0.0892  decode.d0.loss_dice: 0.3896  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.0823  decode.d1.loss_dice: 0.3952  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.0835  decode.d2.loss_dice: 0.4055  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0807  decode.d3.loss_dice: 0.3893  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0826  decode.d4.loss_dice: 0.4022  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0814  decode.d5.loss_dice: 0.3704  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0834  decode.d6.loss_dice: 0.4025  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0798  decode.d7.loss_dice: 0.3938  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0836  decode.d8.loss_dice: 0.3867  grad_norm: 49.7111
2024/07/28 12:38:08 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 12:38:35 - mmengine - INFO - Iter(train) [ 7020/10935]  base_lr: 3.9679e-05 lr: 3.9679e-06  eta: 1:27:43  time: 1.3462  data_time: 0.0102  memory: 25124  loss: 6.5887  decode.loss_cls: 0.0012  decode.loss_mask: 0.0707  decode.loss_dice: 0.4601  decode.d0.loss_cls: 0.1351  decode.d0.loss_mask: 0.0719  decode.d0.loss_dice: 0.5601  decode.d1.loss_cls: 0.2131  decode.d1.loss_mask: 0.0690  decode.d1.loss_dice: 0.6551  decode.d2.loss_cls: 0.1520  decode.d2.loss_mask: 0.0723  decode.d2.loss_dice: 0.5398  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0691  decode.d3.loss_dice: 0.5128  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.0710  decode.d4.loss_dice: 0.5727  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0700  decode.d5.loss_dice: 0.5450  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.0687  decode.d6.loss_dice: 0.4524  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.0692  decode.d7.loss_dice: 0.5137  decode.d8.loss_cls: 0.0833  decode.d8.loss_mask: 0.0702  decode.d8.loss_dice: 0.4878  grad_norm: 31.4794
2024/07/28 12:41:37 - mmengine - INFO - Iter(train) [ 7155/10935]  base_lr: 3.8445e-05 lr: 3.8445e-06  eta: 1:24:41  time: 1.3472  data_time: 0.0105  memory: 25124  loss: 4.7425  decode.loss_cls: 0.0013  decode.loss_mask: 0.0828  decode.loss_dice: 0.3143  decode.d0.loss_cls: 0.0610  decode.d0.loss_mask: 0.0863  decode.d0.loss_dice: 0.3876  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.0851  decode.d1.loss_dice: 0.4734  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.0877  decode.d2.loss_dice: 0.3926  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.0875  decode.d3.loss_dice: 0.3514  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.0854  decode.d4.loss_dice: 0.3436  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.0863  decode.d5.loss_dice: 0.3552  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.0849  decode.d6.loss_dice: 0.4218  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.0819  decode.d7.loss_dice: 0.3238  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.0843  decode.d8.loss_dice: 0.4387  grad_norm: 82.5957
2024/07/28 12:44:39 - mmengine - INFO - Iter(train) [ 7290/10935]  base_lr: 3.7207e-05 lr: 3.7207e-06  eta: 1:21:40  time: 1.3457  data_time: 0.0100  memory: 25124  loss: 5.9263  decode.loss_cls: 0.0003  decode.loss_mask: 0.0680  decode.loss_dice: 0.5685  decode.d0.loss_cls: 0.0590  decode.d0.loss_mask: 0.0736  decode.d0.loss_dice: 0.5330  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.0677  decode.d1.loss_dice: 0.5139  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.0692  decode.d2.loss_dice: 0.4971  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0702  decode.d3.loss_dice: 0.4862  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0694  decode.d4.loss_dice: 0.4607  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0716  decode.d5.loss_dice: 0.5521  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0727  decode.d6.loss_dice: 0.5110  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.0726  decode.d7.loss_dice: 0.5444  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.0677  decode.d8.loss_dice: 0.4866  grad_norm: 105.1451
2024/07/28 12:47:40 - mmengine - INFO - Iter(train) [ 7425/10935]  base_lr: 3.5965e-05 lr: 3.5965e-06  eta: 1:18:39  time: 1.3457  data_time: 0.0106  memory: 25124  loss: 5.6067  decode.loss_cls: 0.0005  decode.loss_mask: 0.0638  decode.loss_dice: 0.4975  decode.d0.loss_cls: 0.0728  decode.d0.loss_mask: 0.0629  decode.d0.loss_dice: 0.4682  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.0675  decode.d1.loss_dice: 0.5194  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0665  decode.d2.loss_dice: 0.5285  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.0637  decode.d3.loss_dice: 0.4830  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0662  decode.d4.loss_dice: 0.5018  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.0622  decode.d5.loss_dice: 0.4657  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.0614  decode.d6.loss_dice: 0.4600  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0624  decode.d7.loss_dice: 0.4880  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0668  decode.d8.loss_dice: 0.4715  grad_norm: 37.3532
2024/07/28 12:50:42 - mmengine - INFO - Iter(train) [ 7560/10935]  base_lr: 3.4717e-05 lr: 3.4717e-06  eta: 1:15:37  time: 1.3470  data_time: 0.0104  memory: 25124  loss: 5.1316  decode.loss_cls: 0.0175  decode.loss_mask: 0.0784  decode.loss_dice: 0.4358  decode.d0.loss_cls: 0.0763  decode.d0.loss_mask: 0.0821  decode.d0.loss_dice: 0.4584  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.0791  decode.d1.loss_dice: 0.3814  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.0741  decode.d2.loss_dice: 0.4293  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.0752  decode.d3.loss_dice: 0.4337  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.0766  decode.d4.loss_dice: 0.4133  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.0740  decode.d5.loss_dice: 0.3739  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.0775  decode.d6.loss_dice: 0.4057  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.0784  decode.d7.loss_dice: 0.4494  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.0746  decode.d8.loss_dice: 0.3774  grad_norm: 31.3016
2024/07/28 12:53:44 - mmengine - INFO - Iter(train) [ 7695/10935]  base_lr: 3.3465e-05 lr: 3.3465e-06  eta: 1:12:36  time: 1.3456  data_time: 0.0102  memory: 25124  loss: 6.2980  decode.loss_cls: 0.0012  decode.loss_mask: 0.0870  decode.loss_dice: 0.6288  decode.d0.loss_cls: 0.0715  decode.d0.loss_mask: 0.0886  decode.d0.loss_dice: 0.4969  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.0858  decode.d1.loss_dice: 0.5051  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.0853  decode.d2.loss_dice: 0.4507  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.0902  decode.d3.loss_dice: 0.5680  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.0899  decode.d4.loss_dice: 0.4770  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.0876  decode.d5.loss_dice: 0.6157  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.0889  decode.d6.loss_dice: 0.5660  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.0861  decode.d7.loss_dice: 0.4897  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.0884  decode.d8.loss_dice: 0.5358  grad_norm: 37.9325
2024/07/28 12:56:46 - mmengine - INFO - Iter(train) [ 7830/10935]  base_lr: 3.2207e-05 lr: 3.2207e-06  eta: 1:09:35  time: 1.3471  data_time: 0.0102  memory: 25124  loss: 6.0255  decode.loss_cls: 0.0002  decode.loss_mask: 0.0736  decode.loss_dice: 0.5087  decode.d0.loss_cls: 0.0724  decode.d0.loss_mask: 0.0728  decode.d0.loss_dice: 0.5048  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.0767  decode.d1.loss_dice: 0.5109  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.0768  decode.d2.loss_dice: 0.5616  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0718  decode.d3.loss_dice: 0.4879  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.0772  decode.d4.loss_dice: 0.5260  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0773  decode.d5.loss_dice: 0.5496  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0748  decode.d6.loss_dice: 0.4946  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.0772  decode.d7.loss_dice: 0.5426  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0763  decode.d8.loss_dice: 0.5073  grad_norm: 41.0809
2024/07/28 12:59:48 - mmengine - INFO - Iter(train) [ 7965/10935]  base_lr: 3.0944e-05 lr: 3.0944e-06  eta: 1:06:33  time: 1.3480  data_time: 0.0105  memory: 25124  loss: 8.1848  decode.loss_cls: 0.0004  decode.loss_mask: 0.1059  decode.loss_dice: 0.7023  decode.d0.loss_cls: 0.0707  decode.d0.loss_mask: 0.1061  decode.d0.loss_dice: 0.7269  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.1073  decode.d1.loss_dice: 0.7151  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.1038  decode.d2.loss_dice: 0.6879  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.1093  decode.d3.loss_dice: 0.7059  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.1032  decode.d4.loss_dice: 0.6808  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.1046  decode.d5.loss_dice: 0.7008  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.1044  decode.d6.loss_dice: 0.7151  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.1066  decode.d7.loss_dice: 0.7232  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.1036  decode.d8.loss_dice: 0.6958  grad_norm: 29.1050
2024/07/28 13:00:35 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 13:02:49 - mmengine - INFO - Iter(train) [ 8100/10935]  base_lr: 2.9675e-05 lr: 2.9675e-06  eta: 1:03:32  time: 1.3463  data_time: 0.0103  memory: 25124  loss: 4.5653  decode.loss_cls: 0.0003  decode.loss_mask: 0.0658  decode.loss_dice: 0.3862  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.0662  decode.d0.loss_dice: 0.3589  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.0660  decode.d1.loss_dice: 0.3705  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.0661  decode.d2.loss_dice: 0.4046  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0664  decode.d3.loss_dice: 0.3756  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.0669  decode.d4.loss_dice: 0.3660  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0652  decode.d5.loss_dice: 0.3637  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.0685  decode.d6.loss_dice: 0.4034  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0672  decode.d7.loss_dice: 0.3929  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.0661  decode.d8.loss_dice: 0.4020  grad_norm: 32.1533
2024/07/28 13:05:51 - mmengine - INFO - Iter(train) [ 8235/10935]  base_lr: 2.8401e-05 lr: 2.8401e-06  eta: 1:00:30  time: 1.3458  data_time: 0.0104  memory: 25124  loss: 3.0914  decode.loss_cls: 0.0006  decode.loss_mask: 0.0577  decode.loss_dice: 0.2571  decode.d0.loss_cls: 0.0689  decode.d0.loss_mask: 0.0572  decode.d0.loss_dice: 0.2693  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0533  decode.d1.loss_dice: 0.2346  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.0562  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0567  decode.d3.loss_dice: 0.2427  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.0568  decode.d4.loss_dice: 0.2434  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0575  decode.d5.loss_dice: 0.2284  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.0562  decode.d6.loss_dice: 0.2244  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0562  decode.d7.loss_dice: 0.2524  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.0570  decode.d8.loss_dice: 0.2664  grad_norm: 52.4050
2024/07/28 13:08:53 - mmengine - INFO - Iter(train) [ 8370/10935]  base_lr: 2.7119e-05 lr: 2.7119e-06  eta: 0:57:29  time: 1.3449  data_time: 0.0102  memory: 25124  loss: 7.0836  decode.loss_cls: 0.0006  decode.loss_mask: 0.0788  decode.loss_dice: 0.6245  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.0790  decode.d0.loss_dice: 0.6142  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.0783  decode.d1.loss_dice: 0.6086  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.0780  decode.d2.loss_dice: 0.5964  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.0796  decode.d3.loss_dice: 0.6349  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.0793  decode.d4.loss_dice: 0.6435  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.0763  decode.d5.loss_dice: 0.6132  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.0746  decode.d6.loss_dice: 0.6064  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.0777  decode.d7.loss_dice: 0.6080  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.0820  decode.d8.loss_dice: 0.6452  grad_norm: 34.1102
2024/07/28 13:11:54 - mmengine - INFO - Iter(train) [ 8505/10935]  base_lr: 2.5831e-05 lr: 2.5831e-06  eta: 0:54:27  time: 1.3434  data_time: 0.0102  memory: 25124  loss: 5.6499  decode.loss_cls: 0.0002  decode.loss_mask: 0.0635  decode.loss_dice: 0.4218  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.0665  decode.d0.loss_dice: 0.4457  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.0691  decode.d1.loss_dice: 0.5332  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.0651  decode.d2.loss_dice: 0.4455  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0631  decode.d3.loss_dice: 0.4342  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0666  decode.d4.loss_dice: 0.5285  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.0657  decode.d5.loss_dice: 0.5633  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0638  decode.d6.loss_dice: 0.5480  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0671  decode.d7.loss_dice: 0.5085  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.0627  decode.d8.loss_dice: 0.4725  grad_norm: 91.9684
2024/07/28 13:14:56 - mmengine - INFO - Iter(train) [ 8640/10935]  base_lr: 2.4536e-05 lr: 2.4536e-06  eta: 0:51:26  time: 1.3442  data_time: 0.0103  memory: 25124  loss: 4.4037  decode.loss_cls: 0.0002  decode.loss_mask: 0.0648  decode.loss_dice: 0.3525  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.0652  decode.d0.loss_dice: 0.3695  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.0684  decode.d1.loss_dice: 0.3635  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0659  decode.d2.loss_dice: 0.3889  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0675  decode.d3.loss_dice: 0.3645  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0675  decode.d4.loss_dice: 0.3798  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0680  decode.d5.loss_dice: 0.3707  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.0671  decode.d6.loss_dice: 0.3520  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.0670  decode.d7.loss_dice: 0.3523  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0674  decode.d8.loss_dice: 0.3587  grad_norm: 52.4031
2024/07/28 13:17:57 - mmengine - INFO - Iter(train) [ 8775/10935]  base_lr: 2.3233e-05 lr: 2.3233e-06  eta: 0:48:24  time: 1.3446  data_time: 0.0103  memory: 25124  loss: 5.4632  decode.loss_cls: 0.0007  decode.loss_mask: 0.0704  decode.loss_dice: 0.4718  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.0688  decode.d0.loss_dice: 0.4616  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.0714  decode.d1.loss_dice: 0.4695  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.0713  decode.d2.loss_dice: 0.4489  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.0673  decode.d3.loss_dice: 0.4792  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.0709  decode.d4.loss_dice: 0.4235  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.0699  decode.d5.loss_dice: 0.5002  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.0728  decode.d6.loss_dice: 0.4870  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.0727  decode.d7.loss_dice: 0.4502  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.0733  decode.d8.loss_dice: 0.4847  grad_norm: 238.8109
2024/07/28 13:20:59 - mmengine - INFO - Iter(train) [ 8910/10935]  base_lr: 2.1922e-05 lr: 2.1922e-06  eta: 0:45:23  time: 1.3475  data_time: 0.0104  memory: 25124  loss: 7.0781  decode.loss_cls: 0.0015  decode.loss_mask: 0.0858  decode.loss_dice: 0.6228  decode.d0.loss_cls: 0.0675  decode.d0.loss_mask: 0.0849  decode.d0.loss_dice: 0.5921  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.0859  decode.d1.loss_dice: 0.5953  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.0872  decode.d2.loss_dice: 0.6163  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.0868  decode.d3.loss_dice: 0.6141  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.0844  decode.d4.loss_dice: 0.6298  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.0836  decode.d5.loss_dice: 0.6141  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.0834  decode.d6.loss_dice: 0.6296  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.0874  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.0858  decode.d8.loss_dice: 0.6362  grad_norm: 33.1767
2024/07/28 13:23:00 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 13:24:00 - mmengine - INFO - Iter(train) [ 9045/10935]  base_lr: 2.0602e-05 lr: 2.0602e-06  eta: 0:42:21  time: 1.3455  data_time: 0.0102  memory: 25124  loss: 4.7695  decode.loss_cls: 0.0003  decode.loss_mask: 0.0752  decode.loss_dice: 0.4453  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.0731  decode.d0.loss_dice: 0.4185  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.0731  decode.d1.loss_dice: 0.3814  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.0742  decode.d2.loss_dice: 0.3746  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.0771  decode.d3.loss_dice: 0.3934  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.0803  decode.d4.loss_dice: 0.4384  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.0722  decode.d5.loss_dice: 0.3892  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0746  decode.d6.loss_dice: 0.4199  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0739  decode.d7.loss_dice: 0.3738  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0732  decode.d8.loss_dice: 0.3127  grad_norm: 36.9321
2024/07/28 13:27:02 - mmengine - INFO - Iter(train) [ 9180/10935]  base_lr: 1.9273e-05 lr: 1.9273e-06  eta: 0:39:19  time: 1.3431  data_time: 0.0103  memory: 25124  loss: 4.5473  decode.loss_cls: 0.0002  decode.loss_mask: 0.0687  decode.loss_dice: 0.3948  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.0717  decode.d0.loss_dice: 0.3621  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.0701  decode.d1.loss_dice: 0.4106  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.0718  decode.d2.loss_dice: 0.3520  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.0695  decode.d3.loss_dice: 0.3911  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.0667  decode.d4.loss_dice: 0.3380  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.0682  decode.d5.loss_dice: 0.4002  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0670  decode.d6.loss_dice: 0.3538  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0648  decode.d7.loss_dice: 0.4156  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.0672  decode.d8.loss_dice: 0.3737  grad_norm: 47.4730
2024/07/28 13:30:04 - mmengine - INFO - Iter(train) [ 9315/10935]  base_lr: 1.7933e-05 lr: 1.7933e-06  eta: 0:36:18  time: 1.3480  data_time: 0.0104  memory: 25124  loss: 6.6877  decode.loss_cls: 0.0002  decode.loss_mask: 0.0865  decode.loss_dice: 0.5737  decode.d0.loss_cls: 0.0549  decode.d0.loss_mask: 0.0849  decode.d0.loss_dice: 0.5795  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0884  decode.d1.loss_dice: 0.6043  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.0909  decode.d2.loss_dice: 0.5943  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0917  decode.d3.loss_dice: 0.5262  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.0902  decode.d4.loss_dice: 0.6059  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.0859  decode.d5.loss_dice: 0.5375  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0879  decode.d6.loss_dice: 0.5396  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.0867  decode.d7.loss_dice: 0.5810  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.0896  decode.d8.loss_dice: 0.6039  grad_norm: 43.0265
2024/07/28 13:33:05 - mmengine - INFO - Iter(train) [ 9450/10935]  base_lr: 1.6583e-05 lr: 1.6583e-06  eta: 0:33:16  time: 1.3568  data_time: 0.0100  memory: 25124  loss: 6.7818  decode.loss_cls: 0.0502  decode.loss_mask: 0.0630  decode.loss_dice: 0.5098  decode.d0.loss_cls: 0.1353  decode.d0.loss_mask: 0.0597  decode.d0.loss_dice: 0.5387  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.0650  decode.d1.loss_dice: 0.5018  decode.d2.loss_cls: 0.1443  decode.d2.loss_mask: 0.0645  decode.d2.loss_dice: 0.5246  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.0625  decode.d3.loss_dice: 0.5165  decode.d4.loss_cls: 0.1348  decode.d4.loss_mask: 0.0659  decode.d4.loss_dice: 0.5293  decode.d5.loss_cls: 0.1058  decode.d5.loss_mask: 0.0661  decode.d5.loss_dice: 0.5146  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.0626  decode.d6.loss_dice: 0.4799  decode.d7.loss_cls: 0.0661  decode.d7.loss_mask: 0.0637  decode.d7.loss_dice: 0.4959  decode.d8.loss_cls: 0.1329  decode.d8.loss_mask: 0.0638  decode.d8.loss_dice: 0.5411  grad_norm: 40.3394
2024/07/28 13:36:07 - mmengine - INFO - Iter(train) [ 9585/10935]  base_lr: 1.5219e-05 lr: 1.5219e-06  eta: 0:30:15  time: 1.3436  data_time: 0.0102  memory: 25124  loss: 8.4710  decode.loss_cls: 0.1721  decode.loss_mask: 0.0533  decode.loss_dice: 0.6264  decode.d0.loss_cls: 0.0588  decode.d0.loss_mask: 0.0521  decode.d0.loss_dice: 0.7084  decode.d1.loss_cls: 0.1944  decode.d1.loss_mask: 0.0538  decode.d1.loss_dice: 0.6104  decode.d2.loss_cls: 0.0485  decode.d2.loss_mask: 0.0528  decode.d2.loss_dice: 0.6733  decode.d3.loss_cls: 0.2148  decode.d3.loss_mask: 0.0576  decode.d3.loss_dice: 0.6569  decode.d4.loss_cls: 0.1984  decode.d4.loss_mask: 0.0579  decode.d4.loss_dice: 0.6484  decode.d5.loss_cls: 0.1056  decode.d5.loss_mask: 0.0543  decode.d5.loss_dice: 0.6738  decode.d6.loss_cls: 0.1726  decode.d6.loss_mask: 0.0538  decode.d6.loss_dice: 0.6405  decode.d7.loss_cls: 0.1493  decode.d7.loss_mask: 0.0522  decode.d7.loss_dice: 0.5846  decode.d8.loss_cls: 0.1572  decode.d8.loss_mask: 0.0543  decode.d8.loss_dice: 0.6344  grad_norm: 36.6907
2024/07/28 13:39:09 - mmengine - INFO - Iter(train) [ 9720/10935]  base_lr: 1.3843e-05 lr: 1.3843e-06  eta: 0:27:13  time: 1.3449  data_time: 0.0103  memory: 25124  loss: 7.2291  decode.loss_cls: 0.0003  decode.loss_mask: 0.0939  decode.loss_dice: 0.5349  decode.d0.loss_cls: 0.0529  decode.d0.loss_mask: 0.0946  decode.d0.loss_dice: 0.6454  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.0910  decode.d1.loss_dice: 0.6040  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.0938  decode.d2.loss_dice: 0.6504  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0931  decode.d3.loss_dice: 0.5863  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0927  decode.d4.loss_dice: 0.6558  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.0921  decode.d5.loss_dice: 0.7063  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.0937  decode.d6.loss_dice: 0.5752  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.0938  decode.d7.loss_dice: 0.6303  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.0919  decode.d8.loss_dice: 0.6515  grad_norm: 37.3780
2024/07/28 13:42:10 - mmengine - INFO - Iter(train) [ 9855/10935]  base_lr: 1.2450e-05 lr: 1.2450e-06  eta: 0:24:12  time: 1.3430  data_time: 0.0098  memory: 25124  loss: 4.4866  decode.loss_cls: 0.0003  decode.loss_mask: 0.0736  decode.loss_dice: 0.3651  decode.d0.loss_cls: 0.0527  decode.d0.loss_mask: 0.0748  decode.d0.loss_dice: 0.3784  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.0742  decode.d1.loss_dice: 0.3702  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.0733  decode.d2.loss_dice: 0.3760  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.0733  decode.d3.loss_dice: 0.3748  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.0718  decode.d4.loss_dice: 0.3733  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0705  decode.d5.loss_dice: 0.3561  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.0748  decode.d6.loss_dice: 0.3870  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0704  decode.d7.loss_dice: 0.3574  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0703  decode.d8.loss_dice: 0.3639  grad_norm: 53.1754
2024/07/28 13:45:12 - mmengine - INFO - Iter(train) [ 9990/10935]  base_lr: 1.1040e-05 lr: 1.1040e-06  eta: 0:21:10  time: 1.3463  data_time: 0.0100  memory: 25124  loss: 5.9902  decode.loss_cls: 0.0022  decode.loss_mask: 0.0822  decode.loss_dice: 0.5270  decode.d0.loss_cls: 0.0656  decode.d0.loss_mask: 0.0828  decode.d0.loss_dice: 0.5546  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.0834  decode.d1.loss_dice: 0.5332  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.0790  decode.d2.loss_dice: 0.5335  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.0818  decode.d3.loss_dice: 0.5440  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.0812  decode.d4.loss_dice: 0.4234  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.0806  decode.d5.loss_dice: 0.4745  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.0923  decode.d6.loss_dice: 0.5247  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.0785  decode.d7.loss_dice: 0.4451  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.0819  decode.d8.loss_dice: 0.5103  grad_norm: 31.1925
2024/07/28 13:45:25 - mmengine - INFO - Exp name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20240728_100106
2024/07/28 13:48:13 - mmengine - INFO - Iter(train) [10125/10935]  base_lr: 9.6103e-06 lr: 9.6103e-07  eta: 0:18:09  time: 1.3426  data_time: 0.0092  memory: 25124  loss: 4.5598  decode.loss_cls: 0.0006  decode.loss_mask: 0.0635  decode.loss_dice: 0.4286  decode.d0.loss_cls: 0.0523  decode.d0.loss_mask: 0.0675  decode.d0.loss_dice: 0.4167  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.0648  decode.d1.loss_dice: 0.4181  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.0647  decode.d2.loss_dice: 0.3950  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.0656  decode.d3.loss_dice: 0.3632  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.0644  decode.d4.loss_dice: 0.3253  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.0644  decode.d5.loss_dice: 0.4138  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.0675  decode.d6.loss_dice: 0.3180  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.0645  decode.d7.loss_dice: 0.3592  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0639  decode.d8.loss_dice: 0.3706  grad_norm: 46.1638
2024/07/28 13:51:14 - mmengine - INFO - Iter(train) [10260/10935]  base_lr: 8.1559e-06 lr: 8.1559e-07  eta: 0:15:07  time: 1.3410  data_time: 0.0093  memory: 25124  loss: 6.5371  decode.loss_cls: 0.0003  decode.loss_mask: 0.0676  decode.loss_dice: 0.5893  decode.d0.loss_cls: 0.0526  decode.d0.loss_mask: 0.0699  decode.d0.loss_dice: 0.6105  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.0696  decode.d1.loss_dice: 0.5140  decode.d2.loss_cls: 0.1497  decode.d2.loss_mask: 0.0699  decode.d2.loss_dice: 0.6595  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.0670  decode.d3.loss_dice: 0.5193  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.0676  decode.d4.loss_dice: 0.5402  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.0692  decode.d5.loss_dice: 0.5351  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.0680  decode.d6.loss_dice: 0.5388  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.0683  decode.d7.loss_dice: 0.5455  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0680  decode.d8.loss_dice: 0.5927  grad_norm: 53.8051
2024/07/28 13:54:16 - mmengine - INFO - Iter(train) [10395/10935]  base_lr: 6.6720e-06 lr: 6.6720e-07  eta: 0:12:06  time: 1.3452  data_time: 0.0097  memory: 25124  loss: 5.7863  decode.loss_cls: 0.0012  decode.loss_mask: 0.0641  decode.loss_dice: 0.4861  decode.d0.loss_cls: 0.0524  decode.d0.loss_mask: 0.0628  decode.d0.loss_dice: 0.5385  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.0607  decode.d1.loss_dice: 0.5173  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.0617  decode.d2.loss_dice: 0.6007  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.0614  decode.d3.loss_dice: 0.4873  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.0633  decode.d4.loss_dice: 0.5283  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.0630  decode.d5.loss_dice: 0.5145  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.0622  decode.d6.loss_dice: 0.4959  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.0588  decode.d7.loss_dice: 0.4748  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.0617  decode.d8.loss_dice: 0.4578  grad_norm: 53.5471
2024/07/28 13:57:17 - mmengine - INFO - Iter(train) [10530/10935]  base_lr: 5.1500e-06 lr: 5.1500e-07  eta: 0:09:04  time: 1.3445  data_time: 0.0095  memory: 25124  loss: 5.1648  decode.loss_cls: 0.0015  decode.loss_mask: 0.0819  decode.loss_dice: 0.4214  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.0862  decode.d0.loss_dice: 0.4067  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.0845  decode.d1.loss_dice: 0.4106  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.0881  decode.d2.loss_dice: 0.4276  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.0864  decode.d3.loss_dice: 0.4426  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.0840  decode.d4.loss_dice: 0.4071  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.0864  decode.d5.loss_dice: 0.4294  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.0882  decode.d6.loss_dice: 0.4334  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.0844  decode.d7.loss_dice: 0.4155  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.0860  decode.d8.loss_dice: 0.4209  grad_norm: 32.8689
2024/07/28 14:00:19 - mmengine - INFO - Iter(train) [10665/10935]  base_lr: 3.5754e-06 lr: 3.5754e-07  eta: 0:06:03  time: 1.3435  data_time: 0.0096  memory: 25124  loss: 5.4524  decode.loss_cls: 0.0125  decode.loss_mask: 0.0539  decode.loss_dice: 0.4631  decode.d0.loss_cls: 0.0832  decode.d0.loss_mask: 0.0559  decode.d0.loss_dice: 0.5125  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.0521  decode.d1.loss_dice: 0.4266  decode.d2.loss_cls: 0.1120  decode.d2.loss_mask: 0.0570  decode.d2.loss_dice: 0.5003  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.0515  decode.d3.loss_dice: 0.4127  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.0565  decode.d4.loss_dice: 0.4753  decode.d5.loss_cls: 0.0155  decode.d5.loss_mask: 0.0555  decode.d5.loss_dice: 0.4061  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.0537  decode.d6.loss_dice: 0.4430  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.0585  decode.d7.loss_dice: 0.4289  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.0542  decode.d8.loss_dice: 0.4679  grad_norm: 47.2634
2024/07/28 14:03:20 - mmengine - INFO - Iter(train) [10800/10935]  base_lr: 1.9160e-06 lr: 1.9160e-07  eta: 0:03:01  time: 1.3413  data_time: 0.0096  memory: 25124  loss: 7.4748  decode.loss_cls: 0.0007  decode.loss_mask: 0.0775  decode.loss_dice: 0.6612  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.0752  decode.d0.loss_dice: 0.6698  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.0728  decode.d1.loss_dice: 0.6733  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.0747  decode.d2.loss_dice: 0.6578  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.0727  decode.d3.loss_dice: 0.6692  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.0753  decode.d4.loss_dice: 0.6322  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.0780  decode.d5.loss_dice: 0.6913  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.0751  decode.d6.loss_dice: 0.6774  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.0756  decode.d7.loss_dice: 0.6547  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.0745  decode.d8.loss_dice: 0.6510  grad_norm: 29.8338
2024/07/28 14:06:22 - mmengine - INFO - Iter(train) [10935/10935]  base_lr: 0.0000e+00 lr: 0.0000e+00  eta: 0:00:00  time: 1.3538  data_time: 0.0097  memory: 25124  loss: 11.3977  decode.loss_cls: 0.0143  decode.loss_mask: 0.1103  decode.loss_dice: 1.0651  decode.d0.loss_cls: 0.0581  decode.d0.loss_mask: 0.1145  decode.d0.loss_dice: 0.9374  decode.d1.loss_cls: 0.1076  decode.d1.loss_mask: 0.1138  decode.d1.loss_dice: 0.9398  decode.d2.loss_cls: 0.1297  decode.d2.loss_mask: 0.1086  decode.d2.loss_dice: 0.9072  decode.d3.loss_cls: 0.0943  decode.d3.loss_mask: 0.1090  decode.d3.loss_dice: 0.9890  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.1092  decode.d4.loss_dice: 0.9895  decode.d5.loss_cls: 0.0281  decode.d5.loss_mask: 0.1123  decode.d5.loss_dice: 0.9650  decode.d6.loss_cls: 0.0248  decode.d6.loss_mask: 0.1047  decode.d6.loss_dice: 1.0064  decode.d7.loss_cls: 0.0383  decode.d7.loss_mask: 0.1104  decode.d7.loss_dice: 0.9765  decode.d8.loss_cls: 0.0235  decode.d8.loss_mask: 0.1130  decode.d8.loss_dice: 0.9824  grad_norm: 106.8615
2024/07/28 14:06:22 - mmengine - INFO - Saving checkpoint at 10935 iterations
2024/07/28 14:08:50 - mmengine - INFO - per class results:
2024/07/28 14:08:50 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| Outside billboards | 99.82 | 99.93 |
|     Billboard      | 95.93 | 98.03 |
|      Goal net      | 93.06 | 97.32 |
|     Occlusion      | 44.56 | 49.96 |
+--------------------+-------+-------+
2024/07/28 14:08:50 - mmengine - INFO - Iter(val) [82/82]    aAcc: 99.7800  mIoU: 83.3400  mAcc: 86.3100  data_time: 0.0205  time: 1.7343
2024/07/28 14:08:52 - mmengine - INFO - The best checkpoint with 83.3400 mIoU at 10935 iter is saved to best_mIoU_iter_10935.pth.
