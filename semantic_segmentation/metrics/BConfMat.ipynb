{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from cv2 import distanceTransform, DIST_L2, DIST_MASK_PRECISE\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predPath = '../inferences/knet/test/tta/'\n",
    "gtPath = '../../Dataset/Labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBConfMat(pred, gt, nClasses, distances):\n",
    "    confMatPerDist = np.zeros((len(distances), nClasses+1, nClasses+1), dtype=np.int64)\n",
    "    if np.any(np.isinf(distances)):\n",
    "        confMatPerDist[-1] += confusion_matrix(gt.flatten(), pred.flatten(), labels=np.arange(nClasses+1))\n",
    "    \n",
    "    distances = [int(d) for d in distances if not np.isinf(d)]\n",
    "    if len(distances) == 0:\n",
    "        return confMatPerDist\n",
    "    \n",
    "    predOneHot = torch.nn.functional.one_hot(pred, 4).permute(2,0,1).numpy().astype(np.uint8)\n",
    "    gtOneHot = torch.nn.functional.one_hot(gt, 4).permute(2,0,1).numpy().astype(np.uint8)\n",
    "    distPredOneHot = np.array([cv2.distanceTransform(binImg, cv2.DIST_L2, cv2.DIST_MASK_PRECISE) for binImg in predOneHot])\n",
    "    distGtOneHot = np.array([cv2.distanceTransform(binImg, cv2.DIST_L2, cv2.DIST_MASK_PRECISE) for binImg in gtOneHot])\n",
    "    \n",
    "    for i, d in enumerate(distances):\n",
    "        boundaryPredOneHot = np.bitwise_and(distPredOneHot <= d, predOneHot)\n",
    "        boundaryGtOneHot = np.bitwise_and(distGtOneHot <= d, gtOneHot)\n",
    "        # concatenate np.ones_like(boundaryPredOneHot[0]) at the end of the array to account for the background class\n",
    "        boundaryPredOneHot = np.concatenate((boundaryPredOneHot, np.ones_like(boundaryPredOneHot[0])[np.newaxis]), axis=0)\n",
    "        boundaryGtOneHot = np.concatenate((boundaryGtOneHot, np.ones_like(boundaryGtOneHot[0])[np.newaxis]), axis=0)\n",
    "        boundaryPred = np.argmax(boundaryPredOneHot, axis=0)\n",
    "        boundaryGt = np.argmax(boundaryGtOneHot, axis=0)\n",
    "        \n",
    "        confMatPerDist[i] += confusion_matrix(boundaryGt.flatten(), boundaryPred.flatten(), labels=np.arange(nClasses+1))\n",
    "\n",
    "    return confMatPerDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [1,3,5,10,np.inf]\n",
    "nClasses = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing boundary confusion matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[    75094     16187      3085      2116     87490]\n",
      "  [    33566     89844       177      5995     46064]\n",
      "  [     3248       159     10940      2525     11439]\n",
      "  [    33930     13480      2092     12217     28495]\n",
      "  [    38626     53959     10133      8764 103090375]]\n",
      "\n",
      " [[   406423     20421      4057      3140    117820]\n",
      "  [    49436    413802       687      9654     49284]\n",
      "  [     5621       631     54902      3939     16610]\n",
      "  [    49244     15968      3112     49032     18770]\n",
      "  [    42839     68303     14728      6150 102255427]]\n",
      "\n",
      " [[   763419     21628      4415      3375    126856]\n",
      "  [    54804    748849       956     10747     50353]\n",
      "  [     6235      1019     98531      4335     20847]\n",
      "  [    50296     16417      3320     75339     15395]\n",
      "  [    48185     73435     17848      4032 101459364]]\n",
      "\n",
      " [[  1666999     24363      5267      3503    138363]\n",
      "  [    68890   1572832      1132     11480     43462]\n",
      "  [     8016      1347    194428      4701     27886]\n",
      "  [    50733     16755      3526    102397      8275]\n",
      "  [    51294     78195     23145      1999  99571012]]\n",
      "\n",
      " [[ 99536326     24389     27600      4200         0]\n",
      "  [    76839   3372282      1158     11940         0]\n",
      "  [    33078      1356    399857      5169         0]\n",
      "  [    56067     16860      3574    109305         0]\n",
      "  [        0         0         0         0         0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# imgFileNames = os.listdir(predPath)\n",
    "# totalConfMatPerDist = np.zeros((len(distances), nClasses+1, nClasses+1), dtype=np.int64)\n",
    "# for imgFileName in tqdm(imgFileNames):\n",
    "#     pred = torch.from_numpy(np.array(Image.open(predPath + imgFileName))).long()\n",
    "#     gt = torch.from_numpy(np.array(Image.open(gtPath + imgFileName))).long()\n",
    "#     totalConfMatPerDist += computeBConfMat(pred, gt, nClasses, distances)\n",
    "\n",
    "# Parallelize the above code using Pool\n",
    "imgFileNames = os.listdir(predPath)[:50]\n",
    "totalConfMatPerDist = np.zeros((len(distances), nClasses+1, nClasses+1), dtype=np.int64)\n",
    "def computeBConfMatWrapper(imgFileName):\n",
    "    pred = torch.from_numpy(np.array(Image.open(predPath + imgFileName))).long()\n",
    "    gt = torch.from_numpy(np.array(Image.open(gtPath + imgFileName))).long()\n",
    "    return computeBConfMat(pred, gt, nClasses, distances)\n",
    "\n",
    "print('Computing boundary confusion matrices...')\n",
    "with Pool(8) as p:\n",
    "    confMats = list(tqdm(p.imap_unordered(computeBConfMatWrapper, imgFileNames), total=len(imgFileNames)))\n",
    "    for confMat in confMats:\n",
    "        totalConfMatPerDist += confMat\n",
    "\n",
    "confMats = np.sum(confMats, axis=0)\n",
    "print(totalConfMatPerDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the confusion matrices\n",
    "np.save('boundary_confusion_matrices.npy', totalConfMatPerDist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmseg2.4.0pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
